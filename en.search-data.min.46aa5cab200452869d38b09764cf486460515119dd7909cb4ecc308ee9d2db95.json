[{"id":0,"href":"/docs/research/be_protocol/tls_ssl/","title":"TLS - SSL","section":"Backend","content":" TLS - SSL # Problem # If a website uses HTTP without SSL/TLS, all packets sent over the internet can easily be captured and read (see packet sniffing demonstration) How can a user determine if the website they are currently visiting is the original or a look-alike website created by a hacker to impersonate it? (see dns poisoning demonstration) Overview # The internet\u0026rsquo;s official birthday is January 1, 1983 A protocol for encrypting, securing, and authenticating communications that take place on the Internet SSL was replaced by an updated protocol called TLS some time ago, SSL is still a commonly used term for this technology To see which TLS version of a website (on Chrome): Open the Developer Tools (Ctrl+Shift+I) Select the Security tab Navigate to the Origin you want to inspect At the Connection section, check the results which TLS protocol is used TLS 1.2 # Key exchange algorithm: Utilize the encryption and decryption capabilities of asymmetric encryption Round trip time: 2 RTT Compatibility: Supported by both older and newer versions of all browsers Flow # Set up your server using TLS 1.2 # Nginx Open Your Nginx Configuration sudo vi /etc/nginx/sites-enabled/default Update the ssl_protocols directive and configure cipher suites: ssl_protocols TLSv1.2; ssl_ciphers 'ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256'; When you set up a free SSL certificate with Certbot (Let\u0026rsquo;s Encrypt certificate), Certbot automatically sets up ssl_protocols and ssl_ciphers for you (include /etc/letsencrypt/options-ssl-nginx.conf;). I commented this out to allow my demo to work correctly server { listen [::]:443 ssl ipv6only=on; # managed by Certbot listen 443 ssl; # managed by Certbot ssl_certificate /etc/letsencrypt/live/mnptt.io.vn/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/mnptt.io.vn/privkey.pem; # managed by Certbot #include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot # Downgrade to TLS 1.2 ssl_protocols TLSv1.2; ssl_ciphers \u0026#39;ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256\u0026#39;; root /var/www/html; index index.html index.htm index.nginx-debian.html; server_name mnptt.io.vn; location / { try_files $uri $uri/ =404; } } Test the configuration sudo nginx -t Reload Nginx sudo systemctl reload nginx Verify TLS 1.3 # Key exchange algorithm: Diffie-Hellman, Elliptic-curve Diffie-Hellman (ECDH) Round trip time: 1 RTT Compatibility: Supported by newer versions of most browsers Flow # Set up your server using TLS 1.3 # Nginx Requirements\nOpenSSL: 1.1.1 or newer Nginx: 1.13.0 or newer Open Your Nginx Configuration\nsudo vi /etc/nginx/sites-enabled/default Update the ssl_protocols directive and configure cipher suites: ssl_protocols TLSv1.3 TLSv1.2; ssl_ciphers 'TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384'; When you set up a free SSL certificate with Certbot (Let\u0026rsquo;s Encrypt certificate), Certbot automatically sets up ssl_protocols and ssl_ciphers for you (include /etc/letsencrypt/options-ssl-nginx.conf;). I commented this out to allow my demo to work correctly server { listen [::]:443 ssl ipv6only=on; # managed by Certbot listen 443 ssl; # managed by Certbot ssl_certificate /etc/letsencrypt/live/mnptt.io.vn/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/mnptt.io.vn/privkey.pem; # managed by Certbot #include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot # Override settings for TLS 1.3 ssl_protocols TLSv1.2 TLSv1.3; # Enable TLS 1.3 and keep TLS 1.2 ssl_ciphers \u0026#39;TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384\u0026#39;; root /var/www/html; index index.html index.htm index.nginx-debian.html; server_name mnptt.io.vn; location / { try_files $uri $uri/ =404; } } Test the configuration sudo nginx -t Reload Nginx sudo systemctl reload nginx Verify SSL Certificate # A SSL certificate contains: Domain name it\u0026rsquo;s issued for Certificate Authority (CA) Validity period Website\u0026rsquo;s public key Other information No certificate # Invalid certificate # Valid certificate # Validation levels # In terms of encryption strength, all three levels provide the same security Domain Validation # Least-stringent level User only has to prove they control the domain Process can be automated Organization Validation # Manual vetting process Extended Validation # Full background check of the organization At higher levels, they give more verified information about the website owner\u0026rsquo;s identity Types # Single Domain SSL Certificates # One domain and all pages\nWildcard SSL Certificates # One domain and all subdomains\nMulti-Domain SSL Certificates # It\u0026rsquo;s a shared certificate Multiple distinct domains will be listed on a certificate How to setup SSL Certificate? # Free SSL Certificate SSL Certificate for localhost Reference # Cloudflare: How does SSL work? Cloudflare: Types of SSL certificates: SSL certificate types explained Gigamon: What Is TLS 1.2, and Why Should You (Still) Care? Xargs: The Illustrated TLS 1.3 Connection (Nov 13th, 2024) Wikipedia: Transport Layer Security (Mar 1st, 2024) Cloudflare: A Detailed Look at RFC 8446 (a.k.a. TLS 1.3) (Aug 10th, 2018) Youtube: Let\u0026rsquo;s Encrypt Explained: Free SSL (Oct 25th, 2020) Youtube: Are Free SSL Certificates Really Good Enough for Your Website? (Sep 1st, 2022) Mozilla: SSL Configuration Generator (Nov 13th, 2024) Networkoptix: How to check and/or change the TLS version (Nov 11th, 2024) Help improve my blog Was this page helpful to you?\nüëç Yes üëé No This page was last modified at 2024-01-14\nView this page on GitHub Report a problem with this content Can I know your name? Yes No "},{"id":1,"href":"/docs/research/be_protocol/communication/","title":"Communication","section":"Backend","content":" Communication # Request-Response # Overview # Fundamental communication pattern The most common patterns for communication in client-server architectures Demo # Server code // server.js const http = require(\u0026#39;http\u0026#39;); const server = http.createServer((req, res) =\u0026gt; { console.log(`Received request: ${req.method} ${req.url}`); if (req.url === \u0026#39;/hello\u0026#39;) { if (req.method === \u0026#39;POST\u0026#39;) { let body = \u0026#39;\u0026#39;; req.on(\u0026#39;data\u0026#39;, chunk =\u0026gt; { body += chunk.toString(); // Convert buffer to string }); req.on(\u0026#39;end\u0026#39;, () =\u0026gt; { res.writeHead(200, { \u0026#39;Content-Type\u0026#39;: \u0026#39;text/plain\u0026#39; }); if (body.trim() === \u0026#34;ping\u0026#34;) { res.end(\u0026#39;pong\u0026#39;); } else { res.end(\u0026#39;\u0026#39;); } }); } else { res.writeHead(200, { \u0026#39;Content-Type\u0026#39;: \u0026#39;text/plain\u0026#39; }); res.end(\u0026#39;world\u0026#39;); } } else { res.writeHead(404, { \u0026#39;Content-Type\u0026#39;: \u0026#39;text/plain\u0026#39; }); res.end(\u0026#39;Not Found\u0026#39;); } }); server.listen(2000, () =\u0026gt; { console.log(\u0026#39;Server is listening on port 2000\u0026#39;); }); Client code fetch(\u0026#39;http://localhost:2000/hello\u0026#39;, { method: \u0026#39;POST\u0026#39;, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;text/plain\u0026#39; }, body: \u0026#39;ping\u0026#39; }) .then(response =\u0026gt; response.text()) .then(data =\u0026gt; console.log(data)) // Should log: \u0026#34;pong\u0026#34; Instruction Start the server by running node server.js\n1.1. Your terminal will display: Server is listening on port 2000 Open your browser and enter: http://localhost:2000/hello\n2.1. Your terminal will first log: Received request: GET /hello\n2.2. Then, your browser will display: world Open the browser console and run Client code\n3.1. Your terminal will first log: Received request: POST /hello\n3.2. Then, your browser console will display: pong Short Polling # Overview # Based on the Request-Response design pattern Continuously polls the server for new updates Near real-time updates Client controls the frequency Use case # Monitor stocks or cryptocurrencies Fetch status updates User notifications Demo # Server code // server.js const express = require(\u0026#39;express\u0026#39;); const app = express(); const port = 2000; app.get(\u0026#39;/\u0026#39;, (req, res) =\u0026gt; { res.send(\u0026#39;Hello world\u0026#39;); }); app.get(\u0026#39;/bitcoin\u0026#39;, (req, res) =\u0026gt; { const randomValue = Math.floor(Math.random() * 111) - 10; // Random value between -10 and +100 res.json({ coins: randomValue }); }); app.listen(port, () =\u0026gt; { console.log(`Server is running at http://localhost:${port}`); }); Client code function fetchBitcoinData() { fetch(\u0026#39;http://localhost:2000/bitcoin\u0026#39;) .then(response =\u0026gt; response.json()) .then(data =\u0026gt; { console.log(`Bitcoin value: ${data.coins}`); }); } setInterval(fetchBitcoinData, 1000); Instruction Start the server by running node server.js\n1.1. Your terminal will display: Server is running at http://localhost:2000 Open your browser and enter: http://localhost:2000\n2.1. Your browser will display: Hello world Open the browser console and run Client code\n3.1. Your browser console will continuously display: \u0026gt;\u0026gt; Bitcoin value: 10 \u0026gt;\u0026gt; Bitcoin value: 100 \u0026gt;\u0026gt; Bitcoin value: 26 \u0026gt;\u0026gt; Bitcoin value: -6 \u0026gt;\u0026gt; Bitcoin value: 65 ... Long Polling # Overview # Based on the Request-Response design pattern Holds the request open and only responds after completing the task Real-time updates Server controls the timing of response Use case # Fetch status updates User notifications Demo # Server code // server.js const express = require(\u0026#39;express\u0026#39;); const app = express(); const port = 2000; app.use(express.json()); app.get(\u0026#39;/\u0026#39;, (req, res) =\u0026gt; { res.send(\u0026#39;Hello world\u0026#39;); }); app.post(\u0026#39;/validate-music\u0026#39;, (req, res) =\u0026gt; { const { musicName, capacity } = req.body; // Simulate processing time with a random delay between 5 to 10 seconds const delay = Math.floor(Math.random() * 6) + 5; console.log(`Received request to validate music: ${musicName}, capacity: ${capacity}`); setTimeout(() =\u0026gt; { res.json({ message: `The music \u0026#34;${musicName}\u0026#34; is valid.` }); }, delay * 1000); }); app.listen(port, () =\u0026gt; { console.log(`Server is running at http://localhost:${port}`); }); Client code function validateMusic(musicName, capacity) { fetch(\u0026#39;http://localhost:2000/validate-music\u0026#39;, { method: \u0026#39;POST\u0026#39;, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39; }, body: JSON.stringify({ musicName, capacity }) }) .then(response =\u0026gt; response.json()) .then(data =\u0026gt; { console.log(data.message); }); } validateMusic(\u0026#39;Supernova\u0026#39;, \u0026#39;5MB\u0026#39;); Instruction Start the server by running node server.js\n1.1. Your terminal will display: Server is running at http://localhost:2000 Open your browser and enter: http://localhost:2000\n2.1. Your browser will display: Hello world Open the browser console and run Client code\n3.1. Your terminal will first log: Received request to validate music: Supernova, capacity: 5MB\n3.2. Then, your browser console after some seconds will display: The music \u0026quot;Supernova\u0026quot; is valid. Push # Overview # Real-time updates Use case # Chat and messaging apps Notification systems Demo Websocket # Bidirectional communication Server code // server.js const http = require(\u0026#39;http\u0026#39;); const WebSocket = require(\u0026#39;ws\u0026#39;); const port = 2000; // Create an HTTP server const server = http.createServer((req, res) =\u0026gt; { if (req.url === \u0026#39;/\u0026#39;) { res.writeHead(200, { \u0026#39;Content-Type\u0026#39;: \u0026#39;text/plain\u0026#39; }); res.end(\u0026#39;Hello, World!\u0026#39;); } else { res.writeHead(404, { \u0026#39;Content-Type\u0026#39;: \u0026#39;text/plain\u0026#39; }); res.end(\u0026#39;Not Found\u0026#39;); } }); // Create a WebSocket server on top of the HTTP server const wss = new WebSocket.Server({ server }); wss.on(\u0026#39;connection\u0026#39;, ws =\u0026gt; { console.log(\u0026#39;Client connected the WebSocket connection\u0026#39;); ws.on(\u0026#39;message\u0026#39;, message =\u0026gt; { console.log(`Received: ${message}`); // Simulating music validation process let progress = 0; const interval = setInterval(() =\u0026gt; { progress += Math.floor(Math.random() * 10) + 10; // Random progress between 10% - 20% if (progress \u0026gt;= 100) { progress = 100; ws.send(JSON.stringify({ status: \u0026#39;complete\u0026#39;, message: \u0026#39;Music validation complete and valid!\u0026#39; })); clearInterval(interval); } else { ws.send(JSON.stringify({ status: \u0026#39;in-progress\u0026#39;, progress: progress })); } }, 1000); }); ws.on(\u0026#39;close\u0026#39;, () =\u0026gt; { console.log(\u0026#39;Client disconnected the WebSocket connection\u0026#39;); }); }); server.listen(port, () =\u0026gt; { console.log(`Server running on http://localhost:${port}`); console.log(`WebSocket server running on ws://localhost:${port}`); }); Client code const socket = new WebSocket(\u0026#39;ws://localhost:2000\u0026#39;); socket.onmessage = function(event) { const data = JSON.parse(event.data); if (data.status === \u0026#39;in-progress\u0026#39;) { console.log(`Validation progress: ${data.progress}%`); } else if (data.status === \u0026#39;complete\u0026#39;) { console.log(data.message); socket.close(); } }; socket.onopen = function() { console.log(\u0026#39;Connected to the server\u0026#39;); // Simulating a music upload with a title and arbitrary size const musicData = { title: \u0026#39;My Awesome Track\u0026#39;, size: 1234 }; socket.send(JSON.stringify(musicData)); }; socket.onclose = function() { console.log(\u0026#39;Disconnected the WebSocket connection from the server\u0026#39;); }; Instruction Start the server by running node server.js\n1.1. Your terminal will display: Server running on http://localhost:2000 WebSocket server running on ws://localhost:2000 Open your browser and enter: http://localhost:2000\n2.1. Your browser will display: Hello world Open the browser console and run Client code\n3.1. Your terminal will first log: Client connected the WebSocket connection Received: {\u0026#34;title\u0026#34;:\u0026#34;My Awesome Track\u0026#34;,\u0026#34;size\u0026#34;:1234} 3.2. Then, your browser console will display: \u0026gt;\u0026gt; Connected to the server \u0026gt;\u0026gt; Validation progress: 18% \u0026gt;\u0026gt; Validation progress: 28% \u0026gt;\u0026gt; Validation progress: 39% \u0026gt;\u0026gt; Validation progress: 50% \u0026gt;\u0026gt; Validation progress: 65% \u0026gt;\u0026gt; Validation progress: 80% \u0026gt;\u0026gt; Validation progress: 97% \u0026gt;\u0026gt; Music validation complete and valid! \u0026gt;\u0026gt; Disconnected the WebSocket connection from the server Demo Server-sent events # Unidirectional communication Server code // server.js const http = require(\u0026#39;http\u0026#39;); const port = 2000; let currentProgress = 0; const server = http.createServer((req, res) =\u0026gt; { if (req.method === \u0026#39;GET\u0026#39; \u0026amp;\u0026amp; req.url === \u0026#39;/\u0026#39;) { res.writeHead(200, { \u0026#39;Content-Type\u0026#39;: \u0026#39;text/plain\u0026#39; }); res.end(\u0026#39;Hello, World!\u0026#39;); } else if (req.method === \u0026#39;POST\u0026#39; \u0026amp;\u0026amp; req.url === \u0026#39;/upload\u0026#39;) { let body = \u0026#39;\u0026#39;; req.on(\u0026#39;data\u0026#39;, chunk =\u0026gt; { body += chunk.toString(); }); req.on(\u0026#39;end\u0026#39;, () =\u0026gt; { console.log(\u0026#39;Received music data:\u0026#39;, body); currentProgress = 0; let interval = setInterval(() =\u0026gt; { currentProgress += Math.floor(Math.random() * 10) + 10; // Random progress between 10% - 20% if (currentProgress \u0026gt;= 100) { currentProgress = 100; clearInterval(interval); } }, 1000); res.writeHead(200, { \u0026#39;Content-Type\u0026#39;: \u0026#39;text/plain\u0026#39; }); res.end(\u0026#39;Music data received and processing started\u0026#39;); }); } else if (req.method === \u0026#39;GET\u0026#39; \u0026amp;\u0026amp; req.url === \u0026#39;/uploadprogress\u0026#39;) { // Set headers for SSE res.writeHead(200, { \u0026#39;Content-Type\u0026#39;: \u0026#39;text/event-stream\u0026#39;, \u0026#39;Cache-Control\u0026#39;: \u0026#39;no-cache\u0026#39;, \u0026#39;Connection\u0026#39;: \u0026#39;keep-alive\u0026#39; }); let interval = null; const sendProgress = () =\u0026gt; { if (currentProgress \u0026lt; 100) { res.write(`data: ${JSON.stringify({ status: \u0026#39;in-progress\u0026#39;, progress: currentProgress })}\\n\\n`); } else { res.write(`data: ${JSON.stringify({ status: \u0026#39;complete\u0026#39;, message: \u0026#39;Music validation complete and valid!\u0026#39; })}\\n\\n`); clearInterval(interval); res.end(); } }; interval = setInterval(sendProgress, 1000); } else { res.writeHead(404, { \u0026#39;Content-Type\u0026#39;: \u0026#39;text/plain\u0026#39; }); res.end(\u0026#39;Not Found\u0026#39;); } }); server.listen(port, () =\u0026gt; { console.log(`Server running on http://localhost:${port}`); }); Client code function uploadMusicData() { const musicData = { title: \u0026#39;My Awesome Track\u0026#39;, size: 1234 }; fetch(\u0026#39;http://localhost:2000/upload\u0026#39;, { method: \u0026#39;POST\u0026#39;, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39; }, body: JSON.stringify(musicData) }) .then(response =\u0026gt; response.text()) .then(data =\u0026gt; { console.log(data); // Create an EventSource connection to the server const eventSource = new EventSource(\u0026#39;http://localhost:2000/uploadprogress\u0026#39;); eventSource.onmessage = function(event) { const data = JSON.parse(event.data); if (data.status === \u0026#39;in-progress\u0026#39;) { console.log(`Validation progress: ${data.progress}%`); } else if (data.status === \u0026#39;complete\u0026#39;) { console.log(data.message); eventSource.close(); } }; eventSource.onopen = function() { console.log(\u0026#39;Connected to the server for progress updates\u0026#39;); }; }); } uploadMusicData(); Instruction Start the server by running node server.js\n1.1. Your terminal will display: Server running on http://localhost:2000 Open your browser and enter: http://localhost:2000\n2.1. Your browser will display: Hello world Open the browser console and run Client code\n3.1. Your terminal will first log: Received music data: {\u0026quot;title\u0026quot;:\u0026quot;My Awesome Track\u0026quot;,\u0026quot;size\u0026quot;:1234} 3.2. Then, your browser console will display: \u0026gt;\u0026gt; Music data received and processing started \u0026gt;\u0026gt; Connected to the server for progress updates \u0026gt;\u0026gt; Validation progress: 18% \u0026gt;\u0026gt; Validation progress: 28% \u0026gt;\u0026gt; Validation progress: 39% \u0026gt;\u0026gt; Validation progress: 50% \u0026gt;\u0026gt; Validation progress: 65% \u0026gt;\u0026gt; Validation progress: 80% \u0026gt;\u0026gt; Validation progress: 97% \u0026gt;\u0026gt; Music validation complete and valid! Publish-Subcribe # Also known as Message Queue Design Pattern Used in microservices architectures RabbitMQ # Producer sends and monitors if the message reaches the intended consumer Designed for complex message routing Support message priorities Messages are deleted once consumed Kafka # Consumers keep track of message retrieval with an offset tracker Retain messages according to the retention policy There‚Äôs no message priority Reference # Freecodecamp: Communication Design Patterns for Backend Development (Sep 12th, 2023) Udemy: Fundamentals of Backend Engineering (Feb, 2024) Linkedin: Understanding Short Polling: A Simple Backend Communication Pattern (Aug 7th, 2024) Stackoverflow: WebSockets vs. Server-Sent events/EventSource (Mar 16th, 2011) Amazon: Message Queues Amazon: What‚Äôs the Difference Between Kafka and RabbitMQ? Help improve my blog Was this page helpful to you?\nüëç Yes üëé No This page was last modified at 2023-11-15\nView this page on GitHub Report a problem with this content Can I know your name? Yes No "},{"id":2,"href":"/docs/research/process_vs_thread/","title":"Process vs Thread","section":"RESEARCH","content":" Process vs Thread # Program # A Program is an executable file containing a set of instructions and passively stored on disk\nProcess # A Process means a program is in execution. When a program is loaded into the memory and becomes active, the program becomes a process or processes\nThread # A Thread is the smallest unit of execution within a process\nProcess vs Thread # Process # The process requires some essential resources such as registers, program counter, and stack\nEach process has its own memory address space. One process can not corrupt the memory address space of another process. This means that when one process malfunctions, other processes keep running\nThread # A process has at least one thread. It‚Äôs called the main thread. It‚Äôs not uncommon for a process to have many threads\nEach thread has its own stack. Earlier we mentioned registers, program counters and stack pointers as being part of a process. It‚Äôs more accurate to say that those things belong to a thread\nThreads within a process share a memory address space It‚Äôs possible to communicate between threads using that shared memory space However, one misbehaving thread could bring down the entire process\nCode demo # When one process malfunctions, other processes keep running Nodejs\nconst cluster = require(\u0026#34;cluster\u0026#34;); if (cluster.isMaster) { // Master process logic console.log(\u0026#34;Master process\u0026#34;, process.pid, \u0026#34;is running\u0026#34;); const normalSlave = cluster.fork(); const misbehavingSlave = cluster.fork(); misbehavingSlave.send({ isNormal: false }); normalSlave.send({ isNormal: true }); setInterval(() =\u0026gt; { console.log(\u0026#34;Master process\u0026#34;, process.pid, \u0026#34;is doing some work.\u0026#34;); }, 300); } else { // Slave process logic console.log(\u0026#34;Slave process\u0026#34;, process.pid, \u0026#34;is running\u0026#34;); process.on(\u0026#34;message\u0026#34;, ({ isNormal }) =\u0026gt; { if (isNormal) { setInterval(() =\u0026gt; { console.log(\u0026#34;Slave process\u0026#34;, process.pid, \u0026#34;is doing some work.\u0026#34;); }, 300); } else { setTimeout(() =\u0026gt; { throw new Error(\u0026#34;Slave process \u0026#34; + process.pid + \u0026#34; is corrupted!!!\u0026#34;); }, 2000); } }); } One misbehaving thread could bring down the entire process Nodejs\nconst { Worker } = require(\u0026#34;worker_threads\u0026#34;); console.log(\u0026#34;Process\u0026#34;, process.pid, \u0026#34;starts\u0026#34;); // Create a misbehaving worker thread const misbehavingWorker = new Worker( ` const { threadId } = require(\u0026#39;worker_threads\u0026#39;); console.log(\u0026#39;Thread\u0026#39;, threadId, \u0026#39;from process\u0026#39;, process.pid, \u0026#39;starts\u0026#39;); // Intentionally cause an unhandled exception setTimeout(() =\u0026gt; { throw new Error(\u0026#39;Thread \u0026#39; + threadId + \u0026#39; is corrupted!!!\u0026#39;); }, 2000); `, { eval: true } ); // Create a normal worker thread const normalWorker = new Worker( ` const { threadId } = require(\u0026#39;worker_threads\u0026#39;); console.log(\u0026#39;Thread\u0026#39;, threadId, \u0026#39;from process\u0026#39;, process.pid, \u0026#39;starts\u0026#39;); // Simulate normal work setInterval(() =\u0026gt; { console.log(\u0026#39;Thread\u0026#39;, threadId, \u0026#39;is doing some work.\u0026#39;); }, 300); `, { eval: true } ); Multithreading and Multiprocessing # Concurrency and Parallelism # Concurrency allows multiple tasks to make progress by interleaving their execution, even if they are not executing simultaneously. It is focused on efficient task scheduling and resource utilization\nParallelism involves executing multiple tasks simultaneously, typically on separate processing units or cores. It aims to achieve higher performance and faster task completion\nMultithreading # Multithreading focuses on generating computing threads from a single process, whereas multiprocessing increases computing power by adding processors\nMultiprocessing # Multiprocessing uses two or more processors to increase computing power, whereas multithreading uses a single process with multiple code segments to increase computing power\nCode demo # Prepared files Nodejs\nk.js\nconst CPUS = require(\u0026#34;os\u0026#34;).cpus(); const NUM_CPU = CPUS.length; const TOTAL_OBJS = 10000000; const numWorkers = NUM_CPU; const workload = TOTAL_OBJS / numWorkers; module.exports = { CPUS, NUM_CPU, TOTAL_OBJS, numWorkers, workload, }; _.js\nconst generateRandomName = () =\u0026gt; { const names = [ \u0026#34;Alice\u0026#34;, \u0026#34;Bob\u0026#34;, \u0026#34;Charlie\u0026#34;, \u0026#34;David\u0026#34;, \u0026#34;Eve\u0026#34;, \u0026#34;Frank\u0026#34;, \u0026#34;Grace\u0026#34;, \u0026#34;Henry\u0026#34;, \u0026#34;Ivy\u0026#34;, \u0026#34;Jack\u0026#34;, ]; return names[Math.floor(Math.random() * names.length)]; }; const generateRandomAge = () =\u0026gt; { return Math.floor(Math.random() * 100) + 1; }; const generateObjects = (count) =\u0026gt; { const objects = []; for (let i = 0; i \u0026lt; count; i++) { const object = { name: generateRandomName(), age: generateRandomAge(), createTime: new Date(), }; objects.push(object); } return objects; }; class Logger { constructor(isEnable) { this.isEnable = !!isEnable; } isDebug = false; logP1(...args) { if (this.isEnable) { console.log(...args); } } debug(...args) { if (this.isDebug \u0026amp;\u0026amp; this.isEnable) { console.log(...args); } } } const ts = () =\u0026gt; new Date().getTime(); class Monitor { startTime; endTime; start() { this.startTime = ts(); } end() { this.endTime = ts(); } getTotal() { return this.endTime - this.startTime; } } module.exports = { Logger, Monitor, generateObjects, }; worker.js\nconst { generateObjects, Monitor, Logger } = require(\u0026#34;../_\u0026#34;); const { workerData, parentPort, threadId } = require(\u0026#34;worker_threads\u0026#34;); const monitor = new Monitor(); const logger = new Logger(true); const { workload, isDebug } = workerData; logger.isDebug = isDebug; logger.debug(\u0026#34;Worker\u0026#34;, threadId, \u0026#34;of process\u0026#34;, process.pid, \u0026#34;is running\u0026#34;); monitor.start(); const objects = generateObjects(workload); monitor.end(); logger.debug( \u0026#34;Worker\u0026#34;, threadId, \u0026#34;generated\u0026#34;, objects.length, \u0026#34;in\u0026#34;, monitor.getTotal(), \u0026#34;ms\u0026#34; ); monitor.start(); parentPort.postMessage(objects); monitor.end(); logger.debug(\u0026#34;worker\u0026#34;, threadId, \u0026#34;send data in\u0026#34;, monitor.getTotal(), \u0026#34;ms\u0026#34;); Single thread vs multithreading vs multiprocessing Nodejs\nsingleThread.js\nconst { TOTAL_OBJS } = require(\u0026#34;../k\u0026#34;); const { generateObjects, Monitor } = require(\u0026#34;../_\u0026#34;); const monitor = new Monitor(); monitor.start(); const obj = generateObjects(TOTAL_OBJS); monitor.end(); console.log(\u0026#34;Generate\u0026#34;, obj.length, \u0026#34;in\u0026#34;, monitor.getTotal(), \u0026#34;ms\u0026#34;); multithread.js\nconst { Worker } = require(\u0026#34;worker_threads\u0026#34;); const { numWorkers, workload, TOTAL_OBJS } = require(\u0026#34;../k\u0026#34;); const { Monitor, Logger } = require(\u0026#34;../_\u0026#34;); let generatedObjects = []; const monitor = new Monitor(); const logger = new Logger(true); // set true to see more logs logger.isDebug = true; function runWorker(workerData) { return new Promise((resolve, reject) =\u0026gt; { const worker = new Worker(\u0026#34;./worker_threads/worker.js\u0026#34;, { workerData }); logger.debug(\u0026#34;Worker\u0026#34;, worker.threadId, \u0026#34;is running\u0026#34;); worker.on(\u0026#34;message\u0026#34;, (message) =\u0026gt; { generatedObjects = generatedObjects.concat(message); }); worker.on(\u0026#34;error\u0026#34;, reject); worker.on(\u0026#34;exit\u0026#34;, (code) =\u0026gt; { if (code === 0) { resolve(); } else { reject(new Error(`Worker stopped with exit code ${code}`)); } }); }); } async function generateObjectsWithWorkers() { const workers = []; monitor.start(); for (let i = 0; i \u0026lt; numWorkers; i++) { const workerData = { workload, isDebug: logger.isDebug, }; workers.push(runWorker(workerData)); } await Promise.all(workers); monitor.end(); logger.logP1( \u0026#34;All done!\u0026#34;, numWorkers, \u0026#34;workers,\u0026#34;, generatedObjects.length, \u0026#34;objects, in\u0026#34;, monitor.getTotal(), \u0026#34;ms\u0026#34; ); } generateObjectsWithWorkers(); multiprocess.js\nconst cluster = require(\u0026#34;cluster\u0026#34;); const { workload, numWorkers } = require(\u0026#34;../k\u0026#34;); const { Monitor, Logger, generateObjects } = require(\u0026#34;../_\u0026#34;); const logger = new Logger(true); const monitor = new Monitor(); // set true to see more logs logger.isDebug = true; if (cluster.isMaster) { monitor.start(); logger.logP1(\u0026#34;Master\u0026#34;, process.pid, \u0026#34;is running\u0026#34;); // Fork slaves for (let i = 0; i \u0026lt; numWorkers; i++) { cluster.fork(); } // Collect data from slaves let generatedObjects = []; cluster.on(\u0026#34;message\u0026#34;, (slave, message) =\u0026gt; { generatedObjects = generatedObjects.concat(message); }); // Wait for all workers to finish logic let slaveOff = 0; cluster.on(\u0026#34;disconnect\u0026#34;, () =\u0026gt; { slaveOff++; if (slaveOff === numWorkers) { monitor.end(); logger.logP1( \u0026#34;All done!\u0026#34;, slaveOff, \u0026#34;slaves, in\u0026#34;, monitor.getTotal(), \u0026#34;ms\u0026#34; ); // Exit the application process.exit(0); } }); } else { // Slave process logic logger.debug(\u0026#34;Slave\u0026#34;, process.pid, \u0026#34;is running\u0026#34;); let generatedObjects = []; // Generate objects in the worker process monitor.start(); const objects = generateObjects(workload); monitor.end(); generatedObjects = generatedObjects.concat(objects); logger.debug( \u0026#34;Generated\u0026#34;, objects.length, \u0026#34;objects in slave\u0026#34;, process.pid, \u0026#34;in\u0026#34;, monitor.getTotal(), \u0026#34;ms\u0026#34; ); // Send objects to the master process monitor.start(); process.send(objects); monitor.end(); logger.debug(\u0026#34;slave\u0026#34;, process.pid, \u0026#34;send data in\u0026#34;, monitor.getTotal(), \u0026#34;ms\u0026#34;); // Disconnect the slave process cluster.worker.disconnect(); } Time-consuming when not communication together Time-consuming when running multiple threads and multiple processes without communication together meaning each item runs separately and does not share data\nNodejs\n// TODO: update guideline how it work and how it look (htop) Time-consuming when communication together Time-consuming when running multiple threads and multiple processes within communication together meaning each item runs separately but shares data with the main item\nNodejs\nContext switching # How does the OS run threads or processes on a CPU (processor) ? =\u0026gt; This is handled by context switching During a context switch, one process is switched out of the CPU (processor) so another process can run\nThe OS stores the states of the current running process so the process can be restored and resume execution at a later point\nIt then restores the previously saved states of a different process and resumes execution for that process\nContext switching is expensive. It involves saving and loading registers, switching out memory pages, and updating various kernel data structures\nSwitching execution between threads also requires context switching\nIt‚Äôs generally faster to switch context between threads than between processes\nThere are fewer states to track, and more importantly, since threads share the same memory address space, there is no need to switch out virtual memory pages which is one of the most expensive operations during a context switch\nContext switching is so costly, there are other mechanisms to try to minimize it. Some examples are fibers and coroutines\nThese mechanisms trade complexity for even lower context-switching costs\nIn general, they are cooperatively scheduled, that is, they must yield control for others to run\nIn other words, the application itself handles task scheduling\nIt‚Äôs the responsibility of the application to make sure a long-running task is broken up by yielding periodically\nConclusion # Program, process, and thread:\nThe program contains a set of instructions The program is loaded into memory. It becomes one or more running processes. When a process starts, it is assigned memory and resources The thread is the smallest unit of execution within a process. A process can have one or more threads If we can ideally run each thread on each idle core, we can actually run parallelism all jobs we want with the shortest time consuming\nThe cost when sharing data between threads and processes is also expensive, processes are more expensive than threads because threads inside the process use together shared memory address space\nContext-switching will appear when the scheduler of OS assigns one logical processor more than one thread or process that needs to run. Context-switching is expensive\nAppendix # Processor definition # There are 2 definitions of the term Processor that can lead you to confusion when researching\nLet‚Äôs devine it into 2 names:\nPhysical processor: means processor definition in the hardware world Logical processor: means processor definition in the software world Physical processor # A processor in this context means the entire CPU chip as the Intel define\nThis image is the complexity of a modern multi-processor, multi-core system Logical processor # A processor in this context means a virtual core:\nCPU has 8 cores CPU has hyperthreading and it is enabled so each core split into 2 virtual cores Virtual memory # A computer can address more memory than the amount physically installed on the system. This extra memory is actually called virtual memory and it is a section of a hard disk that\u0026rsquo;s set up to emulate the computer\u0026rsquo;s RAM\nHyper-threading # Intel¬Æ Hyper-Threading Technology is a hardware innovation that allows more than one thread to run on each core. More threads means more work can be done in parallel\nHow does Hyper-Threading work? When Intel¬Æ Hyper-Threading Technology is active, the CPU exposes two execution contexts per physical core. This means that one physical core now works like two ‚Äúlogical cores‚Äù that can handle different software threads\nReference # Bytebytego: Interview question: Design Twitter (Episode 5) Bytebytego: FANG Interview Question | Process vs Thread Intel: A Better Way to Measure CPU Utilization Medium: Achieving concurrency in Go Stackoverflow: What are the differences between multi-CPU, multi-core and hyper-thread? Tutorialspoint: Operating System - Virtual Memory Wikipedia: Virtual memory Intel: What Is Hyper-Threading? Geeksforgeeks: Difference between User Level thread and Kernel Level thread Geeksforgeeks: Difference between MultiCore and MultiProcessor System Indeed: Multithreading vs. Multiprocessing: What\u0026rsquo;s the Difference? Scaler: Difference Between Multicore and Multiprocessor System Superuser: What\u0026rsquo;s the difference between a multiprocessor and a multiprocessing system? Superuser: What\u0026rsquo;s the difference between multicore proccesor and multiproccess system? Help improve my blog Was this page helpful to you?\nüëç Yes üëé No This page was last modified at 2023-12-05\nView this page on GitHub Report a problem with this content Can I know your name? Yes No "},{"id":3,"href":"/docs/research/chrome_architecture/","title":"Chrome Architecture","section":"RESEARCH","content":" Chrome Architecture # Prerequisites # Read process vs thread first if you don\u0026rsquo;t have any process and thread concept in your mind\nBrowser Architecture # When you start an application, a process is created. The program might create thread(s) to help it do work, but that\u0026rsquo;s optional. The Operating System gives the process a \u0026ldquo;slab\u0026rdquo; of memory to work with and all application state is kept in that private memory space. When you close the application, the process also goes away and the Operating System frees up the memory\nA process can ask the Operating System to spin up another process to run different tasks. When this happens, different parts of the memory are allocated for the new process. If two processes need to talk, they can do so by using Inter Process Communication (IPC). Many applications are designed to work this way so that if a worker process get unresponsive, it can be restarted without stopping other processes which are running different parts of the application\nThere is no standard specification on how one might build a web browser. One browser‚Äôs approach may be completely different from another\nChrome uses a separate content process and engine for each website instance, but Firefox reuses processes and engines to limit memory usage\nProcess What it controls? Browser Controls \u0026ldquo;chrome\u0026rdquo; part of the application including address bar, bookmarks, back and forward buttons. Also handles the invisible, privileged parts of a web browser such as network requests and file access Renderer Controls anything inside of the tab where a website is displayed Plugin Controls any plugins used by the website, for example, flash GPU Handles GPU tasks in isolation from other processes. It is separated into different process because GPUs handles requests from multiple apps and draw them in the same surface There are even more processes like the Extension process and utility processes. If you want to see how many processes are running in your Chrome, click the options menu icon more_vert at the top right corner, select More Tools, then select Task Manager. This opens up a window with a list of processes that are currently running and how much CPU/Memory they are using.\nFor the renderer process, multiple processes are created and assigned to each tab. Until very recently, Chrome gave each tab a process when it could; now it tries to give each site its own process, including iframes\nBrowser process # Thread Mission UI Draws buttons and input fields of the browser Network Deals with network stack to receive data from the internet Storage Controls access to the files and more Renderer process # The renderer process is responsible for everything that happens inside of a tab\nThread Mission Main The main thread handles most of the code you send to the user Worker Sometimes parts of your JavaScript is handled by worker threads if you use a web worker or a service worker Compositor and Raster Compositor and raster threads are also run inside of a renderer processes to render a page efficiently and smoothly The renderer process\u0026rsquo;s core job is to turn HTML, CSS, and JavaScript into a web page that the user can interact with\nMain thread # Pharse Job Visual Parsing When the renderer process starts to receive HTML data, the main thread begins to parse the text string (HTML) and turn it into a Document Object Model (DOM) Style calculation The main thread parses CSS and determines the computed style for each DOM node. This is information about what kind of style is applied to each element based on CSS selectors Layout The layout is a process to find the geometry of elements. The main thread walks through the DOM and computed styles and creates the layout tree which has information like x y coordinates and bounding box sizes. Layout tree may be similar structure to the DOM tree, but it only contains information related to what\u0026rsquo;s visible on the page Paint The main thread walks the layout tree to create paint records. Paint record is a note of painting process like \u0026ldquo;background first, then text, then rectangle\u0026rdquo; A website usually uses external resources like images, CSS, and JavaScript. Those files need to be loaded from network or cache. The main thread could request them one by one as they find them while parsing to build a DOM, but in order to speed up, \u0026ldquo;preload scanner\u0026rdquo; is run concurrently.\nWhen the HTML parser finds a \u0026lt;script\u0026gt; tag, it pauses the parsing of the HTML document and has to load, parse, and execute the JavaScript code\nWhy? Because JavaScript can change the shape of the document using things like document.write() which changes the entire DOM structure\nThe browser then loads and runs the JavaScript code asynchronously and does not block the parsing. You may also use JavaScript module if that\u0026rsquo;s suitable. \u0026lt;link rel=\u0026quot;preload\u0026quot;\u0026gt; is a way to inform browser that the resource is definitely needed for current navigation and you would like to download as soon as possible. You can read more on this at Resource Prioritization\nJavaScript # JavaScript, as you may already know, is single threaded, hence you can‚Äôt spawn new threads as you like to spread your computation cost over multiple CPU‚Äôs core for true-parallel work\nWhen your code is executed it may call the Browser‚Äôs APIs to interact with the DOM or schedule some async task. Those async tasks are added to the Event queue or to the prioritized Job queue (if using Promises). As soon as the the Call Stack has finished to process the current tick (is empty), the Event Loop feeds it with a new Tick (which is composed by ONE callback, the FULL job queue, and the POSSIBILITY to call, fully or only some parts, the Render queue)\nCall Stack: it is the place where your code is executed (your functions are loaded and executed, V8 engine in Chrome and NodeJS), it is basically a LIFO stack (last-in-first-out), when it is empty, a.k.a. has completed all the current Tick tasks, it becomes ready to accept the next Tick from the Event Loop Browser APIs: a link between your code and the browser‚Äôs internals to schedule tasks, interact with the DOM and more (ex. setTimeout, AJAX, createElement, querySelector, append, click, etc.). In case of callbacks they will add your callback code to the Event queue, instead, in case of a then (promise‚Äôs method), your then-code will be added to the Job Queue Event queue: every time you add a callback (ex. via the setTimeout or the AJAX APIs), it is added to this queue Job queue: this queue is reserved for promise‚Äôs thens, it is a prioritized queue, its meaning is like ‚Äòexecute this code later (= asynchronously), but as soon as possible! (= before the next Event Loop tick)‚Äô, and this is why browsers had introduced this new queue to fulfil the Promises specifications Render queue: this is explained in another article Next Tick: it is what will be executed next, basically it‚Äôs composed by ONE callback from the Event queue, THE FULL Job queue (this point is important, the current tick will finish only after the Job queue is empty, so you may inadvertently block it from going to the next Tick if you continuously add new jobs to this queue), may re-render (execute the necessary steps in the Render queue to update the screen) Event Loop: it monitors the Call Stack, as soon as it is empty (has finished to process the current tick), the Event Loop feeds it with the next Tick Along the main thread there are many other threads spawned by the browser to do useful stuff:\nParser Thread: parses your code in machine-understandable trees Statistics collector Thread: collects data and statistics to discover insights about your code (the scope is to optimize it runtime) Optimizer Thread: uses the statistics and insights collected by the Statistics collector Thread to make performance optimizations over your code (Caching, Inlining, etc.) Garbage Collector Thread: removes unconnected (no more referenceable from the ROOT node) JavaScript objects to free up memory using a mark-and-sweep algorithm. We don‚Äôt know when this will happen and have no control over it. AFAIK the browser uses this thread to track whose objects to remove and do useful stuff, but when it needs to remove them it actually blocks the main thread and uses it. From the Firefox blog Q:‚ÄùSilly question here, why must garbage collection stop UI events and js execution? Couldn‚Äôt the GC just run in a separate thread?‚Äù, R:‚ÄùIt can be done, but the garbage collector is looking at the same objects that the JS currently running is touching, so it must be done carefully. That said, the Firefox GC actually does do some work on a separate thread: some types of objects can be thrown away once they are known to be garbage without affecting the main thread.‚Äù Rasterizer Thread: rasterize your graphic into frames Etc Appendix # Input events # The browser process is only aware of where that gesture occurred since content inside of a tab is handled by the renderer process. So the browser process sends the event type (like touchstart) and its coordinates to the renderer process\nRenderer process handles the event appropriately by finding the event target and running event listeners that are attached\nInput event routed through the browser process to the renderer process\nIf no input event listeners are attached to the page, Compositor thread can create a new composite frame completely independent of the main thread. But what if some event listeners were attached to the page? How would the compositor thread find out if the event needs to be handled?\n‚ÄúNon-fast scrollable region‚Äù # Since running JavaScript is the main thread\u0026rsquo;s job, when a page is composited, the compositor thread marks a region of the page that has event handlers attached as \u0026ldquo;Non-Fast Scrollable Region\u0026rdquo;\nBy having this information, the compositor thread can make sure to send input event to the main thread if the event occurs in that region. If input event comes from outside of this region, then the compositor thread carries on compositing new frame without waiting for the main thread\nReference # Chrome: Inside look at modern web browser (part 1) (2018 Sep 21) Chrome: Inside look at modern web browser (part 2) (2018 Sep 21) Chrome: Inside look at modern web browser (part 3) (2020 Aug 18) Chrome: Inside look at modern web browser (part 4) (2019 Jan 12) Gitconnected: How web browsers use processes and threads (2020 Jul 17) Medium: Javascript main thread dissected (2017 Nov 13) V8: JavaScript modules (2018 Jun 18) Help improve my blog Was this page helpful to you?\nüëç Yes üëé No This page was last modified at 2023-12-05\nView this page on GitHub Report a problem with this content Can I know your name? Yes No "},{"id":4,"href":"/docs/research/aws_overview/","title":"AWS Overview","section":"RESEARCH","content":" AWS Overview # Ref: Slide # Types of Cloud Computing # EC2 - Elastic Compute Cloud # EC2 = Infrastructure as a Service (IaaS) On-Demand Instances ‚Äì short workload, predictable pricing, pay by second Has the highest cost Recommended for short-term and un-interrupted workloads, where you can\u0026rsquo;t predict how the application will behave Reserved (1 \u0026amp; 3 years) Reserved Instances ‚Äì long workloads Recommended for steady-state usage applications (think database) Convertible Reserved Instances ‚Äì long workloads with flexible instances Savings Plans (1 \u0026amp; 3 years) ‚Äì commitment to an amount of usage, long workload Spot Instances ‚Äì short workloads, cheap, can lose instances (less reliable) The MOST cost-efficient Dedicated Hosts ‚Äì book an entire physical server, control instance placement The most expensive option Dedicated Instances ‚Äì no other customers will share your hardware No control over instance placement Capacity Reservations ‚Äì reserve capacity in a specific AZ for any duration AMI - Amazon Machine Image # AMI are a customization of an EC2 instance AMI are built for a specific region (and can be copied across regions) You can launch EC2 instances from: A Public AMI: AWS provided Your own AMI: you make and maintain them yourself An AWS Marketplace AMI: an AMI someone else made (and potentially sells) EC2 Image Builder # Used to automate the creation of Virtual Machines or container images\n=\u0026gt; Automate the creation, maintain, validate and test EC2 AMIs Can be run on a schedule (weekly, whenever packages are updated, etc‚Ä¶) Free service (only pay for the underlying resources) EBS - Elastic Block Store # A network drive you can attach to your instances while they run It allows your instances to persist data, even after their termination They can only be mounted to one instance at a time They are bound to a specific AZ Think of them as a ‚Äúnetwork USB stick‚Äù\nSnapshots # Make a backup (snapshot) of your EBS volume at a point in time Can copy snapshots across AZ or Region Snapshots Features # Snapshot Archive Move a Snapshot to an ‚Äùarchive tier‚Äù that is 75% cheaper Takes within 24 to 72 hours for restoring the archive Recycle Bin for EBS Snapshots Setup rules to retain deleted snapshots so you can recover them after an accidental deletion Specify retention (from 1 day to 1 year) EC2 Instance Store # If you need a high-performance hardware disk, use EC2 Instance Store Better I/O performance EC2 Instance Store lose their storage if they‚Äôre stopped (ephemeral) Good for buffer / cache / scratch data / temporary content Risk of data loss if hardware fails Backups and Replication are your responsibility EFS - Elastic File System # Managed NFS (network file system) that can be mounted on 100s of EC2 EFS works with Linux EC2 instances in multi-AZ Highly available, scalable, expensive (3x gp2), pay per use, no capacity planning EFS IA - EFS Infrequent Access # Storage class that is cost-optimized for files not accessed every day EFS will automatically move your files to EFS-IA based on the last time they were accessed Enable EFS-IA with a Lifecycle Policy FSx # for Windows File Server # A fully managed, highly reliable, and scalable Windows native shared file system Built on Windows File Server Supports SMB protocol \u0026amp; Windows NTFS Integrated with Microsoft Active Directory Can be accessed from AWS or your on-premise infrastructure for Lustre # A fully managed, high-performance, scalable file storage for High Performance Computing (HPC) The name Lustre is derived from ‚ÄúLinux‚Äù and ‚Äúcluster‚Äù Machine Learning, Analytics, Video Processing, Financial Modeling, ‚Ä¶ S3 # \u0026ldquo;infinitely scaling\u0026rdquo; storage Buckets # Allows people to store objects (files) in buckets (directories) Buckets must have a globally unique name (across all regions all accounts) Buckets are defined at the region level Naming convention No uppercase, No underscore 3-63 characters long Not an IP Must start with lowercase letter or number Must NOT start with the prefix xn\u0026ndash; Must NOT end with the suffix -s3alias Objects # Objects (files) have a Key The key is the FULL path: s3://my-bucket/my_file.txt s3://my-bucket/my_folder1/another_folder/my_file.txt The key is composed of prefix + object name s3://my-bucket/my_folder1/another_folder/my_file.txt There‚Äôs no concept of ‚Äúdirectories‚Äù within buckets\n(although the UI will trick you to think otherwise) Just keys with very long names that contain slashes (‚Äú/‚Äù) Object values are the content of the body: Max. Object Size is 5TB (5000GB) If uploading more than 5GB, must use ‚Äúmulti-part upload‚Äù Security # User-Based IAM Policies ‚Äì which API calls should be allowed for a specific user from IAM Resource-Based Bucket Policies ‚Äì bucket wide rules from the S3 console - allows cross account Object Access Control List (ACL) ‚Äì finer grain (can be disabled) Bucket Access Control List (ACL) ‚Äì less common (can be disabled) Static Website Hosting # S3 can host static websites and have them accessible on the Internet The website URL will be (depending on the region) http :// bucket-name .s3-website-aws-region.amazonaws.com\nOR http :// bucket-name .s3-website.aws-region.amazonaws.com If you get a 403 Forbidden error, make sure the bucket policy allows public reads! Versioning # It is enabled at the bucket level It is best practice to version your buckets Protect against unintended deletes (ability to restore a version) Easy roll back to previous version Notes: Any file that is not versioned prior to enabling versioning will have version ‚Äúnull‚Äù Suspending versioning does not delete the previous versions Replication # Must enable Versioning in source and destination buckets Cross-Region Replication (CRR) Same-Region Replication (SRR) Buckets can be in different AWS accounts Copying is asynchronous Must give proper IAM permissions to S3 Use cases: CRR ‚Äì compliance, lower latency access, replication across accounts SRR ‚Äì log aggregation, live replication between production and test accounts Storage Classes # Amazon S3 Standard - General Purpose Used for frequently accessed data Use Cases: Big Data analytics, mobile \u0026amp; gaming applications, content distribution Amazon S3 Standard-Infrequent Access (IA) For data that is less frequently accessed, but requires rapid access when needed Use cases: Disaster Recovery, backups Amazon S3 One Zone-Infrequent Access For data that is less frequently accessed, but requires rapid access when needed In a single AZ; data lost when AZ is destroyed Use Cases: Storing secondary backup copies of on-premise data, or data you can recreate Amazon S3 Glacier Instant Retrieval For data accessed once a quarter Millisecond retrieval Amazon S3 Glacier Flexible Retrieval (formerly Amazon S3 Glacier) Retrieval: Expedited (1 to 5 minutes), Standard (3 to 5 hours), Bulk (5 to 12 hours) ‚Äì free Amazon S3 Glacier Deep Archive For long term storage Retrieval: Standard (12 hours), Bulk (48 hours) Amazon S3 Intelligent Tiering\nMoves objects automatically between Access Tiers based on usage Frequent Access tier (automatic): default tier Infrequent Access tier (automatic): objects not accessed for 30 days Archive Instant Access tier (automatic): objects not accessed for 90 days Archive Access tier (optional): configurable from 90 days to 700+ days Deep Archive Access tier (optional): config. from 180 days to 700+ days Encryption # IAM Access Analyzer # Ensures that only intended people have access to your S3 buckets Example: publicly accessible bucket, bucket shared with other AWS account‚Ä¶ Evaluates S3 Bucket Policies, S3 ACLs, S3 Access Point Policies Powered by IAM Access Analyzer Snow Family # Highly-secure, portable devices to collect and process data at the edge, and migrate data into and out of AWS Data migration: Snowcone, Snowball Edge, Snowmobile Edge computing: Snowcone, Snowball Edge OpsHub # A software you install on your computer / laptop To manage your Snow Family Device Transferring files Launch compatible AWS services on your devices (ex: Amazon EC2 instances, AWS DataSync, Network File System (NFS)) Storage Gateway # Bridge between on-premise data and cloud data in S3 Hybrid storage service to allow on-premises to seamlessly use the AWS Cloud Use cases: disaster recovery, backup \u0026amp; restore, tiered storage Monitoring # CloudWatch: Metrics: monitor the performance of AWS services and billing metrics Alarms: automate notification, perform EC2 action, notify to SNS based on metric Logs: collect log files from EC2 instances, servers, Lambda functions‚Ä¶ Events (or EventBridge): react to events in AWS, or trigger a rule on a schedule CloudTrail: audit API calls made within your AWS account CloudTrail Insights: automated analysis of your CloudTrail Events X-Ray: trace requests made through your distributed applications AWS Health Dashboard: status of all AWS services across all regions AWS Account Health Dashboard: AWS events that impact your infrastructure Amazon CodeGuru: automated code reviews and application performance recommendations ECS - Elastic Container Service # You must provision \u0026amp; maintain the infrastructure (the EC2 instances) Fargate # You do not provision the infrastructure (no EC2 instances to manage) ‚Äì simpler! Serverless offering ECR - Elastic Container Registry # Store your Docker images Lambda # Virtual functions ‚Äì no servers to manage! Limited by time - short executions Run on-demand Scaling is automated! Event-Driven: functions get invoked by AWS when needed Pricing # Pay per calls Pay per duration Example # Serverless Thumbnail creation\nServerless CRON Job\nAPI Gateway # Serverless and scalable Supports RESTful APIs and WebSocket APIs Support for security, user authentication, API throttling, API keys, monitoring\u0026hellip; Batch # Fully managed batch processing at any scale Batch will dynamically launch EC2 instances or Spot Instances Batch jobs are defined as Docker images and run on ECS Batch vs Lambda # Lambda\nTime limit Limited runtimes Limited temporary disk space Serverless Batch\nNo time limit Any runtime as long as it‚Äôs packaged as a Docker image Rely on EBS / instance store for disk space Relies on EC2 (can be managed by AWS) Lightsail # Simpler alternative to using EC2, RDS, ELB, EBS, Route 53 Great for people with little cloud experience! \u0026ldquo;almost always be a wrong answer\u0026rdquo; CloudFormation # Infrastructure as code\nWithin a CloudFormation template, you say:\nI want a security group I want two EC2 instances using this security group I want an S3 bucket I want a load balancer (ELB) in front of these machines Then CloudFormation creates those for you, in the right order, with the exact configuration that you specify\nCDK - Cloud Development Kit # Define your cloud infrastructure using a familiar language: JavaScript, Python, \u0026hellip; You can use for loop to create multiple instances The code is ‚Äúcompiled‚Äù into a CloudFormation template (JSON/YAML) You can therefore deploy infrastructure and application runtime code together Elastic Beanstalk # Overview # A developer centric view of deploying an application on AWS It uses all the component‚Äôs we‚Äôve seen before: EC2, ASG, ELB, RDS, etc Beanstalk = Platform as a Service (PaaS) Beanstalk is free but you pay for the underlying instances Just the application code is the responsibility of the developer Three architecture models: Single Instance deployment: good for dev LB + ASG: great for production or pre-production web applications ASG only: great for non-web apps in production (workers, etc..) Health Monitoring # Health agent pushes metrics to CloudWatch Checks for app health, publishes health events CodeDeploy # We want to deploy our application automatically Works with EC2 Instances Works with On-Premises Servers Hybrid service Servers / Instances must be provisioned and configured ahead of time with the CodeDeploy Agent CodeCommit # Like GitHub Developers usually store code in a repository, using the Git technology CodeBuild # Compiles source code, run tests, and produces packages that are ready to be deployed (by CodeDeploy for example) Pay-as-you-go pricing - only pay for the build time CodePipeline # Orchestrate the different steps to have the code automatically pushed to production Code =\u0026gt; Build =\u0026gt; Test =\u0026gt; Provision =\u0026gt; Deploy Basis for CICD (Continuous Integration \u0026amp; Continuous Delivery) CodeArtifact # Software packages depend on each other to be built (also called code dependencies), and new ones are created Storing and retrieving these dependencies is called artifact management Developers and CodeBuild can then retrieve dependencies straight from CodeArtifact CodeStar # Unified UI Set-up CodeCommit, CodePipeline, CodeBuild, CodeDeploy, Elastic Beanstalk, EC2, etc Cloud9 # A cloud IDE Allows for code collaboration in real-time (pair programming) SSM - Systems Manager # Manage your EC2 and On-Premises Hybrid AWS service Session Manager # Allows you to start a secure shell on your EC2 and on-premises servers No SSH access, bastion hosts, or SSH keys needed No port 22 needed (better security) Supports Linux, macOS, and Windows Send session log data to S3 or CloudWatch Logs Parameter Store # Secure storage for configuration and secrets API Keys, passwords, configurations‚Ä¶ Serverless, scalable, durable, easy SDK Control access permissions using IAM Version tracking \u0026amp; encryption (optional) OpsWorks # AWS OpsWorks = Managed Chef \u0026amp; Puppet Chef \u0026amp; Puppet (2 tools not created by AWS) help you perform server configuration automatically, or repetitive actions Route 53 - DNS # Route53 is a Managed DNS (Domain Name System) DNS is a collection of rules and records which helps clients understand how to reach a server through URLs Routing Policies # CloudFront - CDN # Content Delivery Network (CDN) Improves read performance, content is cached at the edge DDoS protection (because worldwide), integration with Shield, AWS Web Application Firewall S3 bucket Enhanced security with CloudFront Origin Access Control (OAC) OAC is replacing Origin Access Identity (OAI) CloudFront can be used as an ingress (to upload files to S3) CloudFront vs S3 Cross Region Replication # CloudFront: # Global Edge network Files are cached for a TTL (maybe a day) Great for static content that must be available everywhere S3 Cross Region Replication: # Must be setup for each region you want replication to happen Files are updated in near real-time Read only Great for dynamic content that needs to be available at low-latency in few regions S3 Transfer Acceleration # Increase transfer speed by transferring file to an AWS edge location which will forward the data to the S3 bucket in the target region Global Accelerator # Improve global application availability and performance using the AWS global network Leverage the AWS internal network to optimize the route to your application (60% improvement) 2 Anycast IP are created for your application and traffic is sent through Edge Locations The Edge locations send the traffic to your application AWS Global Accelerator vs CloudFront # They both use the AWS global network and its edge locations around the world Both services integrate with AWS Shield for DDoS protection CloudFront - CDN # Improves performance for your cacheable content (such as images and videos) Content is served at the edge Global Accelerator # No caching, proxying packets at the edge to applications running in one or more AWS Regions. Improves performance for a wide range of applications over TCP or UDP Good for HTTP use cases that require static IP addresses Good for HTTP use cases that required deterministic, fast regional failover Outposts # Hybrid Cloud: businesses that keep an on-premises infrastructure alongside a cloud infrastructure AWS Outposts are ‚Äúserver racks‚Äù that offers the same AWS infrastructure, services, APIs \u0026amp; tools to build your own applications on-premises just as in the cloud AWS will setup and manage ‚ÄúOutposts Racks‚Äù within your on-premises infrastructure and you can start leveraging AWS services on-premises You are responsible for the Outposts Rack physical security WaveLength # WaveLength Zones are infrastructure deployments embedded within the telecommunications providers\u0026rsquo; datacenters at the edge of the 5G networks Use cases: Smart Cities, ML-assisted diagnostics, Connected Vehicles, Interactive Live Video Streams, AR/VR, Real-time Gaming, ‚Ä¶ Local Zones # Places AWS compute, storage, database, and other selected AWS services closer to end users to run latency-sensitive applications Extend your VPC to more locations ‚Äì ‚ÄúExtension of an AWS Region‚Äù Example: AWS Region: N. Virginia (us-east-1) AWS Local Zones: Boston, Chicago, Dallas, Houston, Miami, ‚Ä¶ Global Applications Architecture # Help improve my blog Was this page helpful to you?\nüëç Yes üëé No This page was last modified at 2023-11-15\nView this page on GitHub Report a problem with this content Can I know your name? Yes No "},{"id":5,"href":"/docs/research/be_protocol/","title":"Backend","section":"RESEARCH","content":" Backend # What is a protocol? # A system that allows two parties to communicate A protocol is designed with a set of properties Depending on the purpose of the protocol TCP, UDP, HTTP, gRPC, FTP The application protocols (HTTP/1.1, HTTP/2, HTTP/3) run on top of transport protocols (TCP, UDP) Protocol properties # Data format Text based (plain text, JSON, XML) Binary (protobuf, RESP, h2, h3) Transfer mode Message based (UDP, HTTP) Stream (TCP, WebRTC) Addressing system DNS name, IP, MAC Directionality Bidirectional (TCP) Unidirectional (HTTP) Full/Half duplex State Stateful (TCP, gRPC, apache thrift) Stateless (UDP, HTTP) Routing Proxies, Gateways Flow \u0026amp; Congestion control TCP (Flow \u0026amp; Congestion) UDP (No control) Error management Error code Retries and timeouts Why do we need a communication model? # Agnostic applications App doesn‚Äôt need to to know network medium Otherwise we need an App for WIFI, ethernet vs LTE vs fiber Network Equipment Management Without a standard model, upgrading network equipments becomes difficult Decoupled Innovation Innovations can be done in each layer separately without affecting the rest of the models OSI Model # 7 Layers each describe a specific networking component:\nLayer 7: Application - HTTP/FTP/gRPC Layer 6: Presentation - Encoding, Serialization Layer 5: Session - Connection establishment, TLS Layer 4: Transport - UDP/TCP Layer 3: Network - IP Layer 2: Data link - Frames, Mac address Ethernet Layer 1: Physical - Electric signals, fiber or radio waves Data across network # TCP/IP Model # Much simpler than OSI just 4 layers\nWhy # OSI Model has too many layers which can be hard to comprehend Hard to argue about which layer does what Simpler to deal with Layers 5-6-7 as just one layer, application TCP/IP Model does just that Reference # Geeksforgeeks: TCP/IP Model (21 Jul, 2023) Udemy: Fundamentals of Backend Engineering (Feb, 2024) "},{"id":6,"href":"/docs/research/encryption/","title":"Encryption","section":"RESEARCH","content":" Encryption # Hash # Can take a message of arbitrary length and transform it into a fixed-length digest Some of the commonly used hashing algorithms: Bcrypt, MD5, SHA1, SHA256, SHA512, and etc MD5('hello') = 5d41402abc4b2a76b9719d911017c592\nNote: An 8-bit byte is represented as 2 characters, from 00 to FF, in hexadecimal\nGood hash function # Fast (exclude Bcrypt) One-way function Collision resistance Use case # Checking file integrity Indexing in in-memory databases (Eg: Redis) Hashing passwords (+ salt) Message authentication code (MAC) Digital signatures Collision # MD5 Collision Demo d131dd02c5e6eec4693d9a0698aff95c2fcab58712467eab4004583eb8fb7f89 55ad340609f4b30283e488832571415a085125e8f7cdc99fd91dbdf280373c5b d8823e3156348f5bae6dacd436c919c6dd53e2b487da03fd02396306d248cda0 e99f33420f577ee8ce54b67080a80d1ec69821bcb6a8839396f9652b6ff72a70\nVS\nd131dd02c5e6eec4693d9a0698aff95c2fcab50712467eab4004583eb8fb7f89 55ad340609f4b30283e4888325f1415a085125e8f7cdc99fd91dbd7280373c5b d8823e3156348f5bae6dacd436c919c6dd53e23487da03fd02396306d248cda0 e99f33420f577ee8ce54b67080280d1ec69821bcb6a8839396f965ab6ff72a70\nNodeJS\nconst crypto = require(\u0026#39;crypto\u0026#39;); // Input 1 (Hexadecimal) const input1 = Buffer.from( \u0026#39;d131dd02c5e6eec4693d9a0698aff95c2fcab58712467eab4004583eb8fb7f89\u0026#39; + \u0026#39;55ad340609f4b30283e488832571415a085125e8f7cdc99fd91dbdf280373c5b\u0026#39; + \u0026#39;d8823e3156348f5bae6dacd436c919c6dd53e2b487da03fd02396306d248cda0\u0026#39; + \u0026#39;e99f33420f577ee8ce54b67080a80d1ec69821bcb6a8839396f9652b6ff72a70\u0026#39;, \u0026#39;hex\u0026#39; ); // Input 2 (Hexadecimal) const input2 = Buffer.from( \u0026#39;d131dd02c5e6eec4693d9a0698aff95c2fcab50712467eab4004583eb8fb7f89\u0026#39; + \u0026#39;55ad340609f4b30283e4888325f1415a085125e8f7cdc99fd91dbd7280373c5b\u0026#39; + \u0026#39;d8823e3156348f5bae6dacd436c919c6dd53e23487da03fd02396306d248cda0\u0026#39; + \u0026#39;e99f33420f577ee8ce54b67080280d1ec69821bcb6a8839396f965ab6ff72a70\u0026#39;, \u0026#39;hex\u0026#39; ); // Function to calculate MD5 hash function calculateMD5(data) { return crypto.createHash(\u0026#39;md5\u0026#39;).update(data).digest(\u0026#39;hex\u0026#39;); } console.log(\u0026#39;Are the inputs identical?\u0026#39;, input1 === input2); const hash1 = calculateMD5(input1); const hash2 = calculateMD5(input2); console.log(\u0026#39;MD5 Hash of Input 1:\u0026#39;, hash1); console.log(\u0026#39;MD5 Hash of Input 2:\u0026#39;, hash2); console.log(\u0026#39;Are the hashes identical?\u0026#39;, hash1 === hash2); Are the inputs identical? false MD5 Hash of Input 1: 79054025255fb1a26e4bc422aef54eb4 MD5 Hash of Input 2: 79054025255fb1a26e4bc422aef54eb4 Are the hashes identical? true Symmetric encryption # Uses the same key to encrypt and decrypt messages\nAES, Twofish and ChaCha20\nUse case # HTTP over SSL/TLS: Session key Data Transmission Data Storage Demo code # This example demonstrates symmetric encryption and decryption using the crypto module with AES (Advanced Encryption Standard) in AES-256-CBC mode\nNodeJS\nInit necessary functions const crypto = require(\u0026#39;crypto\u0026#39;); function generateKeyAndIv() { const key = crypto.randomBytes(32).toString(\u0026#39;hex\u0026#39;); // 256-bit key as hex string const iv = crypto.randomBytes(16).toString(\u0026#39;hex\u0026#39;); // 128-bit IV as hex string return { key, iv }; } function encrypt(text, keyHex, ivHex) { const key = Buffer.from(keyHex, \u0026#39;hex\u0026#39;); // Convert key from hex to Buffer const iv = Buffer.from(ivHex, \u0026#39;hex\u0026#39;); // Convert iv from hex to Buffer const cipher = crypto.createCipheriv(\u0026#39;aes-256-cbc\u0026#39;, key, iv); let encrypted = cipher.update(text, \u0026#39;utf8\u0026#39;, \u0026#39;hex\u0026#39;); encrypted += cipher.final(\u0026#39;hex\u0026#39;); return encrypted; } function decrypt(encryptedText, keyHex, ivHex) { const key = Buffer.from(keyHex, \u0026#39;hex\u0026#39;); // Convert key from hex to Buffer const iv = Buffer.from(ivHex, \u0026#39;hex\u0026#39;); // Convert iv from hex to Buffer const decipher = crypto.createDecipheriv(\u0026#39;aes-256-cbc\u0026#39;, key, iv); let decrypted = decipher.update(encryptedText, \u0026#39;hex\u0026#39;, \u0026#39;utf8\u0026#39;); decrypted += decipher.final(\u0026#39;utf8\u0026#39;); return decrypted; } Encrypt and decrypt a message const { key, iv } = generateKeyAndIv(); console.log(\u0026#34;Generated Key (hex):\u0026#34;, key); console.log(\u0026#34;Generated IV (hex):\u0026#34;, iv); const message = \u0026#34;Hello, this is a secret message!\u0026#34;; console.log(\u0026#34;Original Message:\u0026#34;, message); const encryptedMessage = encrypt(message, key, iv); console.log(\u0026#34;Encrypted Message:\u0026#34;, encryptedMessage); const decryptedMessage = decrypt(encryptedMessage, key, iv); console.log(\u0026#34;Decrypted Message:\u0026#34;, decryptedMessage); Output\nGenerated Key (hex): 00298bfc28cf81a3de3502951b70f3568c4dd5dadbcfadd7b79fee2e640aee07 Generated IV (hex): 387591abb794b2345f496bb1192ace36 Original Message: Hello, this is a secret message! Encrypted Message: 96b91c46b8e380a3b3fc9caf473821508f1ec313ed8b4306eb839c9c04f3692ed0579485016559e272ba9c3c54c5c449 Decrypted Message: Hello, this is a secret message! Decrypt a message with wrong key const { key, iv } = generateKeyAndIv(); console.log(\u0026#34;Generated Key (hex):\u0026#34;, key); console.log(\u0026#34;Generated IV (hex):\u0026#34;, iv); const { key: key2 } = generateKeyAndIv(); console.log(\u0026#34;Generated Key 2 (hex):\u0026#34;, key2); const message = \u0026#34;Hello, this is a secret message!\u0026#34;; console.log(\u0026#34;Original Message:\u0026#34;, message); const encryptedMessage = encrypt(message, key, iv); console.log(\u0026#34;Encrypted Message:\u0026#34;, encryptedMessage); const decryptedMessage = decrypt(encryptedMessage, key2, iv); console.log(\u0026#34;Decrypted Message:\u0026#34;, decryptedMessage); Output\nGenerated Key (hex): 0e35a011a116b0708012ae4165b95be678300be387478c1f217dbc48a1e5f2e8 Generated IV (hex): 6b714efdcab58ebc399332b79df8354d Generated Key 2 (hex): c5bd73c9fa521dd1b019b3be1010645fc2152db17401006781a3908db43ca94f Original Message: Hello, this is a secret message! Encrypted Message: a4b90407ab748d8002d2f33b6ae8698460ed11d1640592fb2e83da9f101e7795ba54e447162f5373f49592ebfff8fa5c node:internal/crypto/cipher:199 const ret = this[kHandle].final(); ^ Error: error:1C800064:Provider routines::bad decrypt at Decipheriv.final (node:internal/crypto/cipher:199:29) at decrypt (/home/dangpham/Workspace/nodejs/demo/symmetric.js:23:27) at Object.\u0026lt;anonymous\u0026gt; (/home/dangpham/Workspace/nodejs/demo/symmetric.js:55:26) at Module._compile (node:internal/modules/cjs/loader:1356:14) at Module._extensions..js (node:internal/modules/cjs/loader:1414:10) at Module.load (node:internal/modules/cjs/loader:1197:32) at Module._load (node:internal/modules/cjs/loader:1013:12) at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:128:12) at node:internal/main/run_main_module:28:49 { library: \u0026#39;Provider routines\u0026#39;, reason: \u0026#39;bad decrypt\u0026#39;, code: \u0026#39;ERR_OSSL_BAD_DECRYPT\u0026#39; } Node.js v18.19.1 Decrypt a message with wrong iv const { key, iv } = generateKeyAndIv(); const { iv: iv2 } = generateKeyAndIv(); const message = \u0026#34;Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\u0026#34;; console.log(\u0026#34;Original Message:\u0026#34;, message); const encryptedMessage = encrypt(message, key, iv); console.log(\u0026#34;Encrypted Message:\u0026#34;, encryptedMessage); const decryptedMessage = decrypt(encryptedMessage, key, iv2); console.log(\u0026#34;Decrypted Message:\u0026#34;, decryptedMessage); Output\nGenerated Key (hex): 76e1a03f6b3e326cd8c383ce12ff6fbd4b77c484afa7811f93304bc548b9de01 Generated IV (hex): 11edd0224d639ac9d8b1c0a1297ed758 Generated IV2 (hex): aca3f6cd3738dab6c97c43a211ec121f Original Message: Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Encrypted Message: 3189b2b3fbb3d511086609f2cbb5f68928fd980bad454fbcfba3c7aada3f6499832a19be0b6285f3b6ed175d67b4fb04c76c4443873a7f6eecbbf3a667dfc70146916de1f55d5e6d057bbed520e9489b97ce25d1cae41a58db5fe3adcf59d6f0d668a4b9561f32303544b90aa5a800000fe2f30f611e9b23af7170e9f95abecd2023df028570e8816a02c603883a90b1b722f2139b3588e78f4dad472f1e799875e30e8a54f9ae9a761779963abd83cc9a8138a91f57b66a9c499a0e0ae0d57ee409bd381d15c52fdeee4b96684cc35bf2db78dedfa433db25fd1323c887597693571d9dab1c1b052a9ed74195aae89a6db5ef47bed08aae24100b19e7ca3e64389fa8b99ad89104f50a7aa291731985e0b464213df61e50df2df5b22b21767987e5b40c5def1ae6ce80a34845d13ca06a6fe250ef291a4ef01b01b531c843d0201b8b06d41b727e0799dd6742a5814a76fefc57a0ba1f7badc854702e8c6f2f88c13d320c45c300a007464c64e73919403e21527570dec2afbb21746fded82a4360887ff7aad565a797cc731deb6cf6f23dccb73427b21c061f46939d1d5e6ef7b16079467199a9ce03f558dbcb3141f2502683cb5af69ec47e35f343bb5e25 Decrypted Message: ÔøΩ!TÔøΩ{)bÔøΩÔøΩ#\\ÔøΩÔøΩ(r sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. HMAC # HMAC stands for Hash-based Message Authentication Code It\u0026rsquo;s a method that generates a Message Authentication Code (MAC) The major difference between a hash and an HMAC is that HMAC uses a secret key It\u0026rsquo;s used to prove message authenticity and integrity There exist many algorithms for calculating a MAC, such as SipHash, BLAKE2, CMAC, etc Why and how # See more details about the bit-flipping attack here Here shows you how HMAC prevents a bit-flipping attack Use case # Signing JSON Web Tokens (JWTs) for secure authentication Signing files in secure file transfer protocols. Eg: SSH File Transfer Protocol (SFTP), FTP over SSL (FTPS) Verifying the integrity and authenticity of transactions in banking Demo # This example demonstrates how HMAC prevents bit-flipping attack\nThis demo can be run directly in the console of the Chrome browser Javascript\nPrepare const iv = crypto.getRandomValues(new Uint8Array(16)); let key; (async () =\u0026gt; { key = await crypto.subtle.generateKey( { name: \u0026#34;AES-CBC\u0026#34;, length: 128, }, true, [\u0026#34;encrypt\u0026#34;, \u0026#34;decrypt\u0026#34;] ); })(); async function encryptData(plaintext) { const encoder = new TextEncoder(); const data = encoder.encode(plaintext); const ciphertext = await crypto.subtle.encrypt( { name: \u0026#34;AES-CBC\u0026#34;, iv, }, key, data ); return new Uint8Array(ciphertext); } async function decryptData(ciphertext) { const plaintextBuffer = await crypto.subtle.decrypt( { name: \u0026#34;AES-CBC\u0026#34;, iv, }, key, ciphertext ); const decoder = new TextDecoder(); return decoder.decode(plaintextBuffer); } async function deriveHmacKey(aesKey) { const rawKey = await crypto.subtle.exportKey(\u0026#34;raw\u0026#34;, aesKey); return crypto.subtle.importKey( \u0026#34;raw\u0026#34;, rawKey, { name: \u0026#34;HMAC\u0026#34;, hash: { name: \u0026#34;SHA-1\u0026#34; }, }, true, [\u0026#34;sign\u0026#34;, \u0026#34;verify\u0026#34;] ); } async function signData(data) { const encoder = new TextEncoder(); const encodedData = encoder.encode(data); const hmacKey = await deriveHmacKey(key); const signature = await crypto.subtle.sign(\u0026#34;HMAC\u0026#34;, hmacKey, encodedData); return new Uint8Array(signature); } async function verifyData(data, signature) { const encoder = new TextEncoder(); const encodedData = encoder.encode(data); const hmacKey = await deriveHmacKey(key); const isValid = await crypto.subtle.verify( \u0026#34;HMAC\u0026#34;, hmacKey, signature, encodedData ); return isValid; } function ord(string) { return string.charCodeAt(0); } Main flow (async () =\u0026gt; { // User const plaintext = \u0026#34;{ Message: \u0026#39;Doing charity work!\u0026#39;, Money: 001 $, To: Beggar }\u0026#34;; const ciphertext = await encryptData(plaintext); const signature = await signData(ciphertext); // Hacker ciphertext[43 - 16] = ord(\u0026#34;0\u0026#34;) ^ ciphertext[43 - 16] ^ ord(\u0026#34;9\u0026#34;); ciphertext[44 - 16] = ord(\u0026#34;0\u0026#34;) ^ ciphertext[44 - 16] ^ ord(\u0026#34;9\u0026#34;); ciphertext[45 - 16] = ord(\u0026#34;1\u0026#34;) ^ ciphertext[45 - 16] ^ ord(\u0026#34;9\u0026#34;); // Bank const decryptedText = await decryptData(ciphertext); console.log(\u0026#34;Decrypted Text:\u0026#34;, decryptedText); const isVerified = await verifyData(ciphertext, signature); console.log(\u0026#34;Signature valid:\u0026#34;, isVerified); })(); Output \u0026gt; Decrypted Text: { Message: \u0026#39;Doin\bÔøΩ\u001eÔøΩiQÔøΩÔøΩÔøΩ\u0026#39;BT_ÔøΩ\u0026#34;\f!\u0026#39;, Money: 999 $, To: Beggar } \u0026gt; Signature valid: false Asymmetric encryption # There are generally three things asymmetric algorithms can do: Encrypt/decrypt: RSA, EC ElGamal Sign/verify: RSA, DSA, ECDSA Key exchange: Diffie-Hellman, ECDH The amount of data that can be encrypted depends on the modulus length and the type (e.g., RSA 2048-bit modulus length with PKCS#1 can encrypt a maximum of ((\u0026lt;modulus length\u0026gt; / 8) - 42 = 2048 / 8) - 42 = 214 bytes) Public encryption / private decryption # Algorithms: RSA, EC ElGamal Common usage Use cases: Key exchange in SSL/TLS 1.2 NodeJS\nInit necessary functions const crypto = require(\u0026#39;crypto\u0026#39;); const generateKeyPair = () =\u0026gt; { return crypto.generateKeyPairSync(\u0026#39;rsa\u0026#39;, { modulusLength: 2048, // Length of key in bits (2048 is standard) publicKeyEncoding: { type: \u0026#39;pkcs1\u0026#39;, // Public Key Cryptography Standards 1 format: \u0026#39;pem\u0026#39; // Output as PEM (Base64 encoded) }, privateKeyEncoding: { type: \u0026#39;pkcs1\u0026#39;, // Private Key Cryptography Standards 1 format: \u0026#39;pem\u0026#39; // Output as PEM (Base64 encoded) } }); } function encryptWithPublicKey(publicKeyPem, message) { const encrypted = crypto.publicEncrypt(publicKeyPem, Buffer.from(message)); return encrypted.toString(\u0026#39;base64\u0026#39;); // Convert encrypted message to base64 for readability } function decryptWithPrivateKey(privateKeyPem, encryptedMessage) { const decrypted = crypto.privateDecrypt(privateKeyPem, Buffer.from(encryptedMessage, \u0026#39;base64\u0026#39;)); return decrypted.toString(\u0026#39;utf8\u0026#39;); // Convert decrypted message to utf8 string } Public key to encrypt and private key to decrypt a message const { publicKey, privateKey } = generateKeyPair(); console.log(\u0026#34;Public Key (PEM format):\\n\u0026#34;, publicKey); console.log(\u0026#34;Private Key (PEM format):\\n\u0026#34;, privateKey); const message = \u0026#34;Hello, this is a secret message!\u0026#34;; console.log(\u0026#34;Original Message:\u0026#34;, message); const encryptedMessage = encryptWithPublicKey(publicKey, message); console.log(\u0026#34;Encrypted Message:\u0026#34;, encryptedMessage); const decryptedMessage = decryptWithPrivateKey(privateKey, encryptedMessage); console.log(\u0026#34;Decrypted Message:\u0026#34;, decryptedMessage); Output\nPublic Key (PEM format): -----BEGIN RSA PUBLIC KEY----- MIIBCgKCAQEA0ivCBvmxFewdtUePX8RG3+SKifuEz9dsoSEJzQiCbdOfxCzZiyCb R7azQhY67IKC93qr/j7zyCGx3WJ2lrRd4ij51Q9CIn75zPExEfLMvCt0HQtO+UQo w0QZLGIZc6Q+eJfQg++PeUVYpZPT/jp3RXHEScpZJfHCarhl6JfCkuu3YuITSpta rhUuaw6UMoWnZCbr0/OW2rC3s97p+VIr5i3jCf+z84E7dTZ529mZ1PsxNue5NKqO /SWyjrNvwORMkdYweoSqz5oZ0U2B29mUWRkhcOrPmrRBCxMRwWTmQC3PpzrAwG2/ eQfbKX1tzzSVjjjMUgKvmeLvr57au62yLwIDAQAB -----END RSA PUBLIC KEY----- Private Key (PEM format): -----BEGIN RSA PRIVATE KEY----- MIIEowIBAAKCAQEA0ivCBvmxFewdtUePX8RG3+SKifuEz9dsoSEJzQiCbdOfxCzZ iyCbR7azQhY67IKC93qr/j7zyCGx3WJ2lrRd4ij51Q9CIn75zPExEfLMvCt0HQtO +UQow0QZLGIZc6Q+eJfQg++PeUVYpZPT/jp3RXHEScpZJfHCarhl6JfCkuu3YuIT SptarhUuaw6UMoWnZCbr0/OW2rC3s97p+VIr5i3jCf+z84E7dTZ529mZ1PsxNue5 NKqO/SWyjrNvwORMkdYweoSqz5oZ0U2B29mUWRkhcOrPmrRBCxMRwWTmQC3PpzrA wG2/eQfbKX1tzzSVjjjMUgKvmeLvr57au62yLwIDAQABAoIBAELNKr4p1gn4QxcP +DfBvJ9EVm52Fegz+jCavjE/r6k11vW1Ja4tfn2ESiTKyQ7MitEbWhiVLMojP5P0 zGmpSZ/tUz9Pur8ZKc/kp6qjSETU8PKcWg0rh2NNPU0Ynytc/Ig7BMkytyEeFAeI 3ZxUO/3EI9YqbTx8w8VE+As+VVd55dkkoEShi77ibxFNeevWvS46k/d1a5hcsVj8 NlsngHux8ZwUu8ZaIQH0wclLo77TcDOJF9NkJb7x8xzXH/pvNOPu49nA098zob6c ivZTW6z2Jsa94NzPzvCQ/NLumrkt07bE0HBXJCkaajlhjn69gXR2fEfWVrryW3e9 sLFEPJUCgYEA9hz4qFpM/QB4q1AzNR7ZK5vfzfAIAQWPmbVpFZXYdUD+tzXut7Yu dd4WZU1l/LgUeLUmUfJqDwiMOz/pGSTNcJqtHl3wP2Yz9n1fcWhxdbjbPZkB1+Di dhKkxvxEih4PyK+367udHcJYF+Su7Pl2hNmBMvTc0rzWpdJHRVCrwEMCgYEA2p0o Dyy5dBhrMCi083074qQhdXQqX1+f0KDZXy1u8JtooktbpARfyc+P9/hT+sdvxln7 hEsYPkplvPS3ahm0tb4tCW1esAZLhn8RvYJqJConBawKRw2oVJ9YCW1Et4vn+oKU pLfvmgX/PgCIuVn6szmU4LUj9pHoaoE5E0ulLaUCgYEA5n+dtvbTsgR1/2RegTrC BGC5TAOpS2Os6TWJFKlBkBduN6KwT6i1fLiiWwARK44vxhlKqWcTQ78qrvcdVeos 6nBDAPTT5FzQ/+LNt8YstSeLVfZuToQVNKYjYyWy/3RGLhu8cnBFJzD0FnScC99b y/J1WYcRJeGsWqNFErsKEEcCgYAw/e0/UVeSU/KZjVXYB2XHSd8RsmHYk9Z9674r HURyeXF+hYLZA/3vfSuXd7hiSBWdjwbVw/p/4y5fpTwBdBdSb3cqWK9SpWaBkrKI FNTym9u44rA+8imaJUeWfT1cIOdw9ZiYPXxduSBVZcs+NpL/XVUm8pFHrbU3QRRo ZZhz3QKBgHcVAZq3TaigmrupfdGlSDN+NdxP7EhOlGaYu5LuJcfic2q/W1+SKoQK 5osEUzV/SeWQH5oHW/2ASx2GOwyiWcn2RfXRFPSXfX4aHfO3JBOZVJ8Wzql9WhST NEw2BFi05XXkbE/ncxq5+SZsHVGQVZ0hlkG2oPc3Hp7sDAMJSDQC -----END RSA PRIVATE KEY----- Original Message: Hello, this is a secret message! Encrypted Message: Vb+Oc8Kn76rvjJuXZOvtLGsQDm/VGXzB2KbqzWXr5UMZV4bXLkhCs407H4Li4ImROH6uPXlA+SNPSYr0XpLQ+Uksnt2b8YbUQZUSvi15bJbXKKXsvo9FLg2ygcSUiqBjGs3coMbWh0sZnGN+GpXbIld8ItGCkLRnMDkvCK/uzgA11bmLcBOFt726ytjK0qGJGDM1svL2A2ZTXGgnLMUSnSzNxWv5K4sUU0yi38/ineL1Kc6FLlUo3YrLnW6MvB0rp+lF9VRGw8Sbagpm01PcnQiQH28OmbQxLomScQ4Mq1EXqN7oVgE2kMDXIO0mec6I0TmLtsLjWirN0iT2Um/cDQ== Decrypted Message: Hello, this is a secret message! Private key to encrypt and decrypt a message const { privateKey } = generateKeyPair(); console.log(\u0026#34;Private Key (PEM format):\\n\u0026#34;, privateKey); const message = \u0026#34;Hello, this is a secret message!\u0026#34;; console.log(\u0026#34;Original Message:\u0026#34;, message); const encryptedMessage = encryptWithPublicKey(privateKey, message); console.log(\u0026#34;Encrypted Message:\u0026#34;, encryptedMessage); const decryptedMessage = decryptWithPrivateKey(privateKey, encryptedMessage); console.log(\u0026#34;Decrypted Message:\u0026#34;, decryptedMessage); Output\nPrivate Key (PEM format): -----BEGIN RSA PRIVATE KEY----- MIIEpAIBAAKCAQEA8+Vsp8r+fNSpHdr+cr8+8tX+Tmm/1oCtU4dlVSz+auKLj490 duuh+rZ2ud7zgMzzCd9cSqFs4JWHsAFbx2oe4LSWD++V7ZES3ORE+48ksziCMC/r ... EZUgvYiHTgt3lJnQunBQPGug59B4mB8JRPZIdrpZc8acTA0X5+Ys8PRSwFoNzQ+b pDxXQo6e+j9SU9xi9ULFuK9ZZp48ERgX8MqG+1fdxGU+LFHfK192Kw== -----END RSA PRIVATE KEY----- Original Message: Hello, this is a secret message! Encrypted Message: V3fyDYvqx5OzPBJfKO434XKTUSC+c7KnpsvjpSdkUYR+BfrK0A+4V+y1Mf7uuCWaCRIA4Npu9aRoAgDPV8u7Zwc7h6sGaGo8WSofWsADCobDiN1d1dX0Htxurr9tVNmcdvXBxigyLK93h+Q7xXg5Xn2RdBpItPBHDITxfBlCRdyDZX+x81b1xTCdue6mTQwEp8CkJpZsahEPYgW7tYA+rWBu147Cz0jKEstk62Udxc82WYMRT+za0pz2nqSVqDKZCpaXBT1xlmPNgy14bzuLNZbykyUScly3PJUmybi9Ml/+OYjPwLY+XuYbXDklV2OX2fPsiuTo0iwXOwZB7HRE1Q== Decrypted Message: Hello, this is a secret message! Private key to encrypt and public key to decrypt a message const { publicKey, privateKey } = generateKeyPair(); console.log(\u0026#34;Public Key (PEM format):\\n\u0026#34;, publicKey); console.log(\u0026#34;Private Key (PEM format):\\n\u0026#34;, privateKey); const message = \u0026#34;Hello, this is a secret message!\u0026#34;; console.log(\u0026#34;Original Message:\u0026#34;, message); const encryptedMessage = encryptWithPublicKey(privateKey, message); console.log(\u0026#34;Encrypted Message:\u0026#34;, encryptedMessage); const decryptedMessage = decryptWithPrivateKey(publicKey, encryptedMessage); console.log(\u0026#34;Decrypted Message:\u0026#34;, decryptedMessage); Output\nPublic Key (PEM format): -----BEGIN RSA PUBLIC KEY----- MIIBCgKCAQEA2UVnWwcABrWqMggU7xxkl25zzV3/FabJvFDiGtaWjTUhLu9QjKtO ... wUXBn7HZjrd8Oue5JVPL1KqpUABxLBYc1QIDAQAB -----END RSA PUBLIC KEY----- Private Key (PEM format): -----BEGIN RSA PRIVATE KEY----- MIIEpAIBAAKCAQEA2UVnWwcABrWqMggU7xxkl25zzV3/FabJvFDiGtaWjTUhLu9Q ... lXDeVDYNZZ5oYCOWxjoAYamUbPrXD+SDGsDwnlgcaHViBBxUeGElHw== -----END RSA PRIVATE KEY----- Original Message: Hello, this is a secret message! Encrypted Message: VwgGUHIcxGAO5J5THYzxEgrmGQlIWy8Xg8f+c2zuyWjEzlgkat2TIyJa4fZ/vvf/kmIaetfw2cJf7wSvDfHP+yikVYRN2/uQ67pE6dK+FtW0d5GK6HaoM4c6QP/DbeMbikywSFjxYiyKsqp7eREtv8rdEgpde7OVL3pthSZmoJWUoSFNUvMqJT5+D1hPv8J38TlNdEUp7YrIQdx/gyZx8w6q+uikyboJbEJ2Z4YCfJVUbw1Fwbijox/jb8bWRFO6OHb2XXC4w2LXGLoZdxAAykRQ19BTsV6ojMflb1Bw428Q2GNaiolJXZX7j20rVRjM0KccLvHQ5FLPzTmK3BHQxg== node:internal/crypto/cipher:80 return method(data, format, type, passphrase, buffer, padding, oaepHash, ^ Error: error:020000B3:rsa routines::missing private key at Object.privateDecrypt (node:internal/crypto/cipher:80:12) at decryptWithPrivateKey (/home/dangpham/Workspace/nodejs/demo/asymmetric.js:23:30) at Object.\u0026lt;anonymous\u0026gt; (/home/dangpham/Workspace/nodejs/demo/asymmetric.js:66:26) at Module._compile (node:internal/modules/cjs/loader:1356:14) at Module._extensions..js (node:internal/modules/cjs/loader:1414:10) at Module.load (node:internal/modules/cjs/loader:1197:32) at Module._load (node:internal/modules/cjs/loader:1013:12) at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:128:12) at node:internal/main/run_main_module:28:49 { opensslErrorStack: [ \u0026#39;error:1C8000A2:Provider routines::failed to decrypt\u0026#39; ], library: \u0026#39;rsa routines\u0026#39;, reason: \u0026#39;missing private key\u0026#39;, code: \u0026#39;ERR_OSSL_RSA_MISSING_PRIVATE_KEY\u0026#39; } Node.js v18.19.1 Private sign (encryption) / public verify (decryption) # Algorithms: RSA, DSA, ECDSA Use cases: Token-based authentication, digital signatures NodeJS\nInit necessary functions const crypto = require(\u0026#39;crypto\u0026#39;); const generateKeyPair = () =\u0026gt; { return crypto.generateKeyPairSync(\u0026#39;rsa\u0026#39;, { modulusLength: 2048, // Length of key in bits (2048 is standard) publicKeyEncoding: { type: \u0026#39;pkcs1\u0026#39;, // Public Key Cryptography Standards 1 format: \u0026#39;pem\u0026#39; // Output as PEM (Base64 encoded) }, privateKeyEncoding: { type: \u0026#39;pkcs1\u0026#39;, // Private Key Cryptography Standards 1 format: \u0026#39;pem\u0026#39; // Output as PEM (Base64 encoded) } }); } // Function to \u0026#34;sign\u0026#34; (encrypt) a message using RSA private key function signWithPrivateKey(privateKeyPem, message) { const encrypted = crypto.privateEncrypt(privateKeyPem, Buffer.from(message)); return encrypted.toString(\u0026#39;base64\u0026#39;); // Convert encrypted message to base64 for readability } // Function to \u0026#34;verify\u0026#34; (decrypt) a message using RSA public key function verifyWithPublicKey(publicKeyPem, encryptedMessage) { const decrypted = crypto.publicDecrypt(publicKeyPem, Buffer.from(encryptedMessage, \u0026#39;base64\u0026#39;)); return decrypted.toString(\u0026#39;utf8\u0026#39;); // Convert decrypted message to utf8 string } Private key to encrypt and public key to decrypt a message const { publicKey, privateKey } = generateKeyPair(); console.log(\u0026#34;Public Key (PEM format):\\n\u0026#34;, publicKey); console.log(\u0026#34;Private Key (PEM format):\\n\u0026#34;, privateKey); const message = \u0026#34;J5 love ST\u0026#34;; console.log(\u0026#34;Original Message:\u0026#34;, message); // \u0026#34;Sign\u0026#34; the message using the private key (Encrypt) const encryptedMessage = signWithPrivateKey(privateKey, message); console.log(\u0026#34;Encrypted Message (Base64):\u0026#34;, encryptedMessage); // \u0026#34;Verify\u0026#34; the message using the public key (Decrypt) const decryptedMessage = verifyWithPublicKey(publicKey, encryptedMessage); console.log(\u0026#34;Decrypted Message:\u0026#34;, decryptedMessage); Output\nPublic Key (PEM format): -----BEGIN RSA PUBLIC KEY----- MIIBCgKCAQEAnxkXw9Cbi4F+tsJImVUNVhOUTYWj/lMUB+jcXBE6myqgZ4xiHWWx 0nGzjqxHiojYcN3jiEtABqbls2KToTs9LvNHDYcr8bPh828HZTcB6V9r1x79zFSp jJtvx4hmOa0K7iOiN2AwWaV1mtFTKOZ/2QsQMqyhleBgPMCQyD6CYS2IJrRq6Wu+ anekIYgfWToajrpbgs4AE5X0aTd10/0eR0A7n3C8jGKiyAaTsROBtqvmoq69QGrW ozDOWl/Dt6I3Y/a0Vx6lyL2bjClbIo61yJqkxW0VWFLodFuKvjd8gln3PZokTiEl fjQFKVj63Wh/ssXHQjFtYvnmS73gMATYSwIDAQAB -----END RSA PUBLIC KEY----- Private Key (PEM format): -----BEGIN RSA PRIVATE KEY----- MIIEowIBAAKCAQEAnxkXw9Cbi4F+tsJImVUNVhOUTYWj/lMUB+jcXBE6myqgZ4xi HWWx0nGzjqxHiojYcN3jiEtABqbls2KToTs9LvNHDYcr8bPh828HZTcB6V9r1x79 zFSpjJtvx4hmOa0K7iOiN2AwWaV1mtFTKOZ/2QsQMqyhleBgPMCQyD6CYS2IJrRq 6Wu+anekIYgfWToajrpbgs4AE5X0aTd10/0eR0A7n3C8jGKiyAaTsROBtqvmoq69 QGrWozDOWl/Dt6I3Y/a0Vx6lyL2bjClbIo61yJqkxW0VWFLodFuKvjd8gln3PZok TiElfjQFKVj63Wh/ssXHQjFtYvnmS73gMATYSwIDAQABAoIBADBGznnKPrC92iP9 30a70sCoT0uYvlMJhZ4C0H8VcUmtTSAuroUKG0Pm4Zvs9gZ5EOhqxETSxLpgAXqF 8pMtpRqukoRt3G1K7sjOC5nwb6GPpWsRCeVrWUmDzw7melKNCjCJ2orgIrvJI98X HpteGjRTkZY24Q9YFwvISQaiRTDURBuTN1xmKNJ22AFU9oinLbedg0wPJ3xS5YPP nROv8Gz/buoRrxysObguPgaBcOPQB3qz1qdsXwjnCDfQGKzo8LrFGtD1z3Zu4jWx CfxzGisk45FuE0FWksNMwD0mKXDh11unA3p/xCstbwD2ISIiFhSvG09tGYl5pqlD tGOZj2UCgYEA0OAyKRCNKPRxj1nXFtg7eR02YXxlnIqhl1ggXdW6hpwTx1t+Bu28 Qi5OsDOBivkTHjqt3x5DQTQTaOdpfwDBUpuYM4NIxL6EoFZaC2R26ocaIsZ4qKkk SmBJW1Yx5iRWrurKB+1iwVshcjAHFyYWiltM4iL25RKAAeE7M1inlGcCgYEAwv3w ceg+/mTmhE9XfW9N6ThEHvnoneHjuil5/7RN4XONDgB5Av68iimOTlcROmrc27TY UcZvDI0j7yrAwv+7Z9I9DS56vSPpqYEC0HXayyFiCn3CS2Om0ySMYdTVJRi+53kf 8qZVEW9OMyRNIbc9djKObN4wTijMiRbZpmT2Tn0CgYAApnIBhrepxPkFhTYSMCIf QmQE8aovTo8qNXAEWsH14U5+dF50DxFi81nzWnWwxQ22LmCULTfwYAUfcnj1mD8B ztIudt4nHqCzDxHAr1Nfb4Q5T3zYqY4fXSVdT2tgWASdDsYKOEbyayIzhMrA27F+ RMJ8gbdbBy+20cipZEFBSQKBgQCEGB2EPO43zkjvRwSg//8KyEg1p9zy3+0y1xhD pnTAD1R2MNHJuqIlAsPZxFfyeCRIXnnQ5BmkqhS22AKf1ziwu5cKT/tsGGEZqEEs 0To4M9REAS/XfJmuHetP9yuxptLk4oRHEHE+j2WtdaEe/xCO+u7LR7X3rOHq2OT3 ORw2zQKBgEACN6Qhs+ExE2+MLlC/8IaI3mPwa893LFk65/qHMuUQ2xUniJo2fQV5 BomT4OFSDaPBftdL1a/WVg6/EvN9Re1VBncAycCsLeSB+UHnk3+MvQTCh5E3j/Vy gvIAt3PKqHBQTTx8p3CSxaDp91U6ru3OxetBgIchdHavxCXOkvrW -----END RSA PRIVATE KEY----- Original Message: J5 love ST Encrypted Message (Base64): cG6810O8omJ67Ji6ZoQRw2um5UTx6YdTvUXWlH4GrUtph5J3xVqJhta4SWgJHNjaMgfMveJpFPTv/iAq0yBskmha+f+hRyYOITzXcz3jqtOl+4G9dC/OyqdkGIHq96lF9YZmWrXVtkCncRR07XoL+AMiBJ37HUgbHS15axAtghtJSYfWzabASA13sbEewVgQTIvg+aH9NvG5s2gKxLNIPtKcqUvmmqB2P0hFhg437QaF4SM/MBz/w7HbQT69B+YveBW8pFcgxAl+oIdl+dAneCog0FZiWI5mg13jlUmx4s7dhBKu7Ebdtayk3pZsHCKCYHNyePgSYA8bnUEqUVw+Hg== Decrypted Message: J5 love ST Public key to encrypt and decrypt a message const { publicKey } = generateKeyPair(); console.log(\u0026#34;Public Key (PEM format):\\n\u0026#34;, publicKey); const message = \u0026#34;J5 love ST\u0026#34;; console.log(\u0026#34;Original Message:\u0026#34;, message); const encryptedMessage = signWithPrivateKey(publicKey, message); console.log(\u0026#34;Encrypted Message (Base64):\u0026#34;, encryptedMessage); const decryptedMessage = verifyWithPublicKey(publicKey, encryptedMessage); console.log(\u0026#34;Decrypted Message:\u0026#34;, decryptedMessage); Output\nPublic Key (PEM format): -----BEGIN RSA PUBLIC KEY----- MIIBCgKCAQEA1GV0AyMKyczyUpRyIolyuDRkw5hpkqhojoZ4KJvh11bqDe6H2mjJ ... f3Io9s6lsPaN3zWxDxxJJMo5SsX48T5NQQIDAQAB -----END RSA PUBLIC KEY----- Original Message: J5 love ST node:internal/crypto/cipher:80 return method(data, format, type, passphrase, buffer, padding, oaepHash, ^ Error: error:020000B3:rsa routines::missing private key at Object.privateEncrypt (node:internal/crypto/cipher:80:12) at signWithPrivateKey (/home/dangpham/Workspace/nodejs/demo/asymmetricLikeJWT.js:19:30) at Object.\u0026lt;anonymous\u0026gt; (/home/dangpham/Workspace/nodejs/demo/asymmetricLikeJWT.js:56:26) at Module._compile (node:internal/modules/cjs/loader:1356:14) at Module._extensions..js (node:internal/modules/cjs/loader:1414:10) at Module.load (node:internal/modules/cjs/loader:1197:32) at Module._load (node:internal/modules/cjs/loader:1013:12) at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:128:12) at node:internal/main/run_main_module:28:49 { opensslErrorStack: [ \u0026#39;error:1C880004:Provider routines::RSA lib\u0026#39; ], library: \u0026#39;rsa routines\u0026#39;, reason: \u0026#39;missing private key\u0026#39;, code: \u0026#39;ERR_OSSL_RSA_MISSING_PRIVATE_KEY\u0026#39; } Node.js v18.19.1 Public key to encrypt and private key to decrypt a message const { publicKey, privateKey } = generateKeyPair(); console.log(\u0026#34;Public Key (PEM format):\\n\u0026#34;, publicKey); console.log(\u0026#34;Private Key (PEM format):\\n\u0026#34;, privateKey); const message = \u0026#34;J5 love ST\u0026#34;; console.log(\u0026#34;Original Message:\u0026#34;, message); const encryptedMessage = signWithPrivateKey(publicKey, message); console.log(\u0026#34;Encrypted Message (Base64):\u0026#34;, encryptedMessage); const decryptedMessage = verifyWithPublicKey(privateKey, encryptedMessage); console.log(\u0026#34;Decrypted Message:\u0026#34;, decryptedMessage); Output\nPublic Key (PEM format): -----BEGIN RSA PUBLIC KEY----- MIIBCgKCAQEAoqD5nBZ1axzJnDyxmuQmb11/3NBVZlk4py/X64ew9HH5NzrwkH04 ... t1rjt5xOTmK5N0fyrxNoouTqIpV3E85P/QIDAQAB -----END RSA PUBLIC KEY----- Private Key (PEM format): -----BEGIN RSA PRIVATE KEY----- MIIEowIBAAKCAQEAoqD5nBZ1axzJnDyxmuQmb11/3NBVZlk4py/X64ew9HH5Nzrw ... fKcxqqYvJv2yio3ogNZSJsFGFU1lafg7FwWMgqnd/99nWBCY2gn1 -----END RSA PRIVATE KEY----- Original Message: J5 love ST node:internal/crypto/cipher:80 return method(data, format, type, passphrase, buffer, padding, oaepHash, ^ Error: error:020000B3:rsa routines::missing private key at Object.privateEncrypt (node:internal/crypto/cipher:80:12) at signWithPrivateKey (/home/dangpham/Workspace/nodejs/demo/asymmetricLikeJWT.js:19:30) at Object.\u0026lt;anonymous\u0026gt; (/home/dangpham/Workspace/nodejs/demo/asymmetricLikeJWT.js:73:26) at Module._compile (node:internal/modules/cjs/loader:1356:14) at Module._extensions..js (node:internal/modules/cjs/loader:1414:10) at Module.load (node:internal/modules/cjs/loader:1197:32) at Module._load (node:internal/modules/cjs/loader:1013:12) at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:128:12) at node:internal/main/run_main_module:28:49 { opensslErrorStack: [ \u0026#39;error:1C880004:Provider routines::RSA lib\u0026#39; ], library: \u0026#39;rsa routines\u0026#39;, reason: \u0026#39;missing private key\u0026#39;, code: \u0026#39;ERR_OSSL_RSA_MISSING_PRIVATE_KEY\u0026#39; } Node.js v18.19.1 Private key to encrypt and decrypt a message const { privateKey } = generateKeyPair(); console.log(\u0026#34;Private Key (PEM format):\\n\u0026#34;, privateKey); const message = \u0026#34;J5 love ST\u0026#34;; console.log(\u0026#34;Original Message:\u0026#34;, message); const encryptedMessage = signWithPrivateKey(privateKey, message); console.log(\u0026#34;Encrypted Message (Base64):\u0026#34;, encryptedMessage); const decryptedMessage = verifyWithPublicKey(privateKey, encryptedMessage); console.log(\u0026#34;Decrypted Message:\u0026#34;, decryptedMessage); Output\nPrivate Key (PEM format): -----BEGIN RSA PRIVATE KEY----- MIIEowIBAAKCAQEAykZk5e0pL+3la4Ydil2jc3sjJWslEvYv0qfGwi5SrKmA8HpS ... Wso3YmC9MOThDlzdM3nY4sNugECT1emFNVitiegOuOuhoD2qBvUb -----END RSA PRIVATE KEY----- Original Message: J5 love ST Encrypted Message (Base64): dOgtEZCxxV+IoD9p8cfCgSlVNfDhgaumgihbBoD5yvhOA4r0qM2/Pq+m28riZZH66EtXUtjQoCaDt9r92flIhvnJbQeDgumCl7MwseMoZdJoDRjGGXuxEqyzinMc5mYmxayz9iSDOMt3NgDSTmClJXb+rGXkLLpM9zxpQSBrdq3wdamMrY0/JAnyul1icLZ6HpSiwSg7DhQYrZR9CDxgNeZpqyzNoUksu61EfYO7hxDcjbIZ37QrDT/Le/RBU+L6jyDyDcgETuV+xyJyVdy/C0iLtr5J72GQbcQozLrPIFZ/yYb0iePiwa72fymhIpNhMlVBgr2VFEIT/Wb9QZr7dw== Decrypted Message: J5 love ST Key exchange # Algorithms: Diffie-Hellman, ECDH Use cases: SSL/TLS 1.3 Diffie-Hellman # Concept Example Demo code NodeJS\nconst crypto = require(\u0026#39;crypto\u0026#39;); // J5 const J5 = crypto.createDiffieHellman(2048); // Prime will be 2048bit long const G = J5.getGenerator(); const P = J5.getPrime(); console.log(\u0026#34;P:\u0026#34;, P.toString(\u0026#34;hex\u0026#34;)); console.log(\u0026#34;G:\u0026#34;, G.toString(\u0026#34;hex\u0026#34;)); console.log(\u0026#39;------\u0026#39;); J5.generateKeys(); const J5_privateKey = J5.getPrivateKey(); const J5_publicKey = J5.getPublicKey(); console.log(\u0026#34;J5 Private Key:\u0026#34;, J5_privateKey.toString(\u0026#39;hex\u0026#39;)); console.log(\u0026#34;J5 Public Key:\u0026#34;, J5_publicKey.toString(\u0026#39;hex\u0026#39;)); console.log(\u0026#39;------\u0026#39;); // ST const ST = crypto.createDiffieHellman(P, G); ST.generateKeys(); const ST_privateKey = ST.getPrivateKey(); const ST_publicKey = ST.getPublicKey(); console.log(\u0026#34;ST Private Key:\u0026#34;, ST_privateKey.toString(\u0026#34;hex\u0026#34;)); console.log(\u0026#34;ST Public Key:\u0026#34;, ST_publicKey.toString(\u0026#34;hex\u0026#34;)); console.log(\u0026#39;------\u0026#39;); // Exchange public keys and compute the session key const J5_SessionKey = J5.computeSecret(ST_publicKey); const ST_SessionKey = ST.computeSecret(J5_publicKey); console.log(\u0026#34;J5 Session Key:\u0026#34;, J5_SessionKey.toString(\u0026#39;hex\u0026#39;)); console.log(\u0026#34;ST Session Key:\u0026#34;, ST_SessionKey.toString(\u0026#39;hex\u0026#39;)); Output\nP: b811e65181d3cc8942efa49832bc09fc4f608ea03d9ccf70a082509b4f31024665ad50e8915a2146b3da8a59d0c1fd32b26dc410f29e9ef265956b6f060b9d70f9be4c2c2b1e4b87391da617962a096a3995be117aa64196d198aa1d4e28769130f7d79bb4ea5c9a21dcce9d6e5b542de3478e860ab304ce97d162334040bb7c24e5d1edfac7bd9223cd848394f001c45078282145a3c32aa127a9e917ac5d896e153800832daa56765cf33f004ee256f23011633ac260bf8a560a131d8f3e39c9692e58fc788ce58a68db7cbb3d2faec198604b4854ade3fd6847480c93a5cae3143ac12632f75aa19dc33cbf8724c421e59fd756706d7c05fe970bb849bc2f G: 02 ------ J5 Private Key: 5b39e6ae9b1edb2907b32bd4be76226b19d7f1b45637a6551fcd83f9ce374bd802ab050c9ddcae9d4a895a9c6d604e285ef18148e2f0952cb250047167052dd026f8229cbce07a1a8eb8aa0917a45ca6af7a43efd793816fcbb2e3bbd37e0afccd787cc0604f511d191e365a8bcd7353484e64b602ac198d22237f2803ab0d70da71d9567044bddc36a41c9d674832af9a0c9e0e058e5be336158b0d7636641171ffce5df77ad1c5f9dc732aec932af1625def4ac267735caff756edbb764f0870055b3f2ab754009080558b3f84643072dd289507dc30b2135934d3d11ab7657ad85971d550615c4bd8b690232e787232ffe58550a08d2cc71ae7f6ecdec593 J5 Public Key: 5b7843a2d16ecf3065db80bdc82e104eeab48d04a0fe1364cba37b865698cb9166e28eac4d0d7e2ed1ef3f23dbabbdc326b4ce6bbf998da1892ee9632ada41a07209e3c8896df1e27c336601d2be777e168110f6b4e3ddcd5096dd12ed3db535a6b8616ed55646d5f42cb5b8788b693e1e7706ff40ba70de6f1293a63f03aa0520e1857a51e6f44dfbefdeb8daa61b33621a543e4d7242142e51aac08484a9c93e311daaab86f51bfa34660076a57a8169175db79982bf779246d2040c37cfc4e66bfce3bad8e2cef138c57e9f9939fc6f088cd62de0944d1f73d2653778bbe665ea8ce15d06a22dce2387c274d641331562018d2a37281db03335a3789688f8 ------ ST Private Key: 46d4b3e40b0a45f9bfab045faff7fb157dce4dc5c71caf4411df231428e83f3b0139f9fb4d2e9bd878a2b0a83a145abf463a32ae37caaea0b679a369b7a4567e3b1e42a57af016e47d6540a9802f2771fdf53c9f8506b637854bf483da590ded287fb43b4f3edfc8801aa32f358b76b89a83dfd192154bc45291caf31244f6c7fe8eee8e44091564bd2b1c82faa3a2bd8c79db56ccb140c84ef92fc4ce6a8647eaaeeda3eaa6720c96e696c982cd76d51fe404280ee7096db53ff01087699b9f2ab816b0c61f9725afde4afe9a270fb87d208b3b927913c1f11be002b7589008c892790deddb67f4c63aab04bcb00dc7c8bba4dec5fe4f966e2c1a332d35faef ST Public Key: 78bbdc4d210d5784bab05bdc68e3c170f77f7adcede7a0c205df4e5416fddd0482717e5020d7f871bd8c04b8e851e0c5da72af96dd124259b759a6ebecbc230e44dfc3eeeef02221ebc7bab20704d1935480bb03605bfcfac31c5e66803771cfabbe029e28620de3f0f4637de4ad5871227d451710b33d9d8eae801e3657d5ee864c6e96951bfadee6e398b71ceda31e61e24685c765b9a63d16bd75cbac34e4093c6f7ba833f447abd5b4778fba145ab5b18e02ad2cc70bc217f85d568ba3445bc9f2a83d446047cb11f2f902078d2dd71250f5443bd634c286334916e1d4d99294a73af6fffa8fb722b39b7a4ca00cf7205663bb61d8f0314ed110ed619fab ------ J5 Session Key: 1e30adb4b9488cbdae04e5c4bb01228ef3f9dcda83f643243ab13199bef55d6e0a828d54f01bd2f8192f89eaca6f221749e172bdd81a0e16c38d1f7775cc2ab4c673a1ac3a05cd39511e5e1ee03a1c741453cfd599f8a49a3ddb8011decc1edaaccda5d276ab4950de6b1e04ff0d770f5d6624a1b3ec6d564a0e1fd4440c08f68c07c633299ae575531117d56e7385f402238c78440dbbd37cf78b70c66a9de5087f911e76056f8f88ab29bb44448b092757e9d3a4224748383584fd5022c070766423a65957eeeff55cba16f991b445d3c93d6b03f2808df199e5d43ac87b4573f641ca0a978695392975f0d6b4d2c035e34bf2ab3c8b1b184bce645fd53eb3 ST Session Key: 1e30adb4b9488cbdae04e5c4bb01228ef3f9dcda83f643243ab13199bef55d6e0a828d54f01bd2f8192f89eaca6f221749e172bdd81a0e16c38d1f7775cc2ab4c673a1ac3a05cd39511e5e1ee03a1c741453cfd599f8a49a3ddb8011decc1edaaccda5d276ab4950de6b1e04ff0d770f5d6624a1b3ec6d564a0e1fd4440c08f68c07c633299ae575531117d56e7385f402238c78440dbbd37cf78b70c66a9de5087f911e76056f8f88ab29bb44448b092757e9d3a4224748383584fd5022c070766423a65957eeeff55cba16f991b445d3c93d6b03f2808df199e5d43ac87b4573f641ca0a978695392975f0d6b4d2c035e34bf2ab3c8b1b184bce645fd53eb3 Elliptic-curve Diffie-Hellman (ECDH) # Demo code NodeJS\nconst crypto = require(\u0026#39;crypto\u0026#39;); // J5 const J5 = crypto.createECDH(\u0026#39;secp256k1\u0026#39;); // Use secp256k1 curve J5.generateKeys(); const J5_privateKey = J5.getPrivateKey(); const J5_publicKey = J5.getPublicKey(); console.log(\u0026#34;J5 Private Key:\u0026#34;, J5_privateKey.toString(\u0026#39;hex\u0026#39;)); console.log(\u0026#34;J5 Public Key:\u0026#34;, J5_publicKey.toString(\u0026#39;hex\u0026#39;)); console.log(\u0026#39;------\u0026#39;); // ST const ST = crypto.createECDH(\u0026#39;secp256k1\u0026#39;); ST.generateKeys(); const ST_privateKey = ST.getPrivateKey(); const ST_publicKey = ST.getPublicKey(); console.log(\u0026#34;ST Private Key:\u0026#34;, ST_privateKey.toString(\u0026#34;hex\u0026#34;)); console.log(\u0026#34;ST Public Key:\u0026#34;, ST_publicKey.toString(\u0026#34;hex\u0026#34;)); console.log(\u0026#39;------\u0026#39;); // Exchange public keys and compute the session key const J5_SessionKey = J5.computeSecret(ST_publicKey); const ST_SessionKey = ST.computeSecret(J5_publicKey); console.log(\u0026#34;J5 Session Key:\u0026#34;, J5_SessionKey.toString(\u0026#39;hex\u0026#39;)); console.log(\u0026#34;ST Session Key:\u0026#34;, ST_SessionKey.toString(\u0026#39;hex\u0026#39;)); Output\nJ5 Private Key: b63f1be5cbccc1a2600e00e1df88b9ad5da603e05cc04c6e0c36185c01ed76f1 J5 Public Key: 04b814f0659792bb510b682bdd1a00ab729abaa2ad177a04453670ae79f7de5342931c773eed012195a1ff0e9fb60eef13310b0938e472d5b51bdb7659a961a4db ------ ST Private Key: 5749d6da1161b582a463a49759627bcb1dcd2d77592d7509bedb86abe046e62a ST Public Key: 046c8f16a93320a034926af4f62300d138686e80d90b25de30c87550d4483e4245440142c4ff386d48fadc46b7ebe280b767bd49c6daf643dc50ae3c941c5655db ------ J5 Session Key: 157d9a740b720f62bd057888d02e806f5f50cebf9e0ffab831243d71152def41 ST Session Key: 157d9a740b720f62bd057888d02e806f5f50cebf9e0ffab831243d71152def41 Digital signatures # Prove message authenticity and integrity Non-repudiation Use asymmetric encryption How # The message is signed by the private key The signature is verified by the corresponding public key Use cases # Sign contracts Sign and approve payments in the bank systems Signed transactions allow users to transfer a blockchain asset from one address to another Demo # This demo can be run directly in the console of the Chrome browser Javascript\nPrepare const generateKeyPair = async () =\u0026gt; { const keyPair = await crypto.subtle.generateKey( { name: \u0026#34;RSASSA-PKCS1-v1_5\u0026#34;, modulusLength: 2048, publicExponent: new Uint8Array([1, 0, 1]), hash: \u0026#34;SHA-256\u0026#34;, }, true, [\u0026#34;sign\u0026#34;, \u0026#34;verify\u0026#34;] ); return keyPair; } const signMessage = async (message, privateKey) =\u0026gt; { const encodedMessage = new TextEncoder().encode(message); const signature = await crypto.subtle.sign( { name: \u0026#34;RSASSA-PKCS1-v1_5\u0026#34;, }, privateKey, encodedMessage ); return arrayBufferToHex(signature); }; const verifySignature = async (message, hexSignature, publicKey) =\u0026gt; { const encodedMessage = new TextEncoder().encode(message); const signatureBuffer = hexToArrayBuffer(hexSignature); return await crypto.subtle.verify( { name: \u0026#34;RSASSA-PKCS1-v1_5\u0026#34;, }, publicKey, signatureBuffer, encodedMessage ); }; const arrayBufferToHex = (buffer) =\u0026gt; { return Array.from(new Uint8Array(buffer)) .map((byte) =\u0026gt; byte.toString(16).padStart(2, \u0026#39;0\u0026#39;)) .join(\u0026#39;\u0026#39;); }; const hexToArrayBuffer = (hex) =\u0026gt; { const typedArray = new Uint8Array(hex.match(/[\\da-f]{2}/gi).map((h) =\u0026gt; parseInt(h, 16))); return typedArray.buffer; }; Main flow (async () =\u0026gt; { const { privateKey, publicKey } = await generateKeyPair(); let message = \u0026#34;I\u0026lt;3U\u0026#34;; console.log(\u0026#34;Message:\u0026#34;, message); // ST-Sender signs the message const signatureHex = await signMessage(message, privateKey); console.log(\u0026#34;Signature (Hex):\u0026#34;, signatureHex); // HT-Hacker modifies the original message message = \u0026#34;I hate you\u0026#34;; console.log(\u0026#34;Message:\u0026#34;, message); // Rose-Receiver verifies the signature const isValid = await verifySignature(message, signatureHex, publicKey); console.log(\u0026#34;Is the signature valid?\u0026#34;, isValid); })(); Output \u0026gt; Message: I\u0026lt;3U \u0026gt; Signature (Hex): 02195d3ee8155a2581f7bf3f784347f2dfbbf352113c5a4489721a7dc5f6b2b2304d3dba1a83f596cd8420e8b8b2beb3bc0e6872d83eb4d430382603c2fb75f875698d19d1212b926c79ee2b8ef08b03a6715bb0eb7d518b7b773d28805aef533836a6f906034fa602958ce769ffa436d8223ba6bf5c144f596ffa64ce0bbaa917157b54d58a0c50c877c7a38583bdcd6ed3d55d2d9d5fd3d8227d387a9b42e3c6d20b7b24d4febf32d771557ed87863cab19db293da28100a7ee2eaba706156f93dba44c20c39c73ef1ae51cdbf511acf063441040d6917fbc68a077ec1a17dfa68cc2208ffb6b06085674fcbe316dfe7102b07ac8dca029ec2e17d4a8ec173 \u0026gt; Message: I hate you \u0026gt; Is the signature valid? false Appendix # Bcrypt vs MD5 # Cracking password time Bcrypt # MD5 # Compare speed # Maximun byte RSA-4096-PKCS1 can encrypt: 470 bytes Name Encrypt Decrypt SHA512 0.34 ms N/A AES-256-GCM 0.43 ms 0.14 ms RSA-4096-PKCS1-encrypt 0.30 ms 2.83 ms RSA-4096-PKCS1-sign 2.66 ms 0.16 ms NodeJS const crypto = require(\u0026#39;crypto\u0026#39;); const { performance } = require(\u0026#39;perf_hooks\u0026#39;); function measurePerformance(func, ...args) { const startTime = performance.now(); const result = func(...args); const endTime = performance.now(); console.log(`${func.name} execution time:`, (endTime - startTime).toFixed(2), \u0026#39;ms\u0026#39;); return result; } function hashSHA512(message) { const hash = crypto.createHash(\u0026#39;sha512\u0026#39;); hash.update(message); return hash; } function generateKeyAndIV() { const key = crypto.randomBytes(32); // 256-bit key (32 bytes, the longest allowed by AES) const iv = crypto.randomBytes(12); // 96-bit IV (12 bytes, recommended for GCM) return { key, iv }; } function encryptAESGCM(key, iv, plaintext) { const cipher = crypto.createCipheriv(\u0026#39;aes-256-gcm\u0026#39;, key, iv); const encryptedAES = Buffer.concat([cipher.update(plaintext, \u0026#39;utf8\u0026#39;), cipher.final()]); const authTag = cipher.getAuthTag() return { encryptedAES, authTag }; } function decryptAESGCM(key, iv, encrypted, authTag) { const decipher = crypto.createDecipheriv(\u0026#39;aes-256-gcm\u0026#39;, key, iv); decipher.setAuthTag(authTag); const decrypted = Buffer.concat([decipher.update(encrypted), decipher.final()]); return decrypted; } const generateKeyPair = () =\u0026gt; { return crypto.generateKeyPairSync(\u0026#39;rsa\u0026#39;, { modulusLength: 4096, publicKeyEncoding: { type: \u0026#39;pkcs1\u0026#39;, // Public Key Cryptography Standards 1 format: \u0026#39;pem\u0026#39; // Output as PEM (Base64 encoded) }, privateKeyEncoding: { type: \u0026#39;pkcs1\u0026#39;, // Private Key Cryptography Standards 1 format: \u0026#39;pem\u0026#39; // Output as PEM (Base64 encoded) } }); } function encryptWithPublicKey(publicKeyPem, message) { const encrypted = crypto.publicEncrypt(publicKeyPem, Buffer.from(message)); return encrypted; } function decryptWithPrivateKey(privateKeyPem, encryptedMessage) { const decrypted = crypto.privateDecrypt(privateKeyPem, encryptedMessage); return decrypted; } function signWithPrivateKey(privateKeyPem, message) { const encrypted = crypto.privateEncrypt(privateKeyPem, Buffer.from(message)); return encrypted; } function verifyWithPublicKey(publicKeyPem, encryptedMessage) { const decrypted = crypto.publicDecrypt(publicKeyPem, encryptedMessage); return decrypted; } function generateDummyText(byteLength) { const characters = \u0026#39;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\u0026#39;; const charactersLength = characters.length; let result = \u0026#39;\u0026#39;; let currentLength = 0; while (currentLength \u0026lt; byteLength) { const char = characters.charAt(Math.floor(Math.random() * charactersLength)); result += char; currentLength = Buffer.byteLength(result, \u0026#39;utf8\u0026#39;); if (currentLength \u0026gt; byteLength) { result = result.slice(0, -1); break; } } return result; } const message = generateDummyText(470); // Maximun byte RSA-4096-PKCS1 can encrypt console.log(\u0026#34;Original Message:\u0026#34;, message); const { publicKey, privateKey } = generateKeyPair(); const { key, iv } = generateKeyAndIV(); const hash = measurePerformance(hashSHA512, message); const { encryptedAES, authTag } = measurePerformance(encryptAESGCM, key, iv, message) const decryptedAES = measurePerformance(decryptAESGCM, key, iv, encryptedAES, authTag); const encryptedMessage = measurePerformance(encryptWithPublicKey, publicKey, message); const decryptedMessage = measurePerformance(decryptWithPrivateKey, privateKey, encryptedMessage); const signedMessage = measurePerformance(signWithPrivateKey, privateKey, message); const verifiedMessage = measurePerformance(verifyWithPublicKey, publicKey, signedMessage); console.log(\u0026#34;SHA-512 hashed message:\u0026#34;, hash.digest(\u0026#39;hex\u0026#39;)); console.log(\u0026#34;AES decrypted message:\u0026#34;, decryptedAES.toString(\u0026#39;utf8\u0026#39;)); console.log(\u0026#34;RSA decrypted message:\u0026#34;, decryptedMessage.toString(\u0026#39;utf8\u0026#39;)); console.log(\u0026#34;RSA verified message:\u0026#34;, verifiedMessage.toString(\u0026#39;utf8\u0026#39;)); Reference # Cryptobook: Cryptography - Overview (Jun 19th, 2019) Jscape: Understanding Hashing (May 18th, 2024) IBM: HASH_MD5, HASH_SHA1, HASH_SHA256, and HASH_SHA512 (Apr 11th, 2023) Dalhousie University: MD5 Collision Demo (Oct 11th, 2011) Hackernoon: HMAC \u0026amp; Message Authentication Codes (Aug 15th, 2023) Linkedin: What are some common use cases and best practices for HMAC in web applications? Jscape: What Is HMAC, And How Does It Secure File Transfers? (May 18th, 2024) Digicert: Asymmetric algorithms Geeksforgeeks: Node.js crypto.createECDH() Method (Oct 11th, 2021) Jscape: What is a Digital Signature? (Dec 11th, 2022) Hivesystems: Are Your Passwords in the Green? (2024) Wikipedia: Key size (Sep 18th, 2024) Townsend Security: How Much Data Can You Encrypt with RSA Keys? (Apr 1st, 2011) DangPham112000: Examples code (2024) Help improve my blog Was this page helpful to you?\nüëç Yes üëé No This page was last modified at 2024-11-15\nView this page on GitHub Report a problem with this content Can I know your name? Yes No "},{"id":7,"href":"/docs/research/token_based_authentication/","title":"Token-based Authentication","section":"RESEARCH","content":" Token-based authentication # Senario: Each time a user accesses your website containing sensitive resources, such as posting a new blog, they are required to log in repeatedly every time they visit Problem: Is there a way to allow them to log in just once and avoid re-logging in, even if their previous session was two days ago? Solution: Access tokens were designed to solve this problem Access token # Provide a one-time login for users Reduce database access for password verification, user information retrieval, and role checking Characteristics # Short-lived Stored in client-side storage Contains the user\u0026rsquo;s identity Contains a set of claims, permissions, or roles of the user Grants access to the system New problems # Problem 1: When a hacker successfully steals an access token, they can impersonate the user Solution 1: Use short-term access tokens to minimize the risk of misuse if a hacker steals one Problem 2: Requiring users to re-login every time an access token is granted leads to a poor user experience Solution 2: Refresh tokens were introduced to address this issue by allowing the generation of new access tokens without requiring the user to log in again Refresh token # To prevent hackers from stealing access tokens, access tokens were designed to be valid for a short duration Refresh tokens were introduced to re-grant access tokens when they expire, allowing users to continue their sessions seamlessly without re-login while reducing the risk of impersonation Characteristics # Long-lived Stored on the server and the client Used to obtain a new pair of access and refresh tokens How do they work together? # Basic flow # You may be curious why using separate keys for creating and verifying tokens (see this use case) Token expired # Threat mitigation strategy # Each refresh token (RT) can only be used once If a reused RT is detected, we must immediately clear all tokens and their associated keys, then force the user to re-login to the system Why does this only mitigate the hacking and not prevent it? In the picture above, if you switch the positions of the hacker and the user, you\u0026rsquo;ll see that if the hacker comes first, they will be granted a new AT and RT, and can access resources as many times as they want until the second token renewal process occurs, forcing them to re-login Authentication server standalone concept # This explains why you should use a key pair to create and verify tokens separately, instead of using a single key for both actions Demo code # This code is intended to give you insight into implementing token-based authentication; it is not my full authentication implementation You can find my complete code implementation on GitHub NodeJS\nauthUtils.js import jwt from \u0026#34;jsonwebtoken\u0026#34;; import crypto from \u0026#34;crypto\u0026#34;; export const genKeyPairRSA = () =\u0026gt; { try { const { privateKey, publicKey } = crypto.generateKeyPairSync(\u0026#34;rsa\u0026#34;, { modulusLength: 4096, publicKeyEncoding: { type: \u0026#34;pkcs1\u0026#34;, format: \u0026#34;pem\u0026#34;, }, privateKeyEncoding: { type: \u0026#34;pkcs1\u0026#34;, format: \u0026#34;pem\u0026#34;, }, }); return { privateKey, publicKey }; } catch (error) { throw new Error(\u0026#34;crypto.generateKeyPairSync got error\u0026#34;); } }; export const createTokenPair = (payload, privateKey) =\u0026gt; { try { const accessToken = jwt.sign(payload, privateKey, { algorithm: \u0026#34;RS256\u0026#34;, expiresIn: \u0026#34;60000\u0026#34;, // 1min }); const refreshToken = jwt.sign(payload, privateKey, { algorithm: \u0026#34;RS256\u0026#34;, expiresIn: \u0026#34;7 days\u0026#34;, }); return { accessToken, refreshToken }; } catch (error) { throw new Error(\u0026#34;jwt.sign got error\u0026#34;); } }; export const authentication = async (req, res, next) =\u0026gt; { const userId = req.headers[HEADER.CLIENT_ID]; if (!userId) { throw new AuthFailureError(\u0026#34;Invalid request\u0026#34;); } const keyStore = await KeyTokenService.findByUserId(userId); if (!keyStore) { throw new NotFoundError(\u0026#34;Not found any keys and token match this user\u0026#34;); } const refreshToken = req.headers[HEADER.REFRESHTOKEN]; if (refreshToken) { try { const decodeUser = jwt.verify(refreshToken, keyStore.publicKey); if (userId !== decodeUser.userId) { throw new AuthFailureError(\u0026#34;Invalid userId\u0026#34;); } req.user = decodeUser; // {userId, email} req.refreshToken = refreshToken; return next(); } catch (error) { throw error; } } const accessToken = req.headers[HEADER.AUTHORIZATION]; if (!accessToken) throw new AuthFailureError(\u0026#34;Invalid request\u0026#34;); try { const decodeUser = jwt.verify(accessToken, keyStore.publicKey); if (userId !== decodeUser.userId) { throw new AuthFailureError(\u0026#34;Invalid userId\u0026#34;); } req.user = decodeUser; // {userId, email} return next(); } catch (error) { throw error; } }; access.service.js import bcrypt from \u0026#34;bcrypt\u0026#34;; import KeyTokenService from \u0026#34;./keyToken.service.js\u0026#34;; import { createTokenPair, genKeyPairRSA } from \u0026#34;../auth/authUtils.js\u0026#34;; class AccessService { static login = async ({ email, password }) =\u0026gt; { const foundUser = await findByEmail({ email }); if (!foundUser) { throw new BadRequestError(\u0026#34;User not yet registered\u0026#34;); } const match = await bcrypt.compare(password, foundUser.password); if (!match) { throw new AuthFailureError(\u0026#34;Authentication error\u0026#34;); } const { privateKey, publicKey } = genKeyPairRSA(); const { _id: userId } = foundUser; const tokens = createTokenPair({ userId, email }, privateKey); await KeyTokenService.createKeyToken({ userId, publicKey, privateKey, refreshToken: tokens.refreshToken, }); return { user: foundUser, tokens, }; }; static handleRefreshToken = async ({ refreshToken, user }) =\u0026gt; { const { userId, email } = user; const keyStore = await KeyTokenService.findByUserId(userId); if (keyStore.refreshTokensUsed.includes(refreshToken)) { await KeyTokenService.removeByUserId(userId); throw new ForbiddenError(\u0026#34;Something wrong happen. Pls relogin\u0026#34;); } if (keyStore.refreshToken !== refreshToken) { throw new AuthFailureError(\u0026#34;Token is deleted or never exist\u0026#34;); } const foundUser = await findByEmail({ email }); if (!foundUser) { throw new AuthFailureError(\u0026#34;User is deleted or never exist\u0026#34;); } const newTokens = createTokenPair( { userId: foundUser._id, email }, keyStore.privateKey ); await KeyTokenService.updateRefreshToken( userId, newTokens.refreshToken, refreshToken ); return { user, tokens: newTokens, }; }; } export default AccessService; access.controller.js import { CREATED, SuccessResponse } from \u0026#34;../core/success.response.js\u0026#34;; import AccessService from \u0026#34;../services/access.service.js\u0026#34;; class AccessController { login = async (req, res, next) =\u0026gt; { new SuccessResponse({ metatdata: await AccessService.login(req.body), }).send(res); }; handleRefreshToken = async (req, res, next) =\u0026gt; { new SuccessResponse({ message: \u0026#34;Update token success\u0026#34;, metatdata: await AccessService.handleRefreshToken({ refreshToken: req.refreshToken, user: req.user, }), }).send(res); }; } export default new AccessController(); routes.js import express from \u0026#34;express\u0026#34;; import accessController from \u0026#34;../../controllers/access.controller.js\u0026#34;; import postController from \u0026#34;../../controllers/post.controller.js\u0026#34;; import { authentication } from \u0026#34;../../auth/authUtils.js\u0026#34;; const router = express.Router(); const asyncHandler = (fn) =\u0026gt; { return (req, res, next) =\u0026gt; { fn(req, res, next).catch(next); }; }; router.post(\u0026#34;/user/login\u0026#34;, asyncHandler(accessController.login)); // Authenticate before using restricted resources router.use(asyncHandler(authentication)); router.post(\u0026#34;/user/handleRefreshToken\u0026#34;, asyncHandler(accessController.handleRefreshToken)); router.post(\u0026#34;\u0026#34;, asyncHandler(postController.createPost)); router.patch(\u0026#34;/:postId\u0026#34;, asyncHandler(postController.updatePost)); router.get(\u0026#34;/drafts/all\u0026#34;, asyncHandler(postController.findAllDraftsOfUser)); Discussion # Question: Why do we need two tokens? Can we combine them? New approach: Use short-term access tokens (AT) and store them in the database. Track the current AT list and the used AT list. If one of the current tokens is stolen by a hacker and the hacker tries to renew the token, the old token will be stored in the used AT list. When the user attempts to renew using the old token, our server can invalidate all tokens and force both the user and the hacker to re-login Problem This approach has one weakness: Access tokens are exposed more frequently to retrieve resources, increasing the potential for them to be captured and stolen Conclusion: By keeping the refresh token separate and less exposed, the chances of a hacker being able to maintain access to our resources are reduced Do you think this approach have any other weaknesses? Reference # Geeksforgeeks: Access Token vs Refresh Token: A Breakdown (27 Sep, 2024) Auth0: What Are Refresh Tokens and How to Use Them Securely (Oct 7th, 2021) Medium: Understanding Access Tokens and Refresh Tokens (Mar 23, 2024) Help improve my blog Was this page helpful to you?\nüëç Yes üëé No This page was last modified at 2025-01-03\nView this page on GitHub Report a problem with this content Can I know your name? Yes No "},{"id":8,"href":"/docs/tips/001_unit_test/","title":"Unit Test","section":"TIPS","content":" Unit Test Tips # Reset all global variables for each unit test case # What environment the unit test cases are running on: Browser or Nodejs? # Because Nodejs does not have browser APIs Using Karma to run browser\u0026rsquo;s unit test Using JS-DOM but it\u0026rsquo;s missing a lot of browser APIs Work only when running alone # Scenario: A unit test case only pass when running alone but fail when running with other test cases Check:\nRestore all mocks after mocking things: sandbox.restore(), jest.restoreAllMocks(), vi.restoreAllMocks() and vi.unstubAllGlobals() at afterEach Reset global variables inner module: create a reset function to reset all variable of module to the initial value Example:\n// calculateThings.js import cal1Thing from \u0026#34;./private/cal1Thing.js\u0026#34;; let cached = \u0026#34;\u0026#34;; // Global variable export default (things) =\u0026gt; { if (cached) return cached; let result = []; for (let i = 0; i \u0026lt; things.length; i++) { const calculatedThing = cal1Thing(things[i]); result.push(calculatedThing); } cached = result; return cached; }; /* start-test-code */ export const testingOnly = { resetCached: () =\u0026gt; { cached = \u0026#34;\u0026#34;; }, }; /* end-test-code */ // calculateThings.test.js import calculateThings from \u0026#34;./calculateThings\u0026#34;; import cal1Thing from \u0026#34;./cal1Thing\u0026#34;; import { testingOnly } from \u0026#34;./calculateThings\u0026#34;; vi.mock(\u0026#34;./cal1Thing\u0026#34;); describe(\u0026#34;calculateThings\u0026#34;, () =\u0026gt; { const { resetCached } = testingOnly; afterEach(() =\u0026gt; { vi.restoreAllMocks(); }); it(\u0026#34;should work as expected\u0026#34;, () =\u0026gt; { cal1Thing.mockReturnValue(\u0026#34;a string\u0026#34;); const caledThings = calculateThings([1, 2, 3]); expect(caledThings).toEqual([\u0026#34;a string\u0026#34;, \u0026#34;a string\u0026#34;, \u0026#34;a string\u0026#34;]); }); it(\u0026#34;should return empty when empty cached and input is empty array\u0026#34;, () =\u0026gt; { resetCached(); // remember reset cached const caledThings = calculateThings([]); expect(caledThings).toEqual(\u0026#34;\u0026#34;); }); }); Setup code for testing only # This setup will help you export function only when run test, not appear when build Gulp - Rollup # // rollup.bundle.js import stripCode from \u0026#34;rollup-plugin-strip-code\u0026#34;; import {rollup} from rollup; const stripcode = stripCode({ start_comment: \u0026#34;start-test-code\u0026#34;, end_comment: \u0026#34;end-test-code\u0026#34;, }); export default async () =\u0026gt; { const bundle = await rollup({input: \u0026#39;mainFilePath.js\u0026#39;, plugins: [stripcode]}); await bundle.write({ file: \u0026#39;dist/destinationName.js\u0026#39;, format: \u0026#39;iife\u0026#39;, name: \u0026#39;YourObjectName\u0026#39;, sourcemap: false }) } // gulpfile.js import rollupBundle from \u0026#34;./rollup.bundle.js\u0026#34;; const clean = () =\u0026gt; { // remove all previous build files or ST like that }, lint = () =\u0026gt; { // run eslint warning }; export default () =\u0026gt; { series(clean, rollupBundle, lint); }; Vite - Vitest # Mock module # When you mock a module, everything you exported in this module will be mocked and can not act like original (even if you call vi.restoreAllMocks()) Solution:\nIf your module exports alots, and you only want to mock one thing, you should split it into another module\nExample:\n// calculateThings.js import cal1Thing from \u0026#34;./private/cal1Thing.js\u0026#34;; export default (things) =\u0026gt; { let result = []; for (let i = 0; i \u0026lt; things.length; i++) { const calculatedThing = cal1Thing(things[i]); result.push(calculatedThing); } return result; }; // calculateThings.test.js import calculateThings from \u0026#34;./calculateThings\u0026#34;; import cal1Thing from \u0026#34;./cal1Thing\u0026#34;; vi.mock(\u0026#34;./cal1Thing\u0026#34;); describe(\u0026#34;calculateThings\u0026#34;, () =\u0026gt; { afterEach(() =\u0026gt; { vi.restoreAllMocks(); }); it(\u0026#34;should work as expected\u0026#34;, () =\u0026gt; { cal1Thing.mockReturnValue(\u0026#34;a string\u0026#34;); const caledThings = calculateThings([1, 2, 3]); expect(caledThings).toEqual([\u0026#34;a string\u0026#34;, \u0026#34;a string\u0026#34;, \u0026#34;a string\u0026#34;]); }); }); Mock library # // authUtils.js import jwt from \u0026#34;jsonwebtoken\u0026#34;; export const createTokenPair = (payload, privateKey) =\u0026gt; { try { const accessToken = jwt.sign(payload, privateKey, { algorithm: \u0026#34;RS256\u0026#34;, expiresIn: \u0026#34;2 days\u0026#34;, }); const refreshToken = jwt.sign(payload, privateKey, { algorithm: \u0026#34;RS256\u0026#34;, expiresIn: \u0026#34;7 days\u0026#34;, }); return { accessToken, refreshToken }; } catch (error) { throw new Error(\u0026#34;createTokenPair got error\u0026#34;); } }; // authUtils.test.js import { describe, expect, it } from \u0026#34;vitest\u0026#34;; import { createTokenPair, genKeyPairRSA } from \u0026#34;../../src/auth/authUtils\u0026#34;; import jwt from \u0026#34;jsonwebtoken\u0026#34;; describe(\u0026#34;auth/authUtils.js\u0026#34;, () =\u0026gt; { describe(\u0026#34;createTokenPair\u0026#34;, () =\u0026gt; { afterEach(() =\u0026gt; { vi.restoreAllMocks(); vi.unstubAllGlobals(); }); it(\u0026#34;should throw error when jwt lib got error\u0026#34;, () =\u0026gt; { vi.spyOn(jwt, \u0026#34;sign\u0026#34;).mockImplementation(() =\u0026gt; { throw new Error(\u0026#34;JWT error\u0026#34;); }); const payload = { userId: 123, email: \u0026#34;a@b.co\u0026#34;, }; const { privateKey, publicKey } = genKeyPairRSA(); const toBeThrowError = () =\u0026gt; { const { accessToken, refreshToken } = createTokenPair( payload, privateKey ); }; expect(toBeThrowError).toThrowError(\u0026#34;createTokenPair got error\u0026#34;); }); }); }); Sinon # Stub a function that is called by another function in the same module # Using this.[func_name] when calling it in your module\nStub an export default function # import * as query from \u0026#34;/database/query\u0026#34;; const makeQueryStub = sandbox.stub(query, \u0026#34;default\u0026#34;).resolves([]); Mocha - Chai - Sinon sample # import sinon from \u0026#34;sinon\u0026#34;; import { function_name, callback_function_name } from \u0026#34;../module_name.js\u0026#34;; const sandbox = sinon.createSandbox(); describe(\u0026#34;module_name\u0026#34;, function () { afterEach(function () { sandbox.restore(); }); describe(\u0026#34;function_name\u0026#34;, function () { it(\u0026#34;Should be a function\u0026#34;, function () { expect(function_name).to.be.a(\u0026#34;function\u0026#34;); }); it(\u0026#34;Should return this value if window.screen is undefined\u0026#34;, function () { sandbox.stub(window, \u0026#34;screen\u0026#34;).value(undefined); expect(function_name()).equal(\u0026#34;expected string\u0026#34;); }); it(\u0026#34;should return expected object when running callback function\u0026#34;, function (done) { callback_function_name(function (returnedData) { expect(returnedData).to.deep.equal({ name: \u0026#34;expected object\u0026#34; }); done(); }); }); }); }); Jest - Sinon sample # import sinon from \u0026#34;sinon\u0026#34;; import { function_name, async_function_name } from \u0026#34;../module_name.js\u0026#34;; const sandbox = sinon.createSandbox(); describe(\u0026#34;module_name\u0026#34;, function () { afterEach(function () { sandbox.restore(); }); describe(\u0026#34;function_name\u0026#34;, function () { it(\u0026#34;Should be a function\u0026#34;, function () { expect(typeof function_name).toEqual(\u0026#34;function\u0026#34;); }); it(\u0026#34;Should return this value if window.screen is undefined\u0026#34;, function () { sandbox.stub(window, \u0026#34;screen\u0026#34;).value(undefined); expect(function_name()).toEqual(\u0026#34;expected string\u0026#34;); }); it(\u0026#34;should return expected object when handling function asynchronously\u0026#34;, async () =\u0026gt; { const returnedData = await async_function_name(); expect(returnedData).toEqual({ name: \u0026#34;expected object\u0026#34; }); }); }); }); Help improve my blog Was this page helpful to you?\nüëç Yes üëé No This page was last modified at 2024-01-06\nView this page on GitHub Report a problem with this content Can I know your name? Yes No "},{"id":9,"href":"/docs/problems/knight_dialer/","title":"Knight Dialer","section":"PROBLEMS","content":" Knight dialer # Description # The chess knight has a unique movement, it may move two squares vertically and one square horizontally, or two squares horizontally and one square vertically (with both forming the shape of an L). The possible movements of chess knight are shown in this diagaram:\nA chess knight can move as indicated in the chess diagram below: We have a chess knight and a phone pad as shown below, the knight can only stand on a numeric cell (i.e. blue cell). Given an integer n, return how many distinct phone numbers of length n we can dial.\nYou are allowed to place the knight on any numeric cell initially\nand then you should perform n - 1 jumps to dial a number of length n. All jumps should be valid knight jumps.\nAs the answer may be very large, return the answer modulo \\(10^9 \u0026#43; 7\\) Example 1:\nInput: n = 1\nOutput: 10\nExplanation: We need to dial a number of length 1, so placing the knight over any numeric cell of the 10 cells is sufficient\nExample 2:\nInput: n = 2\nOutput: 20\nExplanation: All the valid number we can dial are [04, 06, 16, 18, 27, 29, 34, 38, 40, 43, 49, 60, 61, 67, 72, 76, 81, 83, 92, 94]\nExample 3:\nInput: n = 3131\nOutput: 136006598\nExplanation: Please take care of the mod\nConstraints:\n1 \u0026lt;= n \u0026lt;= 5000 Solution # High level # C√≥ th·ªÉ th·∫•y b√†n ph√≠m ƒëi·ªán tho·∫°i kh√° nh·ªè Ta c√≥ th·ªÉ t·∫≠n d·ª•ng c√°c gi·ªõi h·∫°n n√†y ƒë·ªÉ gi·∫£i quy·∫øt b√†i to√°n thay v√¨ ƒë√¢m ƒë·∫ßu v√†o m·ªôt c√¥ng th·ª©c t·ªïng qu√°t: ·ªû m·ªôt v·ªã tr√≠ ch·ªâ c√≥ th·ªÉ nh·∫£y ƒë·∫øn 1 t·∫≠p gi·ªõi h·∫°n c√°c v·ªã tr√≠ kh√°c S·ªë c√°ch di chuy·ªÉn ·ªü m·ªói v·ªã tr√≠ l√† h·∫±ng s·ªë v√† c√≥ th·ªÉ li·ªát k√™ ƒë∆∞·ª£c Low level # Ta n√™n b·∫Øt ƒë·∫ßu b·∫±ng 1 v√≠ d·ª•: ƒë·∫πp nh·∫•t l√† n = 3\n·ªû l·∫ßn ƒë·∫ßu th√¨ v·ªã tr√≠ l√† t·∫•t c·∫£ c√°c n√∫t ·ªû l·∫ßn 2 th√¨ c·∫ßn duy·ªát qua t·ª´ 0 ƒë·∫øn 9 v·ªã tr√≠ 0 s·∫Ω c√≥ th·ªÉ nh·∫£y ƒë·∫øn 4 v√† v·ªã tr√≠ 1 s·∫Ω c√≥ th·ªÉ nh·∫£y ƒë·∫øn 8 v√† \u0026hellip; ·ªû l·∫ßn 3 th√¨ ta s·∫Ω duy·ªát ti·∫øp b√™n trong v·ªã tr√≠ 0 ·ªü l·∫ßn 2 v·ªã tr√≠ 4 s·∫Ω c√≥ th·ªÉ nh·∫£y ƒë·∫øn 3, 9 v√† 0 v·ªã tr√≠ 6 s·∫Ω c√≥ th·ªÉ nh·∫£y ƒë·∫øn 1, 7 v√† 0 trong v·ªã tr√≠ 1 ·ªü l·∫ßn 2 8 =\u0026gt; 1, 3 6 =\u0026gt; 1, 7, 0 \u0026hellip; C√°c k·∫øt qu·∫£ c·∫ßn t√¨m\nV·ªõi n = 1, return 10 V·ªõi n = 2, 0 c√≥ th·ªÉ ƒë·∫øn 4 v√† 6, 1 c√≥ th·ªÉ ƒë·∫øn 8 v√† 6 V·ªõi n = 3, 0 c√≥ th·ªÉ ƒë·∫øn 3, 9, 0, 1, 7, 0 1 c√≥ th·ªÉ ƒë·∫øn 1, 3, 1, 7, 0 K·∫øt qu·∫£ l√† t·ªïng s·ªëng l∆∞·ª£ng v·ªã tr√≠ c√≥ th·ªÉ ƒë·∫øn\nC·∫ßn t·∫°o 1 m·∫£ng ch·ª©a c√°c v·ªã tr√≠ kh·∫£ d·ª•ng qua m·ªói l·∫ßn l·∫∑p n C√≥ th·ªÉ th·∫•y ta c√≥ th·ªÉ t·∫°o 2 m·∫£ng\nM·∫£ng s·ªë v·ªã tr√≠ kh·∫£ d·ª•ng k·∫ø ti·∫øp khi ·ªü v·ªã tr√≠ i: [[4, 6], [8, 6], []] C√≥ th·ªÉ th·∫•y ƒë·ªÉ d√πng ƒë∆∞·ª£c m·∫£ng v·ªã tr√≠ kh·∫£ d·ª•ng th√¨ n ph·∫£i \u0026gt;= 2 V·∫≠y th√¨ thu·∫≠t to√°n c·∫ßn t√¨m ph·∫£i b·∫Øt ƒë·∫ßu √≠t nh·∫•t t·ª´ 2 Code /** * @param {number} n * @return {number} */ var knightDialer = function (n) { const nextPlaces = [ [4, 6], [6, 8], [7, 9], [4, 8], [0, 3, 9], [], [0, 1, 7], [2, 6], [1, 3], [2, 4], ]; if (n === 1) return 10; const validPlaces = JSON.parse(JSON.stringify(nextPlaces)); for (let time = 3; time \u0026lt;= n; time++) { for (let place = 0; place \u0026lt;= 9; place++) { const newPlaces = []; for (let i = 0; i \u0026lt; validPlaces[place].length; i++) { newPlaces.push(...nextPlaces[validPlaces[place][i]]); } validPlaces[place] = newPlaces; } } const totalWays = validPlaces.reduce((acc, currentArray) =\u0026gt; acc + currentArray.length, 0) % (Math.pow(10, 9) + 7); return totalWays; }; Xu·∫•t hi·ªán l·ªói runtime error: C·ª• th·ªÉ th√¨ l√† do out of memory\nKhi th·ª≠ v·ªõi c√°c test case nh·ªè th√¨ d·ªÖ th·∫•y h√†m c·ªßa ch√∫ng ta work nh∆∞ mong ƒë·ª£i Nh∆∞ng khi th·ª≠ v·ªõi s·ªë l·ªõn th√¨ s·∫Ω xu·∫•t hi·ªán l·ªói out of memory Gi·∫£i thu·∫≠t ch∆∞a t·ªëi ∆∞u b·ªô nh·ªõ ? Ch·ªçn c·∫•u tr√∫c d·ªØ li·ªáu ch∆∞a ph√π h·ª£p ? Optimize # Retrospective # C√πng nh√¨n l·∫°i c√°ch di·ªÖn gi·∫£i ban ƒë·∫ßu:\nn = 1: t·∫•t c·∫£ c√°c n√∫t\n==\u0026gt; [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]] n = 2: 0 c√≥ th·ªÉ ƒë·∫øn 4 v√† 6 1 c√≥ th·ªÉ ƒë·∫øn 8 v√† 6 2 c√≥ th·ªÉ ƒë·∫øn 7 v√† 9 \u0026hellip;\n==\u0026gt; [[4, 6], [6, 8], [7, 9], [4, 8], [0, 3, 9], [], [0, 1, 7], [2, 6], [1, 3], [2, 4]] n = 3: 0 c√≥ th·ªÉ ƒë·∫øn 3, 9, 0, 1, 7, 0 1 c√≥ th·ªÉ ƒë·∫øn 1, 3, 1, 7, 0 \u0026hellip;\n==\u0026gt; [[3, 9, 0, 1, 7, 0], [1, 3, 1, 7, 0], ...] \u0026hellip; D·ªÖ th·∫•y n c√†ng cao s·ªë ph·∫ßn t·ª´ tr√πng l·∫∑p l·∫°i trong m·∫£ng c√†ng cao V·ªõi m·ªói ph·∫ßn t·ª≠ tr√πng ·∫•y ta l·∫°i c√≥ c√πng m·ªôt c√¥ng vi·ªác cho ch√∫ng K·∫øt qu·∫£ c·∫ßn t√¨m l·∫°i l√† ƒë·∫øm s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ c·ªßa t·ª´ng m·∫£ng ==\u0026gt; N·∫øu c√≥ th·ªÉ √°p d·ª•ng c·∫•u tr√∫c Dictionary s·∫Ω l√† m·ªôt ph∆∞∆°ng ph√°p t·ªëi ∆∞u\nNew way # C√°ch di·ªÖn d√£i m·ªõi\nn = 1\n==\u0026gt; dic = {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1}\n==\u0026gt; dic = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n==\u0026gt; N√™n ch·ªçn array v√¨ key ch√∫ng ta c·∫ßn ch·ªâ l√† c√°c con s·ªë t·ª´ 0-\u0026gt;9 n = 2 0 c√≥ th·ªÉ ƒë·∫øn 4 v√† 6 =\u0026gt; newDic[4] += dic[0] v√† newDic[6] += dic[0] newDic[4] += dic[0] v√¨ gi·∫£ s·ª≠ v·ªã tr√≠ 0 ƒëang ch·ª©a 2 kh·∫£ nƒÉng, th√¨ 2 kh·∫£ nƒÉng ƒë√≥ ƒë·ªÅu ƒëi ƒë·∫øn ƒë∆∞·ª£c 4 D√πng newDic l√† ƒë·ªÉ tr·∫°ng th√°i c≈© k b·ªã x√°o tr·ªôn khi ƒëang duy·ªát 1 c√≥ th·ªÉ ƒë·∫øn 8 v√† 6 =\u0026gt; newDic[8] += dic[1] v√† newDic[6] += dic[1] \u0026hellip; Code /** * @param {number} n * @return {number} */ var knightDialer = function (n) { const nextPlaces = [ [4, 6], [6, 8], [7, 9], [4, 8], [0, 3, 9], [], [0, 1, 7], [2, 6], [1, 3], [2, 4], ]; if (n === 1) return 10; let dic = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]; for (let time = 2; time \u0026lt;= n; time++) { const newDic = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]; for (let place = 0; place \u0026lt;= 9; place++) { for (let i = 0; i \u0026lt; nextPlaces[place].length; i++) { newDic[nextPlaces[place][i]] += dic[place] % (Math.pow(10, 9) + 7); } } dic = newDic; } const totalWays = dic.reduce((acc, item) =\u0026gt; acc + item, 0) % (Math.pow(10, 9) + 7); return totalWays; }; Time and space complexity optimize # Code Ti√™u ch√≠ l√† √≠t t√≠nh to√°n l·∫°i v√† t·∫≠n d·ª•ng nhi·ªÅu h∆°n # /** * @param {number} n * @return {number} */ var knightDialer = function (n) { const nextPlaces = [ [4, 6], [6, 8], [7, 9], [4, 8], [0, 3, 9], [], [0, 1, 7], [2, 6], [1, 3], [2, 4], ]; if (n === 1) return 10; const mod = Math.pow(10, 9) + 7; let dic = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], newDic = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], place, i; for (let time = 2; time \u0026lt;= n; time++) { newDic = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]; for (place = 0; place \u0026lt;= 9; place++) { if (place === 5) continue; for (i = 0; i \u0026lt; nextPlaces[place].length; i++) { newDic[nextPlaces[place][i]] += dic[place] % mod; } } dic = newDic; } const totalWays = dic.reduce((acc, item) =\u0026gt; acc + item, 0) % mod; return totalWays; }; Reference # Leetcode: knight dialer Help improve my blog Was this page helpful to you?\nüëç Yes üëé No This page was last modified at 2023-11-15\nView this page on GitHub Report a problem with this content Can I know your name? Yes No "},{"id":10,"href":"/docs/tips/002_git/","title":"Git","section":"TIPS","content":" Git - Github Tips # Terminology # HEAD: your current local working branch origin: the address to your remote git, represent for remote repo Tracked file: the file git already had before, so when you edit it, git knows this file is modified (M files)\nUntracked (new file): the file recently add and git don‚Äôt know anything about it (U files)\nRemote-tracking branches: References (in the form of origin/branch-name) that point to the branches in a remote repository Commit # git add . git commit -m \u0026#34;commit message\u0026#34; These 2 commands above can combie into 1:\ngit commit -am \u0026#34;commit message\u0026#34; Note: this only work with tracked files\nChange previous commit message # Commit amend # git commit --amend -m \u0026#34;new message to replace the previous message\u0026#34; Note: this amend can also simplify by amen :))))\nRebase reword # git rebase -i HEAD~1 Vim IDE appear and show a latest commit type i to begin insert mode, ready to modify change pick to r or reword ‚Üí means you will change this commit message press ESC key to end insert mode type :wq to save new Vim IDE appear to let you change the commit message change and save like the early steps git push -f Opps! Code on wrong branch # Stash # git stash git checkout correct-branch git stash pop Note: git stash will only bring the changes on tracked files to store but don\u0026rsquo;t worry when checkout to other branch, the untracked files will move to there also\nOpps! Commit into local main branch # Reset # Solution 1: Erase the current commit and go back to the earlier commit\ngit reset --hard HEAD~1 Solution 2: Bring the current commit to staged change and go back to the earlier commit\ngit reset --soft HEAD~1 Update the outdated feature branch # Relocate branch: rebase # before rebase\n==\u0026gt; after rebase\ngit checkout master git pull git rebase master topic git push -f Note: topic branch will have code from F and G of main branch, but if it conflicts with topic branch, the solution will be the same here\nClean up messy commits # Accumulate commits: rebase fixup # If you have 3 messy commits per 4 commits on your feature branch\ngit rebase -i HEAD~4 Vim IDE appear and show 4 latest commits Type i to change into insert mode Change pick to f or fixup ‚Üí means you accumulate this 3 commits Out insert mode with ESC key Type :wq to save\ngit push -f before after Note: the present commit will have all changes from 3 previous commits\nDelete all local branches except main branch # git branch | grep -v \u0026#34;main\u0026#34; | xargs git branch -D Explain:\nGet all branches (except for the main) via git branch | grep -v \u0026quot;main\u0026quot; command Select every branch with xargs command Delete branch with git branch -D Clean up outdated references # It only removes remote-tracking branches that no longer exist on the remote All local branches you‚Äôve created yourself won‚Äôt be affected git fetch --prune Refresh outdated local branch # If you pull but show some warnings or errors and git show a recommend that is need to type some rebase commands Just checkout to another branch, delete your local conflict branch and then checkout to this branch again to download a latest one in remote repo git checkout dev git branch -D feature-branch git fetch git checkout feature-branch Ignore all modified and new files and pull the latest version # # Discard local changes (tracked files) git reset --hard # Clean untracked files git clean -fd # Pull the latest git pull Note: If you\u0026rsquo;re unsure, stash your changes first so you can recover them later with git stash\nMerge PR but get stuck in conflict # Relocate branch: rebase # git checkout main git pull checkout feature-branch git rebase main feature-branch Conflict appears in IDE\n‚Üí Resolve conflict and save file git add . git rebase --continue Vim IDE appear to make you confirm change\n‚Üí :wq git push -f Remote origin # Check remote origin # git remote -v Change remote origin # git remote set-url origin \u0026lt;url\u0026gt; # E.g git remote set-url origin git://new.url.here Remove remote origin # git remote remove origin Log pretty # git log --graph --decorate --oneline or\ngit log --graph --decorate Config # Show current global credential # git config --global --list Configure local repo‚Äôs credential # when you want it‚Äôs different with the global one\ngit config user.name DangPham112000 git config user.email dangpham112000@gmail.com Switch git user tool # Git-User-Switch Connecting to GitHub using SSH keys (Ubuntu) # Checking for existing SSH keys # ls -al ~/.ssh Check the existing of these files:\nid_rsa.pub id_ecdsa.pub id_ed25519.pub Generating a new SSH key # ssh-keygen -t ed25519 -C \u0026#34;dangpham112000@gmail.com\u0026#34; You can skip all the prompted by Enter\nAdding your SSH key to the ssh-agent # Start the ssh-agent in the background\n$ eval \u0026#34;$(ssh-agent -s)\u0026#34; \u0026gt; Agent pid 59566 Add your SSH private key to the ssh-agent\nssh-add ~/.ssh/id_ed25519 Adding a new SSH key to account # Copy the SSH public key to your clipboard\ncat ~/.ssh/id_ed25519.pub Then select and copy the contents of the id_ed25519.pub file displayed in the terminal to your clipboard\nIn the upper-right corner of any page on GitHub, click your profile photo, then click Settings\nIn the \u0026ldquo;Access\u0026rdquo; section of the sidebar, click SSH and GPG keys\nClick New SSH key or Add SSH key\nIn the \u0026ldquo;Title\u0026rdquo; field, add a descriptive label for the new key. For example, if you\u0026rsquo;re using a personal laptop, you might call this key \u0026ldquo;Personal laptop\u0026rdquo;\nSelect the type of key, either authentication or signing\nIn the \u0026ldquo;Key\u0026rdquo; field, paste your public key\nClick Add SSH key\nTesting your SSH connection # ssh -T git@github.com You may see a message like this: Hi DangPham112000! You've successfully authenticated, but GitHub does not provide shell access.\nHelp improve my blog Was this page helpful to you?\nüëç Yes üëé No This page was last modified at 2024-12-31\nView this page on GitHub Report a problem with this content Can I know your name? Yes No "},{"id":11,"href":"/docs/research/security/","title":"Security - Draft","section":"RESEARCH","content":" Security # Explore your site\u0026rsquo;s vulnerabilities # # IPv4 sudo nmap --script vuln [IPv4] # IPv6 sudo nmap -6 --script vuln [IPv6] # E.g IPv4 sudo nmap --script vuln 18.141.184.34 # E.g IPv6 sudo nmap -6 --script vuln 2606:4700:3033::ac43:b865 Example output Starting Nmap 7.94SVN ( https://nmap.org ) at 2024-12-05 09:00 +07 Nmap scan report for ec2-18-141-184-34.ap-southeast-1.compute.amazonaws.com (18.141.184.34) Host is up (0.033s latency). Not shown: 997 filtered tcp ports (no-response) PORT STATE SERVICE 22/tcp open ssh 80/tcp open http |_http-csrf: Couldn\u0026#39;t find any CSRF vulnerabilities. |_http-dombased-xss: Couldn\u0026#39;t find any DOM based XSS. | http-vuln-cve2011-3192: | VULNERABLE: | Apache byterange filter DoS | State: VULNERABLE | IDs: BID:49303 CVE:CVE-2011-3192 | The Apache web server is vulnerable to a denial of service attack when numerous | overlapping byte ranges are requested. | Disclosure date: 2011-08-19 | References: | https://www.securityfocus.com/bid/49303 | https://www.tenable.com/plugins/nessus/55976 | https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2011-3192 |_ https://seclists.org/fulldisclosure/2011/Aug/175 |_http-stored-xss: Couldn\u0026#39;t find any stored XSS vulnerabilities. 443/tcp open https |_http-csrf: Couldn\u0026#39;t find any CSRF vulnerabilities. |_http-stored-xss: Couldn\u0026#39;t find any stored XSS vulnerabilities. | http-vuln-cve2011-3192: | VULNERABLE: | Apache byterange filter DoS | State: VULNERABLE | IDs: BID:49303 CVE:CVE-2011-3192 | The Apache web server is vulnerable to a denial of service attack when numerous | overlapping byte ranges are requested. | Disclosure date: 2011-08-19 | References: | https://www.securityfocus.com/bid/49303 | https://www.tenable.com/plugins/nessus/55976 | https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2011-3192 |_ https://seclists.org/fulldisclosure/2011/Aug/175 |_http-dombased-xss: Couldn\u0026#39;t find any DOM based XSS. Nmap done: 1 IP address (1 host up) scanned in 193.10 seconds Brute Force Attack # Every password-based system and encryption key out there can be cracked using a brute force attack. There is only one problem with this attack: the time. Why does the hashing method matter when cracking passwords with a brute force attack? Bcrypt will take longer to crack than MD5 Use case # Cracking passwords (SSH logins) Cracking encryption keys (API keys) How it works # The hacker have to run through every possible combination of characters before achieving their goal These attacks are often carried out by scripts or bots that target specific systems or accounts Prevention # Longer password Delay response: A system that responds immediately is not always good. Adding a delay when checking passwords, even a delay of a few seconds, can greatly weaken the effectiveness of a brute force attack Stronger hashing method Two-factor authentication Rate limit Dictionary Attack # Use case # A dictionary attack is a method of breaking into a password-protected computer, network or other IT resource by systematically entering every word in a dictionary, or word list, as a password A dictionary attack can also be used in an attempt to find the key necessary to decrypt an encrypted message or document How it works # If it targets an organization or a particular person, the dictionary can collect all the closely related words around the target they want to hack. It can then combine all of them in all possible ways and try each combination to guess the password or key they want to hack Prevention # Avoid passwords: Passwords can\u0026rsquo;t be hacked if we don\u0026rsquo;t use them for login (I\u0026rsquo;m joking). From a system perspective, we can completely avoid them by using password-free authentication solutions and biometric logins Random passwords: From a user perspective, don\u0026rsquo;t use closely related information (like names, pets, birthdays) or easy-to-predict words (like \u0026ldquo;password,\u0026rdquo; \u0026ldquo;abcd,\u0026rdquo; \u0026ldquo;xyz,\u0026rdquo; \u0026ldquo;123\u0026rdquo;) to create a password. Instead, use random strings. If you find them difficult to remember, you can use a third-party password manager to store them (of course, you need to choose a trustworthy one) Two-factor authentication Limit login attempts Force resets Man In The Middle Attack (MITM) # Packet Sniffing ARP Spoofing Evil Twin DNS Poisoning Bit Flipping Malicious Network Redirects # Attackers can inject fake DNS responses, redirecting you to malicious versions of websites\nHow it works # Hacker hijacking the unsecured Wi-Fi you access (more detail: DNS Poisoning) Malware in your computer edit your Host file (the file work like the DNS in your computer) Prevention # Using SSL/TLS for website: Even if SSL helps detect this (you‚Äôd see a certificate warning), many users may overlook or click through the warning, which could put them at risk Denial Of Service (DOS) # Prevention # Rate limit Distributed Denial Of Service (DDOS) # Backdoor Attack # SQL Injection # IDOR Attack # Authorize route\nCross-domain Access Attack # Syn Flood Attack # References # Cloudflare: What is a brute force attack? Hivesystems: Are Your Passwords in the Green? (2024) Kaspersky: What is a Dictionary Attack? Help improve my blog Was this page helpful to you?\nüëç Yes üëé No This page was last modified at 2024-06-15\nView this page on GitHub Report a problem with this content Can I know your name? Yes No "},{"id":12,"href":"/docs/tips/003_docker/","title":"Docker","section":"TIPS","content":" Docker Tips # Terminology # Image: Like the execution file (.exe) and even more. It have all needed setup dependences that stored inside it and ready to run instructions Container: Like the process after you run the image, but this application at this time is considered as the whole virtual machine Create # Create a docker image\nDockerfile # You will write all the instructions here, guild the Docker engine what enviroment you want your app to run inside, what needed dependencies to be installed, copy your source code into and last but not least is the command to run your app:\nSpecify a base image Run some commands to install additional programs Specify a command to run on the container startup # Dockerfile # 1. Use an existing docker image as a base FROM alpine # 2. Download and install a dependency RUN apk add --update redis # 3. Tell the image what to do when it starts as a container CMD [\u0026#34;redis-server\u0026#34;] Build # Build an image\n# syntax docker build -t \u0026lt;docker-id\u0026gt;/\u0026lt;project-name\u0026gt;:\u0026lt;version\u0026gt; . # eg. docker build -t dangpham/redis:v1 . The -t flag tags your image with a name (dangpham/redis:v1 in this case) The . is the build context that lets Docker know where it can find the Dockerfile Build an image with specific docker file name # docker build -f Dockerfile.dev . Build an image from the running container # docker commit -c \u0026lt;instruction\u0026gt; \u0026lt;container-id\u0026gt; \u0026lt;image-name\u0026gt; # eg. docker commit -c \u0026#39;CMD [\u0026#34;redis-server\u0026#34;]\u0026#39; c3f279d17e0a dangpham/redis:v2 How to import your project files into the image # # Specify a base image FROM node:14-alpine WORKDIR /usr/app # Install some dependencies COPY ./ ./ RUN npm install # Default command CMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;] WORKDIR /usr/app: change container context into this path. It will create a new folder if it doesn‚Äôt exist COPY ./ ./: copy from computer-context to container-context computer context: Path to folder copy from on your machine relative to build context container context: Place to copy stuff inside the container (/usr/app in this case) Run # Run a container from the image\ndocker run \u0026lt;image-name\u0026gt; docker run -it \u0026lt;image-name\u0026gt; sh docker run ‚Ä¶ = docker create ‚Ä¶ + docker start -a ‚Ä¶ -it ... sh: connect your terminal with the container shell Docker Run with port mapping # docker run -p \u0026lt;container-port\u0026gt;:\u0026lt;app-port\u0026gt; \u0026lt;image-name\u0026gt; # eg, docker run -p 7070:8080 dangpham/web-app:v1 container-port: Your computer will open this port for container app-port: Your running application exported port inside the container Detach mode # docker run \u0026lt;image-name\u0026gt; -d The -d flag starts up a container in detached mode Means that output from the container will not be piped to your terminal You can continue to run other commands while the container is still running Attach mode # Attach to the sdtin, stdout, stderr of container\u0026rsquo;s primary process into your terminal docker attach \u0026lt;container-id\u0026gt; Execute # Every process that we create in a Linux environment has three communication channels attached to it, that we refer to as:\nstdin: input to process stdout: output from process stderr: error form process These channels are used to communicate information either into the process or out of the process\nExec command # docker exec -it \u0026lt;container-id\u0026gt; \u0026lt;command\u0026gt; -it: Allow us to provide input to the container The -i flag: we are saying make sure that any stuff that our typed gets directed to stdin of Process. The -t flag: make those stuff we receive prettier Terminal access # Get full terminal access inside the context of the container\ndocker exec -it \u0026lt;container-id\u0026gt; sh sh means a shell or a command processor Allow us to type commands in and have them be executed inside that container Listing # Container # Listing all running containers: docker ps Listing both stopped and runnning containers: docker ps --all Image # docker image ls Caching # Docker has the cache mechanism, that compare each instruction in your Dockerfile with its previous\n# Specify a base image FROM node:14-alpine WORKDIR /usr/app # Install some dependencies COPY ./package.json ./ RUN npm install COPY ./ ./ # Default command CMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;] package.json israrely update so copying package.json before copying all other stuff It will help Docker runing npm install with cache and It will not re-install all dependencies just because you edit some html/css/js files Volumes # Change code in local machine and effect the container right away without rebuild # docker run -p 3000:3000 -v /app/node_modules -v $(pwd):/app \u0026lt;image_name\u0026gt; Note: -v /app/node_modules: Put a bookmark on the node_modules folder pwd: Present Working Directory -v $(pwd):/app: Map the pwd into the /app folder Explain: Means reference all files in pwd (except things inside node_modules) with all files in /app So when we change code in pwd, it also references to /app Stop # When you issue docker stop to a container, if the container does not automatically stop in 10 seconds, then Docker is going to automatically fall back to issuing the docker kill command.\nSoft # Send SIGTERM (terminate signal) to the process: give a process inside the container a little bit of time to do ST (like backup, etc‚Ä¶)\ndocker stop \u0026lt;container-id\u0026gt; Hard # Send SIGKILL (kills signal): shut down right now\ndocker kill \u0026lt;container-id\u0026gt; Remove # Remove all stopped containers in your machine and also clear your docker cache. It means you must re-download it from docker-hub in the next run\ndocker system prune Log # Retrieve all information that has been emitted from the docker\ndocker logs \u0026lt;container-id\u0026gt; Help improve my blog Was this page helpful to you?\nüëç Yes üëé No This page was last modified at 2024-04-08\nView this page on GitHub Report a problem with this content Can I know your name? Yes No "},{"id":13,"href":"/docs/tips/004_ops/","title":"Ops","section":"TIPS","content":" Operation Tips # Common Commands # IP address # # Public curl ipinfo.io/ip # Local ip address show Show detail a command # man \u0026lt;command\u0026gt; # E.g man vim # Then press q to quit Best practice before install anything # sudo apt update sudo apt upgrade Show package detail # apt show \u0026lt;package-name\u0026gt; # E.g apt show ssh E.g output Package: ssh Version: 1:9.6p1-3ubuntu13.5 Priority: optional Section: net Source: openssh Origin: Ubuntu Maintainer: Ubuntu Developers \u0026lt;ubuntu-devel-discuss@lists.ubuntu.com\u0026gt; Original-Maintainer: Debian OpenSSH Maintainers \u0026lt;debian-ssh@lists.debian.org\u0026gt; Bugs: https://bugs.launchpad.net/ubuntu/+filebug Installed-Size: 57.3 kB Depends: openssh-client (\u0026gt;= 1:9.6p1-3ubuntu13.5), openssh-server (\u0026gt;= 1:9.6p1-3ubuntu13.5) Homepage: https://www.openssh.com/ Download-Size: 4,658 B APT-Sources: http://vn.archive.ubuntu.com/ubuntu noble-updates/main amd64 Packages Description: secure shell client and server (metapackage) This metapackage is a convenient way to install both the OpenSSH client and the OpenSSH server. It provides nothing in and of itself, so you may remove it if nothing depends on it. Print working directory # pwd Copy # cp \u0026lt;source\u0026gt; \u0026lt;destination\u0026gt; # E.g cp readme.md readyou.md # create a copy named readyou with the same content as readme Clear directory # rm -rf \u0026lt;directory-name\u0026gt; Move # mv \u0026lt;source\u0026gt; \u0026lt;destination\u0026gt; # E.g mv readme.md .. # Move readme file to parent dir mv ../readme.md . # Move readme from parent dir to current dir Rename # If you move a file within the current directory, that means you are renaming it mv \u0026lt;old-name\u0026gt; \u0026lt;new-name\u0026gt; # E.g mv readme.md readyou.md Create # # Directory: mkdir \u0026lt;dir-name\u0026gt; # File: touch \u0026lt;file-name\u0026gt; Print file content # cat \u0026lt;file-name\u0026gt; Echo # Print env variable # echo $USER # E.g result: # \u0026gt;\u0026gt; dangpham112 Add content to file # echo Hello $USER \u0026gt; readme.md # readme file now have a content: Hello dangpham112 Systemctl # Restart # systemctl restart \u0026lt;service-name\u0026gt; # E.g systemctl restart ssh Check status # systemctl status \u0026lt;service-name\u0026gt; # E.g systemctl status ssh SSH # Stand for Secure Shell Check SSH score SSH Hardening Guides Connect # # Access SSH server ssh \u0026lt;username\u0026gt;@\u0026lt;ip-address || domain-name\u0026gt; # Then typing password and press enter Login with username and password # ssh \u0026lt;host-username\u0026gt;@\u0026lt;host-ip || host-domain\u0026gt; # -\u0026gt; SSH will promt you to enter the password Login via private-key file # # Change permissions to read-only for the private key file chmod 400 \u0026lt;private-key\u0026gt; # E.g chmod 400 MyServer # Log in via SSH (notice host-username) ssh -i \u0026lt;private-key\u0026gt; \u0026lt;host-username\u0026gt;@\u0026lt;host-ip || host-domain\u0026gt; # E.g 1: If you use EC2 Ubuntu, the host-username maybe ubuntu ssh -i MyServer.pem ubuntu@54.251.177.159 # E.g 2: If you use EC2 Amazon Linux, the host-username maybe ec2-user ssh -i MyServer.pem ec2-user@18.141.175.126 # E.g 3: If you use GCP, the host-username is your account username ssh -i gcp-key dangpham112000@34.55.160.169 Where is private-key file? E.g 1: While you create EC2 instance, you can create key-pair for login in aws console, then they will give you private-key to store on your SSH-client E.g 2: With GCP VM instance, you need to create your own key-pair and upload the public-key\u0026rsquo;s content to SSH-KEYS (Compute Engine \u0026gt; Settings \u0026gt; Metadata \u0026gt; SSH-KEYS) # Create key-pair on SSH-Client with username is your account username ssh-keygen -t rsa -f \u0026lt;keypair-name\u0026gt; -C \u0026lt;username\u0026gt; # E.g ssh-keygen -t rsa -f gcp-key -C dangpham112000 Setup passwordless authentication # # On SSH client # Generate a new SSH key pair using the Ed25519 algorithm ssh-keygen -t ed25519 # -\u0026gt; You can leave all the command prompts empty, just press enter # -\u0026gt; You should notice the location of file *.pub for further actions # Copy the public SSH key to the SSH server ssh-copy-id -i \u0026lt;public-key-file-location\u0026gt; \u0026lt;host-username\u0026gt;@\u0026lt;host-ip || host-domain\u0026gt; # E.g ssh-copy-id -i /root/.ssh/id_ed25519.pub ubuntu@123.213.32.1 # Test the connection ssh \u0026lt;host-username\u0026gt;@\u0026lt;host-ip || host-domain\u0026gt; # -\u0026gt; SSH server will no longer ask you a password Disable root login # # Open the SSH daemon configuration file vim /etc/ssh/sshd_config # in [sshd_config] -\u0026gt; Find PermitRootLogin and set it to no PermitRootLogin no # in [sshd_config] -\u0026gt; Find PasswordAuthentication and set it to no PasswordAuthentication no # Restart the SSH Service systemctl restart ssh Secure copy # From SSH-client to SSH-server # # On SSH-client # From SSH-Client to SSH-Server scp \u0026lt;path-to-file\u0026gt; \u0026lt;host-username\u0026gt;@\u0026lt;host-ip\u0026gt;:\u0026lt;destination\u0026gt; # E.g scp ~/Documents/readme.md ubuntu@18.141.184.34:~/Document/ # Or scp -i \u0026lt;private-key\u0026gt;.pem \u0026lt;path-to-file\u0026gt; \u0026lt;host-username\u0026gt;@\u0026lt;host-ip\u0026gt;:\u0026lt;destination\u0026gt; # E.g scp -i ~/Auth/MyServer.pem ~/Documents/readme.md ubuntu@18.141.184.34:~/Document/ # From SSH-Server to SSH-Client scp \u0026lt;host-username\u0026gt;@\u0026lt;host-ip\u0026gt;:\u0026lt;path-to-file\u0026gt; \u0026lt;destination-on-client\u0026gt; # E.g scp ubuntu@18.141.184.34:~/Document/readyou.md ~/Documents # Or scp -i \u0026lt;private-key\u0026gt;.pem \u0026lt;host-username\u0026gt;@\u0026lt;host-ip\u0026gt;:\u0026lt;path-to-file\u0026gt; \u0026lt;destination-on-client\u0026gt; # E.g scp -i ~/Auth/MyServer.pem ubuntu@18.141.184.34:~/Document/readyou.md ~/Documents Nano # A default text editor of some OS Open file # nano \u0026lt;file-name\u0026gt; # E.g nano index.html Save # Press Ctrl + x Press y Press enter Setup root password # If your root user does not yet have a password # Gain root privileges sudo su # Set a Password passwd root # -\u0026gt; Enter and confirm the password Nginx # Capacity: 2MB Install # sudo apt install nginx ==\u0026gt; Press Tab -\u0026raquo; Choose OK and then press enter\nOpen ports # After installing Nginx, we may not be able to access our website because the firewall is enabled by default If you use EC2, the firewall is disabled by default, but your EC2 Security Group will block access to your website You must edit the inbound rules to allow traffic on HTTP (port 80) and HTTPS (port 443) Check firewall status # sudo ufw status ufw: ubuntu firewall Let\u0026rsquo;s firewall allow nginx # sudo ufw allow \u0026#34;Nginx Full\u0026#34; Locate the index file # /var/www/html/ Locate configuration file # /etc/nginx/sites-available/ # Activate the configuration for Nginx sudo ln -s /etc/nginx/sites-available/\u0026lt;my-config\u0026gt;.conf /etc/nginx/sites-enabled/ # Test config syntax sudo nginx -t # Restart nginx sudo systemctl restart nginx Well-known ports (Link) # SSL Certificate # Let\u0026rsquo;s Encrypt SSL/TLS certificate # Issued at no cost by the Let\u0026rsquo;s Encrypt Certificate Authority Provides Domain Validation (DV) certificates Certificates are valid for 90 days, but they can be renewed automatically with Certbot # Install Snap sudo apt install snapd # Ensure stability and compatibility for all snap packages sudo snap install core; sudo snap refresh core # Install Certbot sudo snap install --classic certbot # Ensures that Certbot is accessible system-wide sudo ln -s /snap/bin/certbot /usr/bin/certbot # Obtain and install a certificate for a website running on Nginx # Automatically configuring Nginx to use HTTPS sudo certbot --nginx # -\u0026gt; Certbot will prompt you to provide some information (domain, email, ads) # Test automatic renewal sudo certbot renew --dry-run # -\u0026gt; If the dry run is successful, you\u0026#39;ll see output similar to: # Congratulations, all renewals succeeded Certbot: A popular tool for obtaining and managing SSL/TLS certificates from the Let\u0026rsquo;s Encrypt Certificate Authority Certificates for localhost # Create CA certificate # Generate RootCA.pem, RootCA.key, and RootCA.crt: # Generate a Root CA Certificate openssl req -x509 -nodes -new -sha256 -days 1024 -newkey rsa:2048 -keyout RootCA.key -out RootCA.pem -subj \u0026#34;/C=US/CN=Example-Root-CA\u0026#34; # -\u0026gt; RootCA.key \u0026amp; RootCA.pem # Convert the Certificate to .crt Format openssl x509 -outform pem -in RootCA.pem -out RootCA.crt # -\u0026gt; RootCA.crt RootCA.key: Private key for the Root CA RootCA.pem: Self-signed certificate for the Root CA in PEM format RootCA.crt: Contains the same information as RootCA.pem, but they are often distinguished by convention Create a configuration snippet # Create a file domains.ext # domains.ext authorityKeyIdentifier=keyid,issuer basicConstraints=CA:FALSE keyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment subjectAltName = @alt_names [alt_names] DNS.1 = localhost Generating a signed certificate for localhost # Generate localhost.key, localhost.csr, and localhost.crt # Generate a CSR (Certificate Signing Request) for localhost openssl req -new -nodes -newkey rsa:2048 -keyout localhost.key -out localhost.csr -subj \u0026#34;/C=US/ST=YourState/L=YourCity/O=Example-Certificates/CN=localhost\u0026#34; # -\u0026gt; localhost.key \u0026amp; localhost.csr # Sign the CSR with a Root CA to generate the signed certificate openssl x509 -req -sha256 -days 1024 -in localhost.csr -CA RootCA.pem -CAkey RootCA.key -CAcreateserial -extfile domains.ext -out localhost.crt # -\u0026gt; localhost.crt localhost.key: Private key for the certificate localhost.csr: Certificate Signing Request (CSR) that can be sent to a Certificate Authority (CA) for signing localhost.crt: The final signed certificate for localhost generated by your Root CA Configure your webserver # Nginx server { listen 443 ssl default_server; listen [::]:443 ssl default_server; ssl_certificate /home/dangpham/Auth/ssl_cert/localhost.crt; ssl_certificate_key /home/dangpham/Auth/ssl_cert/localhost.key; root /var/www/html; index index.html index.htm index.nginx-debian.html; server_name localhost; location / { try_files $uri $uri/ =404; } } Nodejs const https = require(\u0026#39;https\u0026#39;); const fs = require(\u0026#39;fs\u0026#39;); const path = require(\u0026#39;path\u0026#39;); const certLocation = \u0026#39;/home/dangpham/Auth/ssl_cert\u0026#39;; const options = { key: fs.readFileSync(path.resolve(certLocation, \u0026#39;localhost.key\u0026#39;)), cert: fs.readFileSync(path.resolve(certLocation, \u0026#39;localhost.crt\u0026#39;)), }; const server = https.createServer(options,(req, res) =\u0026gt; { if (req.url === \u0026#39;/hello\u0026#39; \u0026amp;\u0026amp; req.method === \u0026#39;GET\u0026#39;) { res.writeHead(200, { \u0026#39;Content-Type\u0026#39;: \u0026#39;text/plain\u0026#39; }); res.end(\u0026#39;world\u0026#39;); } else { res.writeHead(404, { \u0026#39;Content-Type\u0026#39;: \u0026#39;text/plain\u0026#39; }); res.end(\u0026#39;Not Found\u0026#39;); } }); server.listen(443, () =\u0026gt; { console.log(\u0026#39;Server is listening on port 443\u0026#39;); }); Add new local CA to the trusted Root Certificate Authorities # Chrome Browse chrome://settings/certificates Choose Authorities then Import Import RootCA.pem we created above Check all options Firefox Make Firefox trusted Root CAs: Browse about:config Type security.enterprise_roots.enabled Enable it to true Import CA certificate: Browse about:preferences#privacy Find Certificats section Choose View Certificates and then Import Import RootCA.pem we created above Confirm References # Wikipedia: List of TCP and UDP port numbers (Nov 13th, 2024) Certbot: Certbot Instructions Nginx on Linux (snap) Letsencrypt: Certificates for localhost (Dec 21st, 2017) Github: How to create an HTTPS certificate for localhost domains (2019) Help improve my blog Was this page helpful to you?\nüëç Yes üëé No This page was last modified at 2024-11-27\nView this page on GitHub Report a problem with this content Can I know your name? Yes No "},{"id":14,"href":"/docs/tips/005_passion/","title":"Spark Passion","section":"TIPS","content":" Spark Your Passion # Server Monitoring # Htop # A lightweight, no-frills process manager for resource-constrained environments or terminal purists # Install apt install htop # Run htop Btop # A feature-rich, visually enhanced monitoring experience where modern aesthetics and detailed insights matter # Install apt install btop # Run btop Termial Custom # Before After Oh My Zsh # A framework for managing the configuration of the Zsh # Install Zsh apt install zsh # Install Oh My Zsh using curl sh -c \u0026#34;$(wget https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -)\u0026#34; # Switch to Zsh (if not already the default shell) chsh -s $(which zsh) # Restart your terminal Agnoster theme # # Download necessary font apt install fonts-powerline # Edit file .zshrc (zsh config) vim ~/.zshrc # Change theme to agnoster (inner file .zshrc) ZSH_THEME=\u0026#34;agnoster\u0026#34; Plugins # Auto-suggestions # # Download plugin git clone https://github.com/zsh-users/zsh-autosuggestions.git $ZSH_CUSTOM/plugins/zsh-autosuggestions # Edit file .zshrc (zsh config) vim ~/.zshrc # Add plugin name (inner file .zshrc) plugins=( git zsh-autosuggestions ) Syntax highlighting # # Download plugin git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting # Edit file .zshrc (zsh config) vim ~/.zshrc # Add plugin name (inner file .zshrc) plugins=( git ... zsh-syntax-highlighting ) Cmatrix # Emulate the digital rain effect seen in the movie The Matrix # Install apt install cmatrix # Run cmatrix Vscode Custom # Power Mode extension # Add visual effects and animations as you type Install extension name: Power Mode ID: hoovercj.vscode-power-mode # Open file setting.json of vscode vim ~/.config/Code/User/settings.json // settings.json { // Other settings \u0026#34;powermode.enabled\u0026#34;: true, \u0026#34;powermode.maxExplosions\u0026#34;: 10, \u0026#34;editor.codeActionsOnSave\u0026#34;: null, \u0026#34;powermode.explosions.size\u0026#34;: 15, \u0026#34;powermode.explosions.frequency\u0026#34;: 2, \u0026#34;powermode.explosions.offset\u0026#34;: 0.215, \u0026#34;powermode.explosions.customExplosions\u0026#34;: [ \u0026#34;https://media.giphy.com/media/sLMRyFR4eIEgnFe4mK/giphy.gif\u0026#34;, \u0026#34;https://media.giphy.com/media/RFvv2miX3KHcOkBwns/giphy.gif\u0026#34;, \u0026#34;https://media.giphy.com/media/8Hw8ei9OiUXIUlHEBy/giphy.gif\u0026#34; ], \u0026#34;powermode.explosions.backgroundMode\u0026#34;: \u0026#34;mask\u0026#34;, \u0026#34;powermode.explosions.gifMode\u0026#34;: \u0026#34;restart\u0026#34;, \u0026#34;powermode.explosions.explosionOrder\u0026#34;: \u0026#34;sequential\u0026#34;, \u0026#34;powermode.explosions.duration\u0026#34;: 1000, \u0026#34;powermode.explosions.customCss\u0026#34;: { \u0026#34;mix-blend-mode\u0026#34;: \u0026#34;color-dodge\u0026#34; }, \u0026#34;powermode.shake.enabled\u0026#34;: false } Todo Tree extension # This extension quickly searches your workspace for comment tags like TODO and FIXME, and displays them in a tree view in the activity bar Install extension name: Todo Tree ID: Gruntfuggly.todo-tree References # Github: Power mode setup templates Scottspence: My Zsh Config (April 14th, 2022) Help improve my blog Was this page helpful to you?\nüëç Yes üëé No This page was last modified at 2024-11-27\nView this page on GitHub Report a problem with this content Can I know your name? Yes No "},{"id":15,"href":"/docs/research/security/hsts/","title":"HSTS","section":"Security - Draft","content":" HTTP Strict-Transport-Security # Overview # HSTS Header: The server sends an Strict-Transport-Security header in its HTTPS response HSTS Policy: The browser enforces the HSTS policy for the specified domain by: Automatically upgrading all HTTP requests to HTTPS Refusing to connect to the site if a valid HTTPS connection cannot be established (e.g., if there are certificate issues) Persistence: The policy is cached in the browser for the duration specified by the max-age directive in the header Pros # Forces HTTPS: Ensures all traffic to the site uses a secure connection. Mitigates MitM Attacks: Prevents attackers from intercepting or altering communication. Protects Against Protocol Downgrade: Blocks attackers from forcing the browser to switch from HTTPS to HTTP. Demo setup # Nginx server { listen 443 ssl; server_name example.com; add_header Strict-Transport-Security \u0026#34;max-age=31536000; includeSubDomains; preload\u0026#34; always; } NodeJS Install the helmet middleware: npm install helmet const helmet = require(\u0026#39;helmet\u0026#39;); app.use(helmet.hsts({ maxAge: 31536000, // 1 year in seconds includeSubDomains: true, preload: true })); Add your domain to the HSTS Preload List at Hstspreload Verify at Hardenize Remove # Set your header: Strict-Transport-Security: max-age=0 You can remove HSTS at Hstspreload-removal References # Mozilla: Strict-Transport-Security (Aug 1st, 2024) Help improve my blog Was this page helpful to you?\nüëç Yes üëé No This page was last modified at 2024-06-15\nView this page on GitHub Report a problem with this content Can I know your name? Yes No "},{"id":16,"href":"/docs/research/security/bit_flipping/","title":"Bit Flipping","section":"Security - Draft","content":" Bit Flipping Attack # As you can see in the Packet Sniffing section, we have a discussion about how messages that go through the internet can easily be seen by hackers. One of our protection solutions is to encrypt all packets that go through the internet, but is it enough? Use case # Attacking financial systems How it works # An attacker alters bits in the ciphertext to produce a predictable change in the plaintext By flipping specific bits, the attacker can control certain parts of the plaintext, potentially altering critical information This manipulation allows the attacker to modify the encrypted message without needing to decrypt it first Prevention # Implement HMAC Demo # DISCLAIMER: This demo is for educational purposes only. The techniques should only be tested on systems you own or have explicit permission to analyze. Misuse of this information is unethical, may violate the law, and could lead to serious consequences. The author takes no responsibility for any damages or misuse arising from this content This demo can be run directly in the console of the Chrome browser Javascript\nPrepare const iv = crypto.getRandomValues(new Uint8Array(16)); let key; (async () =\u0026gt; { key = await crypto.subtle.generateKey( { name: \u0026#34;AES-CBC\u0026#34;, length: 128, }, true, [\u0026#34;encrypt\u0026#34;, \u0026#34;decrypt\u0026#34;] ); })(); async function encryptData(plaintext) { const encoder = new TextEncoder(); const data = encoder.encode(plaintext); const ciphertext = await crypto.subtle.encrypt( { name: \u0026#34;AES-CBC\u0026#34;, iv, }, key, data ); return new Uint8Array(ciphertext); } async function decryptData(ciphertext) { const plaintextBuffer = await crypto.subtle.decrypt( { name: \u0026#34;AES-CBC\u0026#34;, iv, }, key, ciphertext ); const decoder = new TextDecoder(); return decoder.decode(plaintextBuffer); } function ord(string) { return string.charCodeAt(0); } Main flow (async () =\u0026gt; { // User const plaintext = \u0026#34;{ Message: \u0026#39;Doing charity work!\u0026#39;, Money: 001 $, To: Beggar }\u0026#34;; const ciphertext = await encryptData(plaintext); // Hacker ciphertext[43 - 16] = ord(\u0026#34;0\u0026#34;) ^ ciphertext[43 - 16] ^ ord(\u0026#34;9\u0026#34;); ciphertext[44 - 16] = ord(\u0026#34;0\u0026#34;) ^ ciphertext[44 - 16] ^ ord(\u0026#34;9\u0026#34;); ciphertext[45 - 16] = ord(\u0026#34;1\u0026#34;) ^ ciphertext[45 - 16] ^ ord(\u0026#34;9\u0026#34;); // Bank const decryptedText = await decryptData(ciphertext); console.log(\u0026#34;Decrypted Text:\u0026#34;, decryptedText); })(); Output \u0026gt; Decrypted Text: { Message: \u0026#39;Doin\bÔøΩ\u001eÔøΩiQÔøΩÔøΩÔøΩ\u0026#39;BT_ÔøΩ\u0026#34;\f!\u0026#39;, Money: 999 $, To: Beggar } References # Twingate: What Is A Bit Flipping Attack? How It Works \u0026amp; Examples (Aug 15th, 2024) Hackernoon: Why Using Hashing Alone is NOT Enough for Data Integrity (Aug 15th, 2023) Bigous: A deep look into Cipher Block Chaining (CBC) Algorithm Bit Flipping (Nov 17th, 2023) Help improve my blog Was this page helpful to you?\nüëç Yes üëé No This page was last modified at 2025-01-16\nView this page on GitHub Report a problem with this content Can I know your name? Yes No "},{"id":17,"href":"/docs/research/scale/","title":"Scale","section":"RESEARCH","content":" Scale # Monolith architecture # The server in itself is capable and responsible for all the tasks that have to be performed and can perform every step needed to perform a function Tasks: Authorization, Presentation, Database, Business Server side rendering (SSR) # Splitting server # Database splitting # Assume your app have a stable traffic Your data is not maintain steady, it always grows up. So database is the first thing we need to splitting out from our server and be standalone For later you will need to upgrade your DB (whatever scale out or scale up) Client splitting \u0026amp;\u0026amp; Client side rendering (CSR) # Example Flow:\nThe user enters https://gg.com in the browser bar The user\u0026rsquo;s browser send an request to google GG\u0026rsquo;s gateway receive this request first: Parse the request -\u0026gt; { method: GET, url: gg.com } -\u0026gt; This request is belong to frontend Ask and receive index.html, css, js from gg\u0026rsquo;s frontend server Response back these things to user The user\u0026rsquo;s browser receive materials and then render gg website The user enters The biggest butterfly in the gg search Gg website ask browser to send a request to gg\n{ method: POST, url: gg.com/api, body: The biggest butterfly } After receive this request, gateway routes it to the backend server due to path /api Backend server progress the request, get some data from database and response back The gg website using JS to rerender the interface corresponding with the response Mobile # In mobile architecture\nApplication is already installed in the device, they not need an frontend server to serve interface anymore Only need backend server if it need to process some business, CRUD data, \u0026hellip; Scale # Vertical # Also called ‚Äúscale up‚Äù Vertical scaling is based on the idea of adding more power(CPU, RAM) to existing systems, basically adding more resources Pros: Simplicity: less complicated maintenance, less need for software changes, less complex process communication Cost-effective: upgrading a pre-existing server costs less than purchasing a new one Cons: Higher possibility for downtime Single point of failure Upgrade limitations Horizontal # Also called ‚Äúscale out‚Äù Horizontal scaling is based on the idea of adding more machines to our pool of resources. Pros: Fewer periods of downtime Increased resilience and fault tolerance Cons: Increased complexity of maintenance and operation Increased Initial costs Load balancer # A load balancer is a device that sits between the user and the server group and acts as an invisible facilitator, ensuring that all resource servers are used equally Run application server maintenance or upgrades without application downtime Prevents traffic bottlenecks at any one server Route traffic through a group of network firewalls for additional security Algorithms # Round-robin: Route traffic to the servers turn by turn or in a round-robin fashion Weighted round-robin: Servers with higher weights will receive more incoming application traffic Least connection: Which servers have the fewest active connections and sends traffic to those servers Resource-based: Check the server resources, such as its computing capacity and memory. Then, the load balancer checks the agent for sufficient free resources before distributing traffic to that server \u0026hellip; Database Scaling # Replication # All the slaves are connected with the master If the master DB goes down an eligible slave will hold the new master High Availability of data disasters recovery No downtime for maintenance (like backups index rebuilds and compaction) Sharding # Sharding is a method for distributing large dataset and allocating it across multiple servers How it work? # Consistent Hashing Simple example # We have 3 databases (shards) store products, named from 0 to 2 We using product id to determind which shard will be used Each product come to our servers: id will mod with 3 If equal 0, shard 0 will be used to read or write this data Similar to others Combination # Caching # Everything stored on frontend can be changed by the user so this is potential security vulnerability\nThis is the main difference between backend and frontend caching, backend caching can\u0026rsquo;t be edited by the user\nFrontend # On the frontend, a browser or the client application caches data like a header image the first time your user accesses it. The next time they access that same content, the frontend loads the cached files to improve performance\nBrowser caching # Browser caching is a technique that allows you to store certain files, such as CSS, JavaScript, and images\nCDN - Content Delivery Network # Implementing CDN caching requires integrating your website with a CDN provider. This involves configuring your DNS settings to point to the CDN‚Äôs servers and setting up caching rules to determine which files should be cached and for how long\nBackend # Backend development uses caching to reduce the load on the application server. What you store in the backend cache depends on your application itself. Cached content includes static pages, database query results, API responses, session data, images, and videos\nData center # Appendix # Ramble on about the limit of the speed of light Quantum entanglement promises to enable instant communication or data transmission in the future, regardless of distance\nHowever, as of now, we use fiber optic cables, and the latency is significantly higher when transfering data from a distant location compared to a nearby one\nA question is: Aren\u0026rsquo;t data packets traveling at the speed of light? If they did, would the difference in latency between close and far locations be significant?\nFor example:\nThe distance from Ho Chi Minh City to New York is 14,275 km, or 14,275,000 meters The speed of light is approximately 300,000,000 m/s, or 300,000 meters per millisecond (m/ms) The time for a data packet to travel one way would be around 47.583 ms, so a round trip (sending and receiving) would take about 95 ms But this is in an ideal scenario where:\nThe server takes 0 ms to process the request and sends the response instantly The signal is traveling in a vacuum at the speed of light (300,000 m/ms) In reality:\nThe speed of data transmission through fiber optic cables is lower‚Äîaround 200,000 kilometers per second, or 200,000 m/ms Even with a direct fiber optic connection between Ho Chi Minh City and a server in New York, the round trip would take at least 142.75 ms So even with a direct connection to a New York server, I\u0026rsquo;d still be playing League of Legends with a ping of over 140 ms!\nReference # Geeksforgeeks: What is a monolith server ? (19 Nov, 2021) Cloudzero: Horizontal Vs. Vertical Scaling: How Do They Compare? (May 05, 2023) Amazon: What is Load Balancing? Linkedin: How Web is limited by the speed of light? (May 16, 2022) Help improve my blog Was this page helpful to you?\nüëç Yes üëé No This page was last modified at 2024-04-18\nView this page on GitHub Report a problem with this content Can I know your name? Yes No "}]