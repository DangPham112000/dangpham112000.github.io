[{"id":0,"href":"/docs/research/be_protocol/tcp_udp/","title":"TCP - UDP","section":"Backend Protocol","content":"\rTCP - UDP\r#\rUDP\r#\rUser Datagram Protocol\nOverview\r#\rMessage Based Layer 4 protocol Ability to address processes in a host using ports Simple protocol to send and receive messages Prior communication not required (double edge sword) Stateless no knowledge is stored on the host 8 byte header Datagram Demo\r#\r// server.js import dgram from \u0026#34;dgram\u0026#34;; const socket = dgram.createSocket(\u0026#34;udp4\u0026#34;); socket.bind(5500, \u0026#34;127.0.0.1\u0026#34;); socket.on(\u0026#34;message\u0026#34;, (msg, info) =\u0026gt; { console.log( `My server got a datagram ${msg}, from ${info.address}:${info.port}` ); }); # client terminal nc -u 127.0.0.1 5500 # client terminal Hi # client terminal I am Dang The result of the server log: (TBU)\nTCP\r#\rTransmission Control Protocol\nOverview\r#\rStream based Layer 4 protocol Ability to address processes in a host using ports “Controls” the transmission unlike UDP which is a firehose Connection Requires handshake 20 bytes headers Segment (can go to 60) Stateful 3 ways handshake\r#\rDemo\r#\r// server.js import net from \u0026#34;net\u0026#34;; const server = net.createServer((socket) =\u0026gt; { console.log( `TCP successfully handshack with ${socket.remoteAddress}:${socket.remotePort}` ); socket.write(\u0026#34;Hello Client!\u0026#34;); socket.on(\u0026#34;data\u0026#34;, (data) =\u0026gt; { console.log(`Received data ${data.toString()}`); }); server.listen(6600, \u0026#34;127.0.0.1\u0026#34;); }); # client terminal nc 127.0.0.1 6600 Client recieve message when successful establish the connection: (TBU)\n# client terminal This is data to send to the server! "},{"id":1,"href":"/docs/research/be_protocol/tls_ssl/","title":"TLS - SSL","section":"Backend Protocol","content":"\rTLS - SSL\r#\rTransport Layer Security - Secure Sockets Layer\nOverview\r#\rSSL stands for Secure Sockets Layer, and it refers to a protocol for encrypting, securing, and authenticating communications that take place on the Internet. Although SSL was replaced by an updated protocol called TLS (Transport Layer Security) some time ago, \u0026ldquo;SSL\u0026rdquo; is still a commonly used term for this technology\nTLS 1.2\r#\rDiffie Hellman\r#\rTLS 1.3\r#\rReference\r#\rCloudflare: How does SSL work? Gigamon: What Is TLS 1.2, and Why Should You (Still) Care? Wikipedia: Transport Layer Security (Mar 1, 2024) "},{"id":2,"href":"/docs/research/be_protocol/http/","title":"HTTP","section":"Backend Protocol","content":"\rHTTP\r#\rHTTP 1.0\r#\rHTTP/1.1\r#\rHTTP/2\r#\rHTTP/3\r#\rHTTP over QUIC\nReference\r#\rUpwork: What is the HTTP/2 Protocol? Overview and Examples (Aug 23, 2021) "},{"id":3,"href":"/docs/research/be_protocol/https/","title":"HTTPS","section":"Backend Protocol","content":"\rHTTPS\r#\rOver TCP With TLS 1.2\r#\rOver TCP With TLS 1.3\r#\rOver QUIC (HTTP/3)\r#\rOver TCP With TLS 1.3 0RTT\r#\rOver QUIC 0RTT\r#\r"},{"id":4,"href":"/docs/research/be_protocol/webrtc/","title":"WebRTC","section":"Backend Protocol","content":"\rWebRTC\r#\rWeb Real-Time Communication\nOverview\r#\rA protocol that connects peer to peer Find a peer to peer path to exchange video and audio in an efficient and low latency manner Standardized API Enables rich communications browsers, mobile, IOT devices "},{"id":5,"href":"/docs/research/be_protocol/websocket/","title":"Websocket","section":"Backend Protocol","content":"\rWebsocket\r#\rBidirectional communications on the web\nExample code:\r#\r// server.js const http = require(\u0026#34;http\u0026#34;); const WebSocketServer = require(\u0026#34;websocket\u0026#34;).server; let connections = []; //create a raw http server (this will help us create the TCP which will then pass to the websocket to do the job) const httpserver = http.createServer(); //pass the httpserver object to the WebSocketServer library to do all the job, this class will override the req/res const websocket = new WebSocketServer({ httpServer: httpserver }); //listen on the TCP socket httpserver.listen(8080, () =\u0026gt; console.log(\u0026#34;My server is listening on port 8080\u0026#34;) ); //when a legit websocket request comes listen to it and get the connection .. once you get a connection that\u0026#39;s it! websocket.on(\u0026#34;request\u0026#34;, (request) =\u0026gt; { const connection = request.accept(null, request.origin); connection.on(\u0026#34;message\u0026#34;, (message) =\u0026gt; { //someone just sent a message tell everybody connections.forEach((c) =\u0026gt; c.send(`User${connection.socket.remotePort} says: ${message.utf8Data}`) ); }); connections.push(connection); //someone just connected, tell everybody connections.forEach((c) =\u0026gt; c.send(`User${connection.socket.remotePort} just connected.`) ); }); // client.js let ws = new WebSocket(\u0026#34;ws://localhost:8080\u0026#34;); ws.onmessage = (message) =\u0026gt; console.log(`Received: ${message.data}`); ws.send(\u0026#34;Hello! I\u0026#39;m client\u0026#34;); "},{"id":6,"href":"/docs/research/be_protocol/grpc/","title":"gRPC","section":"Backend Protocol","content":"\rgRPC\r#\rTaking HTTP/2 to the next level\nOverview\r#\rClient Library: One library for popular languages Protocol: HTTP/2 (hidden implementation) Message Format: Protocol buffers as format "},{"id":7,"href":"/docs/research/be_protocol/communication/","title":"Communication","section":"Backend Protocol","content":"\rCommunication\r#\rRequest-Response\r#\rOverview\r#\rThe Request-Response pattern is a fundamental communication pattern where a client sends a request to a server, and the server processes the request and sends back a response. It\u0026rsquo;s one of the most common patterns for communication in distributed systems, client-server architectures, and web applications.\nPush\r#\rReal time notification\nOverview\r#\rUsed by RabbitMQ Implementation\r#\rConcept:\r#\rClient connects to a server Server sends data to the client Client doesn’t have to request anything Protocol must be bidirectional Example code:\r#\rShort Polling\r#\rRequest is taking a while, I’ll check with you later\nImplementation\r#\rConcept:\r#\rClient sends a request Server responds immediately with a handle Server continues to process the request Client uses that handle to check for status Multiple “short” request response as polls Long Polling\r#\rImplementation\r#\rConcept:\r#\rClient sends a request Server responds immediately with a handle Server continues to process the request Client uses that handle to check for status Server DOES not reply until it has the response So we got a handle, we can disconnect and we are less chatty Some variation has timeouts too Server sent events\r#\rImplementation\r#\rConcept:\r#\rA response has start and end Client sends a request Server sends logical events as part of response Server never writes the end of the response It is still a request but an unending response Client parses the streams data looking for events Works with request/response (HTTP) Message Queue\r#\rAsynchronous messaging for batching jobs and decoupling applications\nOverview\r#\rA message queue is a form of asynchronous service-to-service communication used in serverless and microservices architectures. Messages are stored on the queue until they are processed and deleted. Each message is processed only once, by a single consumer. Message queues can be used to decouple heavyweight processing, to buffer or batch work, and to smooth spiky workloads.\nPublish Subcribe\r#\rOne publisher many readers\nImplementation\r#\rConcept:\r#\rReference\r#\rLinkedin: Backend Communication Design Patterns (Sep 13, 2023) Freecodecamp: Communication Design Patterns for Backend Development Amazon: Message Queues "},{"id":8,"href":"/docs/research/process_vs_thread/","title":"Process vs Thread","section":"RESEARCH","content":"\rProcess vs Thread\r#\rProgram\r#\rA Program is an executable file containing a set of instructions and passively stored on disk\nProcess\r#\rA Process means a program is in execution. When a program is loaded into the memory and becomes active, the program becomes a process or processes\nThread\r#\rA Thread is the smallest unit of execution within a process\nProcess vs Thread\r#\rProcess\r#\rThe process requires some essential resources such as registers, program counter, and stack\nEach process has its own memory address space. One process can not corrupt the memory address space of another process. This means that when one process malfunctions, other processes keep running\nThread\r#\rA process has at least one thread. It’s called the main thread. It’s not uncommon for a process to have many threads\nEach thread has its own stack. Earlier we mentioned registers, program counters and stack pointers as being part of a process. It’s more accurate to say that those things belong to a thread\nThreads within a process share a memory address space\rIt’s possible to communicate between threads using that shared memory space However, one misbehaving thread could bring down the entire process\nCode demo\r#\rWhen one process malfunctions, other processes keep running\rNodejs\nconst cluster = require(\u0026#34;cluster\u0026#34;); if (cluster.isMaster) { // Master process logic console.log(\u0026#34;Master process\u0026#34;, process.pid, \u0026#34;is running\u0026#34;); const normalSlave = cluster.fork(); const misbehavingSlave = cluster.fork(); misbehavingSlave.send({ isNormal: false }); normalSlave.send({ isNormal: true }); setInterval(() =\u0026gt; { console.log(\u0026#34;Master process\u0026#34;, process.pid, \u0026#34;is doing some work.\u0026#34;); }, 300); } else { // Slave process logic console.log(\u0026#34;Slave process\u0026#34;, process.pid, \u0026#34;is running\u0026#34;); process.on(\u0026#34;message\u0026#34;, ({ isNormal }) =\u0026gt; { if (isNormal) { setInterval(() =\u0026gt; { console.log(\u0026#34;Slave process\u0026#34;, process.pid, \u0026#34;is doing some work.\u0026#34;); }, 300); } else { setTimeout(() =\u0026gt; { throw new Error(\u0026#34;Slave process \u0026#34; + process.pid + \u0026#34; is corrupted!!!\u0026#34;); }, 2000); } }); } One misbehaving thread could bring down the entire process\rNodejs\nconst { Worker } = require(\u0026#34;worker_threads\u0026#34;); console.log(\u0026#34;Process\u0026#34;, process.pid, \u0026#34;starts\u0026#34;); // Create a misbehaving worker thread const misbehavingWorker = new Worker( ` const { threadId } = require(\u0026#39;worker_threads\u0026#39;); console.log(\u0026#39;Thread\u0026#39;, threadId, \u0026#39;from process\u0026#39;, process.pid, \u0026#39;starts\u0026#39;); // Intentionally cause an unhandled exception setTimeout(() =\u0026gt; { throw new Error(\u0026#39;Thread \u0026#39; + threadId + \u0026#39; is corrupted!!!\u0026#39;); }, 2000); `, { eval: true } ); // Create a normal worker thread const normalWorker = new Worker( ` const { threadId } = require(\u0026#39;worker_threads\u0026#39;); console.log(\u0026#39;Thread\u0026#39;, threadId, \u0026#39;from process\u0026#39;, process.pid, \u0026#39;starts\u0026#39;); // Simulate normal work setInterval(() =\u0026gt; { console.log(\u0026#39;Thread\u0026#39;, threadId, \u0026#39;is doing some work.\u0026#39;); }, 300); `, { eval: true } ); Multithreading and Multiprocessing\r#\rConcurrency and Parallelism\r#\rConcurrency allows multiple tasks to make progress by interleaving their execution, even if they are not executing simultaneously. It is focused on efficient task scheduling and resource utilization\nParallelism involves executing multiple tasks simultaneously, typically on separate processing units or cores. It aims to achieve higher performance and faster task completion\nMultithreading\r#\rMultithreading focuses on generating computing threads from a single process, whereas multiprocessing increases computing power by adding processors\nMultiprocessing\r#\rMultiprocessing uses two or more processors to increase computing power, whereas multithreading uses a single process with multiple code segments to increase computing power\nCode demo\r#\rPrepared files\rNodejs\nk.js\nconst CPUS = require(\u0026#34;os\u0026#34;).cpus(); const NUM_CPU = CPUS.length; const TOTAL_OBJS = 10000000; const numWorkers = NUM_CPU; const workload = TOTAL_OBJS / numWorkers; module.exports = { CPUS, NUM_CPU, TOTAL_OBJS, numWorkers, workload, }; _.js\nconst generateRandomName = () =\u0026gt; { const names = [ \u0026#34;Alice\u0026#34;, \u0026#34;Bob\u0026#34;, \u0026#34;Charlie\u0026#34;, \u0026#34;David\u0026#34;, \u0026#34;Eve\u0026#34;, \u0026#34;Frank\u0026#34;, \u0026#34;Grace\u0026#34;, \u0026#34;Henry\u0026#34;, \u0026#34;Ivy\u0026#34;, \u0026#34;Jack\u0026#34;, ]; return names[Math.floor(Math.random() * names.length)]; }; const generateRandomAge = () =\u0026gt; { return Math.floor(Math.random() * 100) + 1; }; const generateObjects = (count) =\u0026gt; { const objects = []; for (let i = 0; i \u0026lt; count; i++) { const object = { name: generateRandomName(), age: generateRandomAge(), createTime: new Date(), }; objects.push(object); } return objects; }; class Logger { constructor(isEnable) { this.isEnable = !!isEnable; } isDebug = false; logP1(...args) { if (this.isEnable) { console.log(...args); } } debug(...args) { if (this.isDebug \u0026amp;\u0026amp; this.isEnable) { console.log(...args); } } } const ts = () =\u0026gt; new Date().getTime(); class Monitor { startTime; endTime; start() { this.startTime = ts(); } end() { this.endTime = ts(); } getTotal() { return this.endTime - this.startTime; } } module.exports = { Logger, Monitor, generateObjects, }; worker.js\nconst { generateObjects, Monitor, Logger } = require(\u0026#34;../_\u0026#34;); const { workerData, parentPort, threadId } = require(\u0026#34;worker_threads\u0026#34;); const monitor = new Monitor(); const logger = new Logger(true); const { workload, isDebug } = workerData; logger.isDebug = isDebug; logger.debug(\u0026#34;Worker\u0026#34;, threadId, \u0026#34;of process\u0026#34;, process.pid, \u0026#34;is running\u0026#34;); monitor.start(); const objects = generateObjects(workload); monitor.end(); logger.debug( \u0026#34;Worker\u0026#34;, threadId, \u0026#34;generated\u0026#34;, objects.length, \u0026#34;in\u0026#34;, monitor.getTotal(), \u0026#34;ms\u0026#34; ); monitor.start(); parentPort.postMessage(objects); monitor.end(); logger.debug(\u0026#34;worker\u0026#34;, threadId, \u0026#34;send data in\u0026#34;, monitor.getTotal(), \u0026#34;ms\u0026#34;); Single thread vs multithreading vs multiprocessing\rNodejs\nsingleThread.js\nconst { TOTAL_OBJS } = require(\u0026#34;../k\u0026#34;); const { generateObjects, Monitor } = require(\u0026#34;../_\u0026#34;); const monitor = new Monitor(); monitor.start(); const obj = generateObjects(TOTAL_OBJS); monitor.end(); console.log(\u0026#34;Generate\u0026#34;, obj.length, \u0026#34;in\u0026#34;, monitor.getTotal(), \u0026#34;ms\u0026#34;); multithread.js\nconst { Worker } = require(\u0026#34;worker_threads\u0026#34;); const { numWorkers, workload, TOTAL_OBJS } = require(\u0026#34;../k\u0026#34;); const { Monitor, Logger } = require(\u0026#34;../_\u0026#34;); let generatedObjects = []; const monitor = new Monitor(); const logger = new Logger(true); // set true to see more logs logger.isDebug = true; function runWorker(workerData) { return new Promise((resolve, reject) =\u0026gt; { const worker = new Worker(\u0026#34;./worker_threads/worker.js\u0026#34;, { workerData }); logger.debug(\u0026#34;Worker\u0026#34;, worker.threadId, \u0026#34;is running\u0026#34;); worker.on(\u0026#34;message\u0026#34;, (message) =\u0026gt; { generatedObjects = generatedObjects.concat(message); }); worker.on(\u0026#34;error\u0026#34;, reject); worker.on(\u0026#34;exit\u0026#34;, (code) =\u0026gt; { if (code === 0) { resolve(); } else { reject(new Error(`Worker stopped with exit code ${code}`)); } }); }); } async function generateObjectsWithWorkers() { const workers = []; monitor.start(); for (let i = 0; i \u0026lt; numWorkers; i++) { const workerData = { workload, isDebug: logger.isDebug, }; workers.push(runWorker(workerData)); } await Promise.all(workers); monitor.end(); logger.logP1( \u0026#34;All done!\u0026#34;, numWorkers, \u0026#34;workers,\u0026#34;, generatedObjects.length, \u0026#34;objects, in\u0026#34;, monitor.getTotal(), \u0026#34;ms\u0026#34; ); } generateObjectsWithWorkers(); multiprocess.js\nconst cluster = require(\u0026#34;cluster\u0026#34;); const { workload, numWorkers } = require(\u0026#34;../k\u0026#34;); const { Monitor, Logger, generateObjects } = require(\u0026#34;../_\u0026#34;); const logger = new Logger(true); const monitor = new Monitor(); // set true to see more logs logger.isDebug = true; if (cluster.isMaster) { monitor.start(); logger.logP1(\u0026#34;Master\u0026#34;, process.pid, \u0026#34;is running\u0026#34;); // Fork slaves for (let i = 0; i \u0026lt; numWorkers; i++) { cluster.fork(); } // Collect data from slaves let generatedObjects = []; cluster.on(\u0026#34;message\u0026#34;, (slave, message) =\u0026gt; { generatedObjects = generatedObjects.concat(message); }); // Wait for all workers to finish logic let slaveOff = 0; cluster.on(\u0026#34;disconnect\u0026#34;, () =\u0026gt; { slaveOff++; if (slaveOff === numWorkers) { monitor.end(); logger.logP1( \u0026#34;All done!\u0026#34;, slaveOff, \u0026#34;slaves, in\u0026#34;, monitor.getTotal(), \u0026#34;ms\u0026#34; ); // Exit the application process.exit(0); } }); } else { // Slave process logic logger.debug(\u0026#34;Slave\u0026#34;, process.pid, \u0026#34;is running\u0026#34;); let generatedObjects = []; // Generate objects in the worker process monitor.start(); const objects = generateObjects(workload); monitor.end(); generatedObjects = generatedObjects.concat(objects); logger.debug( \u0026#34;Generated\u0026#34;, objects.length, \u0026#34;objects in slave\u0026#34;, process.pid, \u0026#34;in\u0026#34;, monitor.getTotal(), \u0026#34;ms\u0026#34; ); // Send objects to the master process monitor.start(); process.send(objects); monitor.end(); logger.debug(\u0026#34;slave\u0026#34;, process.pid, \u0026#34;send data in\u0026#34;, monitor.getTotal(), \u0026#34;ms\u0026#34;); // Disconnect the slave process cluster.worker.disconnect(); } Time-consuming when not communication together\rTime-consuming when running multiple threads and multiple processes without communication together meaning each item runs separately and does not share data\nNodejs\n// TODO: update guideline how it work and how it look (htop) Time-consuming when communication together\rTime-consuming when running multiple threads and multiple processes within communication together meaning each item runs separately but shares data with the main item\nNodejs\n// TODO: update guideline how it work and how it look (htop)\nContext switching\r#\rHow does the OS run threads or processes on a CPU (processor) ? =\u0026gt; This is handled by context switching\rDuring a context switch, one process is switched out of the CPU (processor) so another process can run\nThe OS stores the states of the current running process so the process can be restored and resume execution at a later point\nIt then restores the previously saved states of a different process and resumes execution for that process\nContext switching is expensive. It involves saving and loading registers, switching out memory pages, and updating various kernel data structures\nSwitching execution between threads also requires context switching\nIt’s generally faster to switch context between threads than between processes\nThere are fewer states to track, and more importantly, since threads share the same memory address space, there is no need to switch out virtual memory pages which is one of the most expensive operations during a context switch\nContext switching is so costly, there are other mechanisms to try to minimize it. Some examples are fibers and coroutines\nThese mechanisms trade complexity for even lower context-switching costs\nIn general, they are cooperatively scheduled, that is, they must yield control for others to run\nIn other words, the application itself handles task scheduling\nIt’s the responsibility of the application to make sure a long-running task is broken up by yielding periodically\nConclusion\r#\rProgram, process, and thread:\nThe program contains a set of instructions The program is loaded into memory. It becomes one or more running processes. When a process starts, it is assigned memory and resources The thread is the smallest unit of execution within a process. A process can have one or more threads If we can ideally run each thread on each idle core, we can actually run parallelism all jobs we want with the shortest time consuming\nThe cost when sharing data between threads and processes is also expensive, processes are more expensive than threads because threads inside the process use together shared memory address space\nContext-switching will appear when the scheduler of OS assigns one logical processor more than one thread or process that needs to run. Context-switching is expensive\nAppendix\r#\rProcessor definition\r#\rThere are 2 definitions of the term Processor that can lead you to confusion when researching\nLet’s devine it into 2 names:\nPhysical processor: means processor definition in the hardware world Logical processor: means processor definition in the software world Physical processor\r#\rA processor in this context means the entire CPU chip as the Intel define\nThis image is the complexity of a modern multi-processor, multi-core system Logical processor\r#\rA processor in this context means a virtual core:\nCPU has 8 cores CPU has hyperthreading and it is enabled so each core split into 2 virtual cores Virtual memory\r#\rA computer can address more memory than the amount physically installed on the system. This extra memory is actually called virtual memory and it is a section of a hard disk that\u0026rsquo;s set up to emulate the computer\u0026rsquo;s RAM\nHyper-threading\r#\rIntel® Hyper-Threading Technology is a hardware innovation that allows more than one thread to run on each core. More threads means more work can be done in parallel\nHow does Hyper-Threading work? When Intel® Hyper-Threading Technology is active, the CPU exposes two execution contexts per physical core. This means that one physical core now works like two “logical cores” that can handle different software threads\nReference\r#\rBytebytego: Interview question: Design Twitter (Episode 5) Bytebytego: FANG Interview Question | Process vs Thread Intel: A Better Way to Measure CPU Utilization Medium: Achieving concurrency in Go Stackoverflow: What are the differences between multi-CPU, multi-core and hyper-thread? Tutorialspoint: Operating System - Virtual Memory Wikipedia: Virtual memory Intel: What Is Hyper-Threading? Geeksforgeeks: Difference between User Level thread and Kernel Level thread Geeksforgeeks: Difference between MultiCore and MultiProcessor System Indeed: Multithreading vs. Multiprocessing: What\u0026rsquo;s the Difference? Scaler: Difference Between Multicore and Multiprocessor System Superuser: What\u0026rsquo;s the difference between a multiprocessor and a multiprocessing system? Superuser: What\u0026rsquo;s the difference between multicore proccesor and multiproccess system? Give a thank to ChatGPT dude to support me during a process create multiple supreme demos "},{"id":9,"href":"/docs/research/chrome_architecture/","title":"Chrome Architecture","section":"RESEARCH","content":"\rChrome Architecture\r#\rPrerequisites\r#\rRead process vs thread first if you don\u0026rsquo;t have any process and thread concept in your mind\nBrowser Architecture\r#\rWhen you start an application, a process is created. The program might create thread(s) to help it do work, but that\u0026rsquo;s optional. The Operating System gives the process a \u0026ldquo;slab\u0026rdquo; of memory to work with and all application state is kept in that private memory space. When you close the application, the process also goes away and the Operating System frees up the memory\nA process can ask the Operating System to spin up another process to run different tasks. When this happens, different parts of the memory are allocated for the new process. If two processes need to talk, they can do so by using Inter Process Communication (IPC). Many applications are designed to work this way so that if a worker process get unresponsive, it can be restarted without stopping other processes which are running different parts of the application.\nThere is no standard specification on how one might build a web browser. One browser’s approach may be completely different from another\nChrome uses a separate content process and engine for each website instance, but Firefox reuses processes and engines to limit memory usage\nProcess What it controls? Browser Controls \u0026ldquo;chrome\u0026rdquo; part of the application including address bar, bookmarks, back and forward buttons. Also handles the invisible, privileged parts of a web browser such as network requests and file access Renderer Controls anything inside of the tab where a website is displayed Plugin Controls any plugins used by the website, for example, flash GPU Handles GPU tasks in isolation from other processes. It is separated into different process because GPUs handles requests from multiple apps and draw them in the same surface There are even more processes like the Extension process and utility processes. If you want to see how many processes are running in your Chrome, click the options menu icon more_vert at the top right corner, select More Tools, then select Task Manager. This opens up a window with a list of processes that are currently running and how much CPU/Memory they are using.\nFor the renderer process, multiple processes are created and assigned to each tab. Until very recently, Chrome gave each tab a process when it could; now it tries to give each site its own process, including iframes\nBrowser process\r#\rThread Mission UI Draws buttons and input fields of the browser Network Deals with network stack to receive data from the internet Storage Controls access to the files and more Renderer process\r#\rThe renderer process is responsible for everything that happens inside of a tab\nThread Mission Main The main thread handles most of the code you send to the user Worker Sometimes parts of your JavaScript is handled by worker threads if you use a web worker or a service worker Compositor and Raster Compositor and raster threads are also run inside of a renderer processes to render a page efficiently and smoothly The renderer process\u0026rsquo;s core job is to turn HTML, CSS, and JavaScript into a web page that the user can interact with\nMain thread\r#\rPharse Job Visual Parsing When the renderer process starts to receive HTML data, the main thread begins to parse the text string (HTML) and turn it into a Document Object Model (DOM) Style calculation The main thread parses CSS and determines the computed style for each DOM node. This is information about what kind of style is applied to each element based on CSS selectors Layout The layout is a process to find the geometry of elements. The main thread walks through the DOM and computed styles and creates the layout tree which has information like x y coordinates and bounding box sizes. Layout tree may be similar structure to the DOM tree, but it only contains information related to what\u0026rsquo;s visible on the page Paint The main thread walks the layout tree to create paint records. Paint record is a note of painting process like \u0026ldquo;background first, then text, then rectangle\u0026rdquo; A website usually uses external resources like images, CSS, and JavaScript. Those files need to be loaded from network or cache. The main thread could request them one by one as they find them while parsing to build a DOM, but in order to speed up, \u0026ldquo;preload scanner\u0026rdquo; is run concurrently.\nWhen the HTML parser finds a \u0026lt;script\u0026gt; tag, it pauses the parsing of the HTML document and has to load, parse, and execute the JavaScript code\nWhy? Because JavaScript can change the shape of the document using things like document.write() which changes the entire DOM structure\nThe browser then loads and runs the JavaScript code asynchronously and does not block the parsing. You may also use JavaScript module if that\u0026rsquo;s suitable. \u0026lt;link rel=\u0026quot;preload\u0026quot;\u0026gt; is a way to inform browser that the resource is definitely needed for current navigation and you would like to download as soon as possible. You can read more on this at Resource Prioritization\nJavaScript\r#\rJavaScript, as you may already know, is single threaded, hence you can’t spawn new threads as you like to spread your computation cost over multiple CPU’s core for true-parallel work\nWhen your code is executed it may call the Browser’s APIs to interact with the DOM or schedule some async task. Those async tasks are added to the Event queue or to the prioritized Job queue (if using Promises). As soon as the the Call Stack has finished to process the current tick (is empty), the Event Loop feeds it with a new Tick (which is composed by ONE callback, the FULL job queue, and the POSSIBILITY to call, fully or only some parts, the Render queue)\nCall Stack: it is the place where your code is executed (your functions are loaded and executed, V8 engine in Chrome and NodeJS), it is basically a LIFO stack (last-in-first-out), when it is empty, a.k.a. has completed all the current Tick tasks, it becomes ready to accept the next Tick from the Event Loop Browser APIs: a link between your code and the browser’s internals to schedule tasks, interact with the DOM and more (ex. setTimeout, AJAX, createElement, querySelector, append, click, etc.). In case of callbacks they will add your callback code to the Event queue, instead, in case of a then (promise’s method), your then-code will be added to the Job Queue Event queue: every time you add a callback (ex. via the setTimeout or the AJAX APIs), it is added to this queue Job queue: this queue is reserved for promise’s thens, it is a prioritized queue, its meaning is like ‘execute this code later (= asynchronously), but as soon as possible! (= before the next Event Loop tick)’, and this is why browsers had introduced this new queue to fulfil the Promises specifications Render queue: this is explained in another article Next Tick: it is what will be executed next, basically it’s composed by ONE callback from the Event queue, THE FULL Job queue (this point is important, the current tick will finish only after the Job queue is empty, so you may inadvertently block it from going to the next Tick if you continuously add new jobs to this queue), may re-render (execute the necessary steps in the Render queue to update the screen) Event Loop: it monitors the Call Stack, as soon as it is empty (has finished to process the current tick), the Event Loop feeds it with the next Tick Along the main thread there are many other threads spawned by the browser to do useful stuff:\nParser Thread: parses your code in machine-understandable trees Statistics collector Thread: collects data and statistics to discover insights about your code (the scope is to optimize it runtime) Optimizer Thread: uses the statistics and insights collected by the Statistics collector Thread to make performance optimizations over your code (Caching, Inlining, etc.) Garbage Collector Thread: removes unconnected (no more referenceable from the ROOT node) JavaScript objects to free up memory using a mark-and-sweep algorithm. We don’t know when this will happen and have no control over it. AFAIK the browser uses this thread to track whose objects to remove and do useful stuff, but when it needs to remove them it actually blocks the main thread and uses it. From the Firefox blog Q:”Silly question here, why must garbage collection stop UI events and js execution? Couldn’t the GC just run in a separate thread?”, R:”It can be done, but the garbage collector is looking at the same objects that the JS currently running is touching, so it must be done carefully. That said, the Firefox GC actually does do some work on a separate thread: some types of objects can be thrown away once they are known to be garbage without affecting the main thread.” Rasterizer Thread: rasterize your graphic into frames Etc. Appendix\r#\rInput events\r#\rThe browser process is only aware of where that gesture occurred since content inside of a tab is handled by the renderer process. So the browser process sends the event type (like touchstart) and its coordinates to the renderer process\nRenderer process handles the event appropriately by finding the event target and running event listeners that are attached\nInput event routed through the browser process to the renderer process\nIf no input event listeners are attached to the page, Compositor thread can create a new composite frame completely independent of the main thread. But what if some event listeners were attached to the page? How would the compositor thread find out if the event needs to be handled?\n“Non-fast scrollable region”\r#\rSince running JavaScript is the main thread\u0026rsquo;s job, when a page is composited, the compositor thread marks a region of the page that has event handlers attached as \u0026ldquo;Non-Fast Scrollable Region\u0026rdquo;\nBy having this information, the compositor thread can make sure to send input event to the main thread if the event occurs in that region. If input event comes from outside of this region, then the compositor thread carries on compositing new frame without waiting for the main thread\nReference\r#\rChrome: Inside look at modern web browser (part 1) (2018 Sep 21) Chrome: Inside look at modern web browser (part 2) (2018 Sep 21) Chrome: Inside look at modern web browser (part 3) (2020 Aug 18) Chrome: Inside look at modern web browser (part 4) (2019 Jan 12) Gitconnected: How web browsers use processes and threads (2020 Jul 17) Medium: Javascript main thread dissected (2017 Nov 13) V8: JavaScript modules (2018 Jun 18) "},{"id":10,"href":"/docs/research/aws_overview/","title":"AWS Overview","section":"RESEARCH","content":"\rAWS Overview\r#\rSlide\r#\rTypes of Cloud Computing\r#\rEC2 - Elastic Compute Cloud\r#\rEC2 = Infrastructure as a Service (IaaS) On-Demand Instances – short workload, predictable pricing, pay by second Has the highest cost Recommended for short-term and un-interrupted workloads, where you can\u0026rsquo;t predict how the application will behave Reserved (1 \u0026amp; 3 years) Reserved Instances – long workloads Recommended for steady-state usage applications (think database) Convertible Reserved Instances – long workloads with flexible instances Savings Plans (1 \u0026amp; 3 years) – commitment to an amount of usage, long workload Spot Instances – short workloads, cheap, can lose instances (less reliable) The MOST cost-efficient Dedicated Hosts – book an entire physical server, control instance placement The most expensive option Dedicated Instances – no other customers will share your hardware No control over instance placement Capacity Reservations – reserve capacity in a specific AZ for any duration AMI - Amazon Machine Image\r#\rAMI are a customization of an EC2 instance AMI are built for a specific region (and can be copied across regions) You can launch EC2 instances from: A Public AMI: AWS provided Your own AMI: you make and maintain them yourself An AWS Marketplace AMI: an AMI someone else made (and potentially sells) EC2 Image Builder\r#\rUsed to automate the creation of Virtual Machines or container images\n=\u0026gt; Automate the creation, maintain, validate and test EC2 AMIs Can be run on a schedule (weekly, whenever packages are updated, etc…) Free service (only pay for the underlying resources) EBS - Elastic Block Store\r#\rA network drive you can attach to your instances while they run It allows your instances to persist data, even after their termination They can only be mounted to one instance at a time They are bound to a specific AZ Think of them as a “network USB stick”\nSnapshots\r#\rMake a backup (snapshot) of your EBS volume at a point in time Can copy snapshots across AZ or Region Snapshots Features\r#\rSnapshot Archive Move a Snapshot to an ”archive tier” that is 75% cheaper Takes within 24 to 72 hours for restoring the archive Recycle Bin for EBS Snapshots Setup rules to retain deleted snapshots so you can recover them after an accidental deletion Specify retention (from 1 day to 1 year) EC2 Instance Store\r#\rIf you need a high-performance hardware disk, use EC2 Instance Store Better I/O performance EC2 Instance Store lose their storage if they’re stopped (ephemeral) Good for buffer / cache / scratch data / temporary content Risk of data loss if hardware fails Backups and Replication are your responsibility EFS - Elastic File System\r#\rManaged NFS (network file system) that can be mounted on 100s of EC2 EFS works with Linux EC2 instances in multi-AZ Highly available, scalable, expensive (3x gp2), pay per use, no capacity planning EFS IA - EFS Infrequent Access\r#\rStorage class that is cost-optimized for files not accessed every day EFS will automatically move your files to EFS-IA based on the last time they were accessed Enable EFS-IA with a Lifecycle Policy FSx\r#\rfor Windows File Server\r#\rA fully managed, highly reliable, and scalable Windows native shared file system Built on Windows File Server Supports SMB protocol \u0026amp; Windows NTFS Integrated with Microsoft Active Directory Can be accessed from AWS or your on-premise infrastructure for Lustre\r#\rA fully managed, high-performance, scalable file storage for High Performance Computing (HPC) The name Lustre is derived from “Linux” and “cluster” Machine Learning, Analytics, Video Processing, Financial Modeling, … S3\r#\r\u0026ldquo;infinitely scaling\u0026rdquo; storage Buckets\r#\rAllows people to store objects (files) in buckets (directories) Buckets must have a globally unique name (across all regions all accounts) Buckets are defined at the region level Naming convention No uppercase, No underscore 3-63 characters long Not an IP Must start with lowercase letter or number Must NOT start with the prefix xn\u0026ndash; Must NOT end with the suffix -s3alias Objects\r#\rObjects (files) have a Key The key is the FULL path: s3://my-bucket/my_file.txt s3://my-bucket/my_folder1/another_folder/my_file.txt The key is composed of prefix + object name s3://my-bucket/my_folder1/another_folder/my_file.txt There’s no concept of “directories” within buckets\n(although the UI will trick you to think otherwise) Just keys with very long names that contain slashes (“/”) Object values are the content of the body: Max. Object Size is 5TB (5000GB) If uploading more than 5GB, must use “multi-part upload” Security\r#\rUser-Based IAM Policies – which API calls should be allowed for a specific user from IAM Resource-Based Bucket Policies – bucket wide rules from the S3 console - allows cross account Object Access Control List (ACL) – finer grain (can be disabled) Bucket Access Control List (ACL) – less common (can be disabled) Static Website Hosting\r#\rS3 can host static websites and have them accessible on the Internet The website URL will be (depending on the region) http :// bucket-name .s3-website-aws-region.amazonaws.com\nOR http :// bucket-name .s3-website.aws-region.amazonaws.com If you get a 403 Forbidden error, make sure the bucket policy allows public reads! Versioning\r#\rIt is enabled at the bucket level It is best practice to version your buckets Protect against unintended deletes (ability to restore a version) Easy roll back to previous version Notes: Any file that is not versioned prior to enabling versioning will have version “null” Suspending versioning does not delete the previous versions Replication\r#\rMust enable Versioning in source and destination buckets Cross-Region Replication (CRR) Same-Region Replication (SRR) Buckets can be in different AWS accounts Copying is asynchronous Must give proper IAM permissions to S3 Use cases: CRR – compliance, lower latency access, replication across accounts SRR – log aggregation, live replication between production and test accounts Storage Classes\r#\rAmazon S3 Standard - General Purpose Used for frequently accessed data Use Cases: Big Data analytics, mobile \u0026amp; gaming applications, content distribution Amazon S3 Standard-Infrequent Access (IA) For data that is less frequently accessed, but requires rapid access when needed Use cases: Disaster Recovery, backups Amazon S3 One Zone-Infrequent Access For data that is less frequently accessed, but requires rapid access when needed In a single AZ; data lost when AZ is destroyed Use Cases: Storing secondary backup copies of on-premise data, or data you can recreate Amazon S3 Glacier Instant Retrieval For data accessed once a quarter Millisecond retrieval Amazon S3 Glacier Flexible Retrieval (formerly Amazon S3 Glacier) Retrieval: Expedited (1 to 5 minutes), Standard (3 to 5 hours), Bulk (5 to 12 hours) – free Amazon S3 Glacier Deep Archive For long term storage Retrieval: Standard (12 hours), Bulk (48 hours) Amazon S3 Intelligent Tiering\nMoves objects automatically between Access Tiers based on usage Frequent Access tier (automatic): default tier Infrequent Access tier (automatic): objects not accessed for 30 days Archive Instant Access tier (automatic): objects not accessed for 90 days Archive Access tier (optional): configurable from 90 days to 700+ days Deep Archive Access tier (optional): config. from 180 days to 700+ days Encryption\r#\rIAM Access Analyzer\r#\rEnsures that only intended people have access to your S3 buckets Example: publicly accessible bucket, bucket shared with other AWS account… Evaluates S3 Bucket Policies, S3 ACLs, S3 Access Point Policies Powered by IAM Access Analyzer Snow Family\r#\rHighly-secure, portable devices to collect and process data at the edge, and migrate data into and out of AWS Data migration: Snowcone, Snowball Edge, Snowmobile Edge computing: Snowcone, Snowball Edge OpsHub\r#\rA software you install on your computer / laptop To manage your Snow Family Device Transferring files Launch compatible AWS services on your devices (ex: Amazon EC2 instances, AWS DataSync, Network File System (NFS)) Storage Gateway\r#\rBridge between on-premise data and cloud data in S3 Hybrid storage service to allow on-premises to seamlessly use the AWS Cloud Use cases: disaster recovery, backup \u0026amp; restore, tiered storage Monitoring\r#\rCloudWatch: Metrics: monitor the performance of AWS services and billing metrics Alarms: automate notification, perform EC2 action, notify to SNS based on metric Logs: collect log files from EC2 instances, servers, Lambda functions… Events (or EventBridge): react to events in AWS, or trigger a rule on a schedule CloudTrail: audit API calls made within your AWS account CloudTrail Insights: automated analysis of your CloudTrail Events X-Ray: trace requests made through your distributed applications AWS Health Dashboard: status of all AWS services across all regions AWS Account Health Dashboard: AWS events that impact your infrastructure Amazon CodeGuru: automated code reviews and application performance recommendations ECS - Elastic Container Service\r#\rYou must provision \u0026amp; maintain the infrastructure (the EC2 instances) Fargate\r#\rYou do not provision the infrastructure (no EC2 instances to manage) – simpler! Serverless offering ECR - Elastic Container Registry\r#\rStore your Docker images Lambda\r#\rVirtual functions – no servers to manage! Limited by time - short executions Run on-demand Scaling is automated! Event-Driven: functions get invoked by AWS when needed Pricing\r#\rPay per calls Pay per duration Example\r#\rServerless Thumbnail creation\nServerless CRON Job\nAPI Gateway\r#\rServerless and scalable Supports RESTful APIs and WebSocket APIs Support for security, user authentication, API throttling, API keys, monitoring\u0026hellip; Batch\r#\rFully managed batch processing at any scale Batch will dynamically launch EC2 instances or Spot Instances Batch jobs are defined as Docker images and run on ECS Batch vs Lambda\r#\rLambda\nTime limit Limited runtimes Limited temporary disk space Serverless Batch\nNo time limit Any runtime as long as it’s packaged as a Docker image Rely on EBS / instance store for disk space Relies on EC2 (can be managed by AWS) Lightsail\r#\rSimpler alternative to using EC2, RDS, ELB, EBS, Route 53 Great for people with little cloud experience! \u0026ldquo;almost always be a wrong answer\u0026rdquo; CloudFormation\r#\rInfrastructure as code\nWithin a CloudFormation template, you say:\nI want a security group I want two EC2 instances using this security group I want an S3 bucket I want a load balancer (ELB) in front of these machines Then CloudFormation creates those for you, in the right order, with the exact configuration that you specify\nCDK - Cloud Development Kit\r#\rDefine your cloud infrastructure using a familiar language: JavaScript, Python, \u0026hellip; You can use for loop to create multiple instances The code is “compiled” into a CloudFormation template (JSON/YAML) You can therefore deploy infrastructure and application runtime code together Elastic Beanstalk\r#\rOverview\r#\rA developer centric view of deploying an application on AWS It uses all the component’s we’ve seen before: EC2, ASG, ELB, RDS, etc Beanstalk = Platform as a Service (PaaS) Beanstalk is free but you pay for the underlying instances Just the application code is the responsibility of the developer Three architecture models: Single Instance deployment: good for dev LB + ASG: great for production or pre-production web applications ASG only: great for non-web apps in production (workers, etc..) Health Monitoring\r#\rHealth agent pushes metrics to CloudWatch Checks for app health, publishes health events CodeDeploy\r#\rWe want to deploy our application automatically Works with EC2 Instances Works with On-Premises Servers Hybrid service Servers / Instances must be provisioned and configured ahead of time with the CodeDeploy Agent CodeCommit\r#\rLike GitHub Developers usually store code in a repository, using the Git technology CodeBuild\r#\rCompiles source code, run tests, and produces packages that are ready to be deployed (by CodeDeploy for example) Pay-as-you-go pricing - only pay for the build time CodePipeline\r#\rOrchestrate the different steps to have the code automatically pushed to production Code =\u0026gt; Build =\u0026gt; Test =\u0026gt; Provision =\u0026gt; Deploy Basis for CICD (Continuous Integration \u0026amp; Continuous Delivery) CodeArtifact\r#\rSoftware packages depend on each other to be built (also called code dependencies), and new ones are created Storing and retrieving these dependencies is called artifact management Developers and CodeBuild can then retrieve dependencies straight from CodeArtifact CodeStar\r#\rUnified UI Set-up CodeCommit, CodePipeline, CodeBuild, CodeDeploy, Elastic Beanstalk, EC2, etc Cloud9\r#\rA cloud IDE Allows for code collaboration in real-time (pair programming) SSM - Systems Manager\r#\rManage your EC2 and On-Premises Hybrid AWS service Session Manager\r#\rAllows you to start a secure shell on your EC2 and on-premises servers No SSH access, bastion hosts, or SSH keys needed No port 22 needed (better security) Supports Linux, macOS, and Windows Send session log data to S3 or CloudWatch Logs Parameter Store\r#\rSecure storage for configuration and secrets API Keys, passwords, configurations… Serverless, scalable, durable, easy SDK Control access permissions using IAM Version tracking \u0026amp; encryption (optional) OpsWorks\r#\rAWS OpsWorks = Managed Chef \u0026amp; Puppet Chef \u0026amp; Puppet (2 tools not created by AWS) help you perform server configuration automatically, or repetitive actions Route 53 - DNS\r#\rRoute53 is a Managed DNS (Domain Name System) DNS is a collection of rules and records which helps clients understand how to reach a server through URLs Routing Policies\r#\rCloudFront - CDN\r#\rContent Delivery Network (CDN) Improves read performance, content is cached at the edge DDoS protection (because worldwide), integration with Shield, AWS Web Application Firewall S3 bucket Enhanced security with CloudFront Origin Access Control (OAC) OAC is replacing Origin Access Identity (OAI) CloudFront can be used as an ingress (to upload files to S3) CloudFront vs S3 Cross Region Replication\r#\rCloudFront:\r#\rGlobal Edge network Files are cached for a TTL (maybe a day) Great for static content that must be available everywhere S3 Cross Region Replication:\r#\rMust be setup for each region you want replication to happen Files are updated in near real-time Read only Great for dynamic content that needs to be available at low-latency in few regions S3 Transfer Acceleration\r#\rIncrease transfer speed by transferring file to an AWS edge location which will forward the data to the S3 bucket in the target region Global Accelerator\r#\rImprove global application availability and performance using the AWS global network Leverage the AWS internal network to optimize the route to your application (60% improvement) 2 Anycast IP are created for your application and traffic is sent through Edge Locations The Edge locations send the traffic to your application AWS Global Accelerator vs CloudFront\r#\rThey both use the AWS global network and its edge locations around the world Both services integrate with AWS Shield for DDoS protection CloudFront - CDN\r#\rImproves performance for your cacheable content (such as images and videos) Content is served at the edge Global Accelerator\r#\rNo caching, proxying packets at the edge to applications running in one or more AWS Regions. Improves performance for a wide range of applications over TCP or UDP Good for HTTP use cases that require static IP addresses Good for HTTP use cases that required deterministic, fast regional failover Outposts\r#\rHybrid Cloud: businesses that keep an on-premises infrastructure alongside a cloud infrastructure AWS Outposts are “server racks” that offers the same AWS infrastructure, services, APIs \u0026amp; tools to build your own applications on-premises just as in the cloud AWS will setup and manage “Outposts Racks” within your on-premises infrastructure and you can start leveraging AWS services on-premises You are responsible for the Outposts Rack physical security WaveLength\r#\rWaveLength Zones are infrastructure deployments embedded within the telecommunications providers\u0026rsquo; datacenters at the edge of the 5G networks Use cases: Smart Cities, ML-assisted diagnostics, Connected Vehicles, Interactive Live Video Streams, AR/VR, Real-time Gaming, … Local Zones\r#\rPlaces AWS compute, storage, database, and other selected AWS services closer to end users to run latency-sensitive applications Extend your VPC to more locations – “Extension of an AWS Region” Example: AWS Region: N. Virginia (us-east-1) AWS Local Zones: Boston, Chicago, Dallas, Houston, Miami, … Global Applications Architecture\r#\r"},{"id":11,"href":"/docs/research/be_protocol/","title":"Backend Protocol","section":"RESEARCH","content":"\rBackend Protocol\r#\rWhat is a protocol?\r#\rA system that allows two parties to communicate A protocol is designed with a set of properties Depending on the purpose of the protocol TCP, UDP, HTTP, gRPC, FTP The application protocols (HTTP/1.1, HTTP/2, HTTP/3) run on top of transport protocols (TCP, UDP) Protocol properties\r#\rData format Text based (plain text, JSON, XML) Binary (protobuf, RESP, h2, h3) Transfer mode Message based (UDP, HTTP) Stream (TCP, WebRTC) Addressing system DNS name, IP, MAC Directionality Bidirectional (TCP) Unidirectional (HTTP) Full/Half duplex State Stateful (TCP, gRPC, apache thrift) Stateless (UDP, HTTP) Routing Proxies, Gateways Flow \u0026amp; Congestion control TCP (Flow \u0026amp; Congestion) UDP (No control) Error management Error code Retries and timeouts Why do we need a communication model?\r#\rAgnostic applications App doesn’t need to to know network medium Otherwise we need an App for WIFI, ethernet vs LTE vs fiber Network Equipment Management Without a standard model, upgrading network equipments becomes difficult Decoupled Innovation Innovations can be done in each layer separately without affecting the rest of the models OSI Model\r#\r7 Layers each describe a specific networking component\nLayer 7 - Application - HTTP/FTP/gRPC\nLayer 6 - Presentation - Encoding, Serialization\nLayer 5 - Session - Connection establishment, TLS\nLayer 4 - Transport - UDP/TCP\nLayer 3 - Network - IP\nLayer 2 - Data link - Frames, Mac address Ethernet\nLayer 1 - Physical - Electric signals, fiber or radio waves\nTCP/IP Model\r#\rMuch simpler than OSI just 4 layers\nApplication (Layer 5, 6 and 7) Transport (Layer 4) Internet (Layer 3) Data link (Layer 2) Physical layer is not officially covered in the model "},{"id":12,"href":"/docs/research/encryption/","title":"Encryption","section":"RESEARCH","content":"\rEncryption\r#\r"},{"id":13,"href":"/docs/tips/git/","title":"Git","section":"TIPS","content":"\rGIT TIPS\r#\rTerminology\r#\rHEAD: your current local working branch origin: the address to your remote git, represent for remote repo tracked file: the file git already had before, so when you edit it, git know this file is modified (M files)\nuntracked, new file: the file recently add and git don’t know anything about it (U files)\nCommit\r#\rgit add . git commit -m \u0026#34;commit message\u0026#34; These 2 commands can combie into 1\ngit commit -am \u0026#34;commit message\u0026#34; Note: this only work with tracked files\nChange previous commit message\r#\rCommit amend\r#\rgit commit --amend -m \u0026#34;new message to replace the previous message\u0026#34; Note: this amend can also simplify by amen :))))\nRebase reword\r#\rgit rebase -i HEAD~1 Vim IDE appear and show a latest commit\rtype i to begin insert mode, ready to modify change pick to r or reword → means you will change this commit message press ESC key to end insert mode type :wq to save new Vim IDE appear to let you change the commit message change and save like the early steps git push -f Opps! Code on wrong branch\r#\rStash\r#\rgit stash git checkout correct-branch git stash pop Note: git stash will only bring the changes on tracked files to store but don\u0026rsquo;t worry when checkout to other branch, the untracked files will move to there also\nOpps! Commit into local main branch\r#\rReset\r#\rSolution 1: Erase the current commit and go back to the earlier commit\ngit reset --hard HEAD~1 Solution 2: Bring the current commit to staged change and go back to the earlier commit\ngit reset --soft HEAD~1 Update the outdated feature branch\r#\rRelocate branch: rebase\r#\rbefore rebase\n==\u0026gt; after rebase\ngit checkout master git pull git rebase master topic git push -f Note: topic branch will have code from F and G of main branch, but if it conflicts with topic branch, the solution will be the same here\nPull origin\r#\rCollect code from master to feature branch. Feature branch in this example is topic branch\ngit checkout master git pull git checkout topic git pull origin master Note: never ever tried it yet\rClean up messy commits\r#\rAccumulate commits: rebase fixup\r#\rIf you have 3 messy commits per 4 commits on your feature branch\ngit rebase -i HEAD~4 Vim IDE appear and show 4 latest commits\rType i to change into insert mode Change pick to f or fixup → means you accumulate this 3 commits Out insert mode with ESC key Type :wq to save\ngit push -f before after Note: the present commit will have all changes from 3 previous commits\nDelete all local branches except main branch\r#\rgit branch | grep -v \u0026#34;main\u0026#34; | xargs git branch -D Explain:\nGet all branches (except for the main) via git branch | grep -v \u0026quot;main\u0026quot; command Select every branch with xargs command Delete branch with git branch -D Refresh outdated local branch\r#\rIf you pull but show some warnings or errors and git show a recommend that is need to type some rebase commands Just checkout to another branch, delete your local conflict branch and then checkout to this branch again to download a latest one in remote repo git checkout dev git branch -D feature-branch git fetch git checkout feature-branch Force pull\r#\rgit pull -f Note: never ever tried it yet\rMerge PR but get stuck in conflict\r#\rRelocate branch: rebase\r#\rgit checkout main git pull checkout feature-branch git rebase main feature-branch Conflict appears in IDE\n→ Resolve conflict and save file\rgit add . git rebase --continue Vim IDE appear to make you confirm change\n→ :wq\rgit push -f Log pretty\r#\rgit log --graph --decorate --oneline or\ngit log --graph --decorate Config\r#\rShow current global credential\r#\rgit config --global --list Configure local repo’s credential\r#\rwhen you want it’s different with the global one\ngit config user.name DangPham112000 git config user.email dangpham112000@gmail.com Switch git user tool\r#\rhttps://github.com/geongeorge/Git-User-Switch\n"},{"id":14,"href":"/docs/research/security/","title":"Security","section":"RESEARCH","content":"\rSecurity\r#\rDDOS\r#\rBackdoor attack\r#\rSQL injection\r#\rCross-site scripting (XSS) attack\r#\rCross-site request forgery (CSRF) attack\r#\rCross-domain access attack\r#\rSyn flood attack\r#\rRelay attack\r#\rMan in the middle attack\r#\rrequest modify\r#\rresponse modify\r#\r"},{"id":15,"href":"/docs/tips/unit_test/","title":"Unit Test","section":"TIPS","content":"\rUnit Test\r#\rReset all global variables for each unit test case\r#\rWhat environment the unit test cases are running on: Browser or Nodejs?\r#\rBecause Nodejs does not have browser APIs Using Karma to run browser\u0026rsquo;s unit test Using JS-DOM but it\u0026rsquo;s missing a lot of browser APIs Work only when running alone\r#\rScenario: A unit test case only pass when running alone but fail when running with other test cases\rCheck:\nRestore all mocks after mocking things: sandbox.restore(), jest.restoreAllMocks(), vi.restoreAllMocks() and vi.unstubAllGlobals() at afterEach Reset global variables inner module: create a reset function to reset all variable of module to the initial value Example:\n// calculateThings.js import cal1Thing from \u0026#34;./private/cal1Thing.js\u0026#34;; let cached = \u0026#34;\u0026#34;; // Global variable export default (things) =\u0026gt; { if (cached) return cached; let result = []; for (let i = 0; i \u0026lt; things.length; i++) { const calculatedThing = cal1Thing(things[i]); result.push(calculatedThing); } cached = result; return cached; }; /* start-test-code */ export const testingOnly = { resetCached: () =\u0026gt; { cached = \u0026#34;\u0026#34;; }, }; /* end-test-code */ // calculateThings.test.js import calculateThings from \u0026#34;./calculateThings\u0026#34;; import cal1Thing from \u0026#34;./cal1Thing\u0026#34;; import { testingOnly } from \u0026#34;./calculateThings\u0026#34;; vi.mock(\u0026#34;./cal1Thing\u0026#34;); describe(\u0026#34;calculateThings\u0026#34;, () =\u0026gt; { const { resetCached } = testingOnly; afterEach(() =\u0026gt; { vi.restoreAllMocks(); }); it(\u0026#34;should work as expected\u0026#34;, () =\u0026gt; { cal1Thing.mockReturnValue(\u0026#34;a string\u0026#34;); const caledThings = calculateThings([1, 2, 3]); expect(caledThings).toEqual([\u0026#34;a string\u0026#34;, \u0026#34;a string\u0026#34;, \u0026#34;a string\u0026#34;]); }); it(\u0026#34;should return empty when empty cached and input is empty array\u0026#34;, () =\u0026gt; { resetCached(); // remember reset cached const caledThings = calculateThings([]); expect(caledThings).toEqual(\u0026#34;\u0026#34;); }); }); Setup code for testing only\r#\rThis setup will help you export function only when run test, not appear when build\rGulp - Rollup\r#\r// rollup.bundle.js import stripCode from \u0026#34;rollup-plugin-strip-code\u0026#34;; import {rollup} from rollup; const stripcode = stripCode({ start_comment: \u0026#34;start-test-code\u0026#34;, end_comment: \u0026#34;end-test-code\u0026#34;, }); export default async () =\u0026gt; { const bundle = await rollup({input: \u0026#39;mainFilePath.js\u0026#39;, plugins: [stripcode]}); await bundle.write({ file: \u0026#39;dist/destinationName.js\u0026#39;, format: \u0026#39;iife\u0026#39;, name: \u0026#39;YourObjectName\u0026#39;, sourcemap: false }) } // gulpfile.js import rollupBundle from \u0026#34;./rollup.bundle.js\u0026#34;; const clean = () =\u0026gt; { // remove all previous build files or ST like that }, lint = () =\u0026gt; { // run eslint warning }; export default () =\u0026gt; { series(clean, rollupBundle, lint); }; Vite - Vitest\r#\rMock module\r#\rWhen you mock a module, everything you exported in this module will be mocked and can not act like original (even if you call vi.restoreAllMocks())\rSolution:\nIf your module exports alots, and you only want to mock one thing, you shoult split it into another module\nExample:\n// calculateThings.js import cal1Thing from \u0026#34;./private/cal1Thing.js\u0026#34;; export default (things) =\u0026gt; { let result = []; for (let i = 0; i \u0026lt; things.length; i++) { const calculatedThing = cal1Thing(things[i]); result.push(calculatedThing); } return result; }; // calculateThings.test.js import calculateThings from \u0026#34;./calculateThings\u0026#34;; import cal1Thing from \u0026#34;./cal1Thing\u0026#34;; vi.mock(\u0026#34;./cal1Thing\u0026#34;); describe(\u0026#34;calculateThings\u0026#34;, () =\u0026gt; { afterEach(() =\u0026gt; { vi.restoreAllMocks(); }); it(\u0026#34;should work as expected\u0026#34;, () =\u0026gt; { cal1Thing.mockReturnValue(\u0026#34;a string\u0026#34;); const caledThings = calculateThings([1, 2, 3]); expect(caledThings).toEqual([\u0026#34;a string\u0026#34;, \u0026#34;a string\u0026#34;, \u0026#34;a string\u0026#34;]); }); }); Sinon\r#\rStub a function that is called by another function in the same module\r#\rUsing this.[func_name] when calling it in your module\nStub an export default function\r#\rimport * as query from \u0026#34;/database/query\u0026#34;; const makeQueryStub = sandbox.stub(query, \u0026#34;default\u0026#34;).resolves([]); Mocha - Chai - Sinon sample\r#\rimport sinon from \u0026#34;sinon\u0026#34;; import { function_name, callback_function_name } from \u0026#34;../module_name.js\u0026#34;; const sandbox = sinon.createSandbox(); describe(\u0026#34;module_name\u0026#34;, function () { afterEach(function () { sandbox.restore(); }); describe(\u0026#34;function_name\u0026#34;, function () { it(\u0026#34;Should be a function\u0026#34;, function () { expect(function_name).to.be.a(\u0026#34;function\u0026#34;); }); it(\u0026#34;Should return this value if window.screen is undefined\u0026#34;, function () { sandbox.stub(window, \u0026#34;screen\u0026#34;).value(undefined); expect(function_name()).equal(\u0026#34;expected string\u0026#34;); }); it(\u0026#34;should return expected object when running callback function\u0026#34;, function (done) { callback_function_name(function (returnedData) { expect(returnedData).to.deep.equal({ name: \u0026#34;expected object\u0026#34; }); done(); }); }); }); }); Jest - Sinon sample\r#\rimport sinon from \u0026#34;sinon\u0026#34;; import { function_name, async_function_name } from \u0026#34;../module_name.js\u0026#34;; const sandbox = sinon.createSandbox(); describe(\u0026#34;module_name\u0026#34;, function () { afterEach(function () { sandbox.restore(); }); describe(\u0026#34;function_name\u0026#34;, function () { it(\u0026#34;Should be a function\u0026#34;, function () { expect(typeof function_name).toEqual(\u0026#34;function\u0026#34;); }); it(\u0026#34;Should return this value if window.screen is undefined\u0026#34;, function () { sandbox.stub(window, \u0026#34;screen\u0026#34;).value(undefined); expect(function_name()).toEqual(\u0026#34;expected string\u0026#34;); }); it(\u0026#34;should return expected object when handling function asynchronously\u0026#34;, async () =\u0026gt; { const returnedData = await async_function_name(); expect(returnedData).toEqual({ name: \u0026#34;expected object\u0026#34; }); }); }); }); "},{"id":16,"href":"/docs/problems/design_hashmap/","title":"Design HashMap","section":"PROBLEMS","content":"\rDesign HashMap\r#\rOverview\r#\rIts other names: hash table, map, unordered map, dictionary\nA hash table is a data structure that you can use to store data in key-value format with direct access to its items in constant time\nThe most valuable aspect of a hash table over other abstract data structures is its speed to perform insertion, deletion, and search operations. Hash tables can do them all in constant time\nTime complexity\nOperation Average Worst case Search O(1) O(n) Insert O(1) O(n) Delete O(1) O(n) Space complexity\nSpace O(n) O(n) Design requirement\r#\rLet\u0026rsquo;s begin with a hash map for storing phone books\nHash map for storing phone books\nNot using any built-in hash map libraries HashMap() initializes the object with an empty map void put(string key, string value) inserts a (key, value) pair into the HashMap. If the key already exists in the map, update the corresponding value string get(key) returns the value to which the specified key is mapped, or empty string if this map contains no mapping for the key void remove(key) removes the key and its corresponding value if the map contains the mapping for the key Design hashing function\r#\rHash collisions\r#\rProblem\r#\rSolution\r#\rOpen addressing Linear probing Plus 3 rehash Quadratic probing (failed attempts) Double hashing Closed addresing Use cases\r#\rSets\r#\rA set is like a hash map except it only stores keys, without values\nReference\r#\rLeetcode: Design HashMap Interviewcake: Hash Table (2018 Jun 18) Freecodecamp: JavaScript Hash Table – Associative Array Hashing in JS Wikipedia: Hash table Khalilstemmler: Hash Tables | What, Why \u0026amp; How to Use Them (Jan 19th, 2022) Youtube: Hash Tables and Hash Functions (Mar 5th, 2017) "},{"id":17,"href":"/docs/research/event_loop/","title":"Event loop","section":"RESEARCH","content":"\rEvent loop\r#\rChallenge\r#\rCan you guess the output of the below JS code\nvar name = \u0026#34;JS\u0026#34;; function execLater() { setTimeout(printName, 0); Promise .resolve() .then(() =\u0026gt; { console.log(\u0026#34;Promise resolve\u0026#34;); }); console.log(name); var name = \u0026#34;TS\u0026#34;; } printName(name); function printName() { console.log(name); } execLater(); Phase 1: the memory creation phase\nname is declared and initialized equal \u0026quot;JS\u0026quot; execLater is declared and initialized printName is declared and initialized Phase 2: the code execution phase\nprintName is called and it prints \u0026quot;JS\u0026quot; execLater is called: Phase 1: name is assigned to undefined due to hoisting Phase 2: printName goes to the callback queue and wait for 0ms to be executed later The promise goes to the microtask queue printName is executed with the value of name is undefined name is assigned to \u0026quot;TS\u0026quot; but only in execLater scope Once the call stack is empty, the event loop pulls the promise to execute it as it has higher priority printName is called and print \u0026quot;JS\u0026quot; b/c it referents to the global scope The display order on the console\rJS undefined Promise resolve JS Overview\r#\rStack\r#\rHeap\r#\rQueue\r#\rReference\r#\rMozilla: The event loop (Dec 20, 2023) Youtube: What the heck is the event loop anyway? | Philip Roberts | JSConf EU (Oct 9, 2014) Nodejs: The Node.js Event Loop "},{"id":18,"href":"/docs/research/javascript_engine/","title":"JavaScript Engine","section":"RESEARCH","content":"\rJavaScript Engine\r#\rV8: Google Chrome, NodeJS SpiderMonkey: Firefox JavaScriptCore: Safari Reference\r#\rNodejs: The V8 JavaScript Engine Mozilla: SpiderMonkey Apple: JavaScriptCore "},{"id":19,"href":"/docs/problems/knight_dialer/","title":"Knight Dialer","section":"PROBLEMS","content":"\rKnight dialer\r#\rDescription\r#\rThe chess knight has a unique movement, it may move two squares vertically and one square horizontally, or two squares horizontally and one square vertically (with both forming the shape of an L). The possible movements of chess knight are shown in this diagaram:\nA chess knight can move as indicated in the chess diagram below: We have a chess knight and a phone pad as shown below, the knight can only stand on a numeric cell (i.e. blue cell). Given an integer n, return how many distinct phone numbers of length n we can dial.\nYou are allowed to place the knight on any numeric cell initially\nand then you should perform n - 1 jumps to dial a number of length n. All jumps should be valid knight jumps.\nAs the answer may be very large, return the answer modulo \\(10^9 \u0026#43; 7\\)\rExample 1:\nInput: n = 1\nOutput: 10\nExplanation: We need to dial a number of length 1, so placing the knight over any numeric cell of the 10 cells is sufficient\nExample 2:\nInput: n = 2\nOutput: 20\nExplanation: All the valid number we can dial are [04, 06, 16, 18, 27, 29, 34, 38, 40, 43, 49, 60, 61, 67, 72, 76, 81, 83, 92, 94]\nExample 3:\nInput: n = 3131\nOutput: 136006598\nExplanation: Please take care of the mod\nConstraints:\n1 \u0026lt;= n \u0026lt;= 5000 Solution\r#\rHigh level\r#\rCó thể thấy bàn phím điện thoại khá nhỏ Ta có thể tận dụng các giới hạn này để giải quyết bài toán thay vì đâm đầu vào một công thức tổng quát: Ở một vị trí chỉ có thể nhảy đến 1 tập giới hạn các vị trí khác Số cách di chuyển ở mỗi vị trí là hằng số và có thể liệt kê được Low level\r#\rTa nên bắt đầu bằng 1 ví dụ: đẹp nhất là n = 3\nỞ lần đầu thì vị trí là tất cả các nút Ở lần 2 thì cần duyệt qua từ 0 đến 9 vị trí 0 sẽ có thể nhảy đến 4 và vị trí 1 sẽ có thể nhảy đến 8 và \u0026hellip; Ở lần 3 thì ta sẽ duyệt tiếp bên trong vị trí 0 ở lần 2 vị trí 4 sẽ có thể nhảy đến 3, 9 và 0 vị trí 6 sẽ có thể nhảy đến 1, 7 và 0 trong vị trí 1 ở lần 2 8 =\u0026gt; 1, 3 6 =\u0026gt; 1, 7, 0 \u0026hellip; Các kết quả cần tìm\nVới n = 1, return 10 Với n = 2, 0 có thể đến 4 và 6, 1 có thể đến 8 và 6 Với n = 3, 0 có thể đến 3, 9, 0, 1, 7, 0 1 có thể đến 1, 3, 1, 7, 0 Kết quả là tổng sống lượng vị trí có thể đến\nCần tạo 1 mảng chứa các vị trí khả dụng qua mỗi lần lặp n Có thể thấy ta có thể tạo 2 mảng\nMảng số vị trí khả dụng kế tiếp khi ở vị trí i: [[4, 6], [8, 6], []] Có thể thấy để dùng được mảng vị trí khả dụng thì n phải \u0026gt;= 2 Vậy thì thuật toán cần tìm phải bắt đầu ít nhất từ 2 Code\r/** * @param {number} n * @return {number} */ var knightDialer = function (n) { const nextPlaces = [ [4, 6], [6, 8], [7, 9], [4, 8], [0, 3, 9], [], [0, 1, 7], [2, 6], [1, 3], [2, 4], ]; if (n === 1) return 10; const validPlaces = JSON.parse(JSON.stringify(nextPlaces)); for (let time = 3; time \u0026lt;= n; time++) { for (let place = 0; place \u0026lt;= 9; place++) { const newPlaces = []; for (let i = 0; i \u0026lt; validPlaces[place].length; i++) { newPlaces.push(...nextPlaces[validPlaces[place][i]]); } validPlaces[place] = newPlaces; } } const totalWays = validPlaces.reduce((acc, currentArray) =\u0026gt; acc + currentArray.length, 0) % (Math.pow(10, 9) + 7); return totalWays; }; Xuất hiện lỗi runtime error: Cụ thể thì là do out of memory\nKhi thử với các test case nhỏ thì dễ thấy hàm của chúng ta work như mong đợi Nhưng khi thử với số lớn thì sẽ xuất hiện lỗi out of memory Giải thuật chưa tối ưu bộ nhớ ? Chọn cấu trúc dữ liệu chưa phù hợp ? Optimize\r#\rRetrospective\r#\rCùng nhìn lại cách diễn giải ban đầu:\nn = 1: tất cả các nút\n==\u0026gt; [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]] n = 2: 0 có thể đến 4 và 6 1 có thể đến 8 và 6 2 có thể đến 7 và 9 \u0026hellip;\n==\u0026gt; [[4, 6], [6, 8], [7, 9], [4, 8], [0, 3, 9], [], [0, 1, 7], [2, 6], [1, 3], [2, 4]] n = 3: 0 có thể đến 3, 9, 0, 1, 7, 0 1 có thể đến 1, 3, 1, 7, 0 \u0026hellip;\n==\u0026gt; [[3, 9, 0, 1, 7, 0], [1, 3, 1, 7, 0], ...] \u0026hellip; Dễ thấy n càng cao số phần từ trùng lặp lại trong mảng càng cao Với mỗi phần tử trùng ấy ta lại có cùng một công việc cho chúng Kết quả cần tìm lại là đếm số lượng phần tử của từng mảng ==\u0026gt; Nếu có thể áp dụng cấu trúc Dictionary sẽ là một phương pháp tối ưu\nNew way\r#\rCách diễn dãi mới\nn = 1\n==\u0026gt; dic = {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1}\n==\u0026gt; dic = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n==\u0026gt; Nên chọn array vì key chúng ta cần chỉ là các con số từ 0-\u0026gt;9 n = 2 0 có thể đến 4 và 6 =\u0026gt; newDic[4] += dic[0] và newDic[6] += dic[0] newDic[4] += dic[0] vì giả sử vị trí 0 đang chứa 2 khả năng, thì 2 khả năng đó đều đi đến được 4 Dùng newDic là để trạng thái cũ k bị xáo trộn khi đang duyệt 1 có thể đến 8 và 6 =\u0026gt; newDic[8] += dic[1] và newDic[6] += dic[1] \u0026hellip; Code\r/** * @param {number} n * @return {number} */ var knightDialer = function (n) { const nextPlaces = [ [4, 6], [6, 8], [7, 9], [4, 8], [0, 3, 9], [], [0, 1, 7], [2, 6], [1, 3], [2, 4], ]; if (n === 1) return 10; let dic = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]; for (let time = 2; time \u0026lt;= n; time++) { const newDic = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]; for (let place = 0; place \u0026lt;= 9; place++) { for (let i = 0; i \u0026lt; nextPlaces[place].length; i++) { newDic[nextPlaces[place][i]] += dic[place] % (Math.pow(10, 9) + 7); } } dic = newDic; } const totalWays = dic.reduce((acc, item) =\u0026gt; acc + item, 0) % (Math.pow(10, 9) + 7); return totalWays; }; Time and space complexity optimize\r#\rCode\rTiêu chí là ít tính toán lại và tận dụng nhiều hơn\r#\r/** * @param {number} n * @return {number} */ var knightDialer = function (n) { const nextPlaces = [ [4, 6], [6, 8], [7, 9], [4, 8], [0, 3, 9], [], [0, 1, 7], [2, 6], [1, 3], [2, 4], ]; if (n === 1) return 10; const mod = Math.pow(10, 9) + 7; let dic = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], newDic = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], place, i; for (let time = 2; time \u0026lt;= n; time++) { newDic = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]; for (place = 0; place \u0026lt;= 9; place++) { if (place === 5) continue; for (i = 0; i \u0026lt; nextPlaces[place].length; i++) { newDic[nextPlaces[place][i]] += dic[place] % mod; } } dic = newDic; } const totalWays = dic.reduce((acc, item) =\u0026gt; acc + item, 0) % mod; return totalWays; }; Reference\r#\rLeetcode: knight dialer "},{"id":20,"href":"/docs/research/social_media/","title":"Social Media","section":"RESEARCH","content":"\rSocial Media: fakebut.site\r#\rArchitecture\r#\rFrontend: VanilaJS, Vite, Bootstrap 5 Backend: ExpressJS, MongoDB Ops: Git Action, Docker Login\r#\rFront: Login/Register page Setup Vite Routing handling Back: API login/register Cookie base Token base SSO Chat\r#\rWebsocket Post\r#\rComment\r#\rNotification\r#\rAdmin management\r#\r"}]